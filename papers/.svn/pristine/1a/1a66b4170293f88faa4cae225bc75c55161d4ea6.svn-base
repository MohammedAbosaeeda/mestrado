\documentclass{sig-alternate}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}	% for multilingual support

\usepackage{graphicx}

\usepackage[caption=false]{subfig} % Para usar duas ou mais figuras como uma só.

\newcommand{\fig}[4][ht]{
  \begin{figure}[#1] {\centering\scalebox{#2}{\includegraphics{fig/#3}}\par}
    \caption{#4\label{fig:#3}}
  \end{figure}
}
% Current \fig{.5}{subsampling}{Illustration of 4:1 subsampling.}

\newcommand{\wfig}[4][ht]{
  \begin{figure*}[#1] {\centering\scalebox{#2}{\includegraphics{fig/#3}}\par}
    \caption{#4\label{fig:#3}}
  \end{figure*}
}

% Para colocar 2 figuras como uma só - dispostas horizontalmente
\newcommand{\multfigtwoh}[6][htbp]{
\begin{figure*}[#1]
  \centering
  \subfloat[]{\label{fig:#3}\scalebox{#2}{\includegraphics{fig/#3}}}
  \subfloat[]{\label{fig:#4}\scalebox{#2}{\includegraphics{fig/#4}}}
  \caption{#6}
  \label{fig:#5}
\end{figure*}
}
% e.g.
%\multfigtwoh{.65}{fig_plot_time_orig}{fig_plot_time_mod}
%{fig_plot_time_all}
%{Original (a) and modified (b) benchmarks execution time comparison.}

% Para colocar 2 figuras como uma só - dispostas verticalmente
\newcommand{\multfigtwov}[6][htbp]{
\begin{figure}[#1]
  \centering
  \subfloat[]{\label{fig:#3}\scalebox{#2}{\includegraphics{fig/#3}}}\\
  \subfloat[]{\label{fig:#4}\scalebox{#2}{\includegraphics{fig/#4}}}
  \caption{#6}
  \label{fig:#5}
\end{figure}
}
% e.g.
%\multfigtwov{.35}{fig_epos_mem_framework}{fig_epos_mem_framework_spm}
%{fig_epos_mem_framework_all}
%{EPOS memory mapping before (a) and after (b) using the new framework}

%\hyphenation{soft-ware-im-ple-ment-ed}

\begin{document}
\conferenceinfo{Webmedia}{2011 Florianópolis, SC Brazil} % Webmedia2011

\title{Optimizing Motion Estimation for H.264 Encoding}

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.

% Author for article style
%\author{
%{Mateus Krepsky Ludwich and Antônio Augusto Fröhlich} \\
%Federal University of Santa Catarina -- UFSC\\
%Laboratory for Software and Hardware Integration -- LISHA\\
%PO Box 476 - 88049-900 - Florianópolis, SC, Brazil\\
%Email: \{mateus,guto\}@lisha.ufsc.br
%}

\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Mateus Krepsky Ludwich\\
   \affaddr{Federal University of Santa Catarina -- UFSC}\\
   \affaddr{Laboratory for Software and Hardware Integration -- LISHA}\\
   \affaddr{PO Box 476 - 88049-900 - Florianópolis, SC, Brazil}\\
   \email{mateus@lisha.ufsc.br}
% 2nd. author
\alignauthor
Antônio Augusto Fröhlich\\
   \affaddr{Federal University of Santa Catarina -- UFSC}\\
   \affaddr{Laboratory for Software and Hardware Integration -- LISHA}\\
   \affaddr{PO Box 476 - 88049-900 - Florianópolis, SC, Brazil}\\
   \email{guto@lisha.ufsc.br}
}

\maketitle


%
\begin{abstract}
Around 90\% of the total encoding time of raw video into H.264 is spent in
block-matching, a stage of Motion Estimation. In this paper we combine
two block-matching optimizations that yield significant performance
improvements on Motion Estimation: 4:1 subsampling by macroblock and 
truncation of the two less significant bits per sample. When
applied to the JM Reference Encoder, our strategy showed an average
speedup of 2.64 times in total encoding time with a small loss of
quality (less than 0.5 dB).
\end{abstract}
%

% A category with the (minimum) three required fields
\category{I.4}{Image Processing and Computer Vision}{Compression (Coding)}

\terms{Algorithms}

\keywords{Video encoding, Motion Estimation, H.264}

% -----------------------------------------------------------------------------
\section{Introduction}\label{sec:intro}

% P1
% Compactação de vídeo, exploração de redundancias.
% Exploração de redundancia temporal, técnicas para exploração de redundancia temporal.
% ME baseada em blocos, Block-mathing Algorithms (BMAs).
Motion Estimation (ME) is a technique used to explore temporal redundancy in video sequences during compression. Temporal redundancy arises from the fact that neighboring frames very often share similar pixel regions. Therefore the goal of Motion Estimation is to \emph{estimate} the shifting of such similar regions across neighbor frames, thus enabling them to be differentially encoded. In block-based ME, the displacement of similar regions is represented by \emph{motion vectors}, which are computed by the \emph{Block-Matching Algorithms}. Standards like the ISO MPEG series and the ITU-T H26x are examples of encoders that use ME to improve compression ratios in output video streams~\cite{citeulike:1269699}.

% P2
% ME é o que mais consome tempo no encoder H.264 
% Necessidade de otimizar a ME
% Como otimizar a ME? (estratégias)
Around 90\% of the total encoding time in a H.264 encoder is spent in the Motion Estimation stage \cite{XiangLi:2004}, \cite{Yang:2005}.
Consequently, Motion Estimation optimization is a relevant issue for H.264 and video encoding in general. Since the appearance of ME, many strategies were proposed for its optimization. The \emph{Block-Matching Algorithm} (BMA), which searches for similar blocks and generates the motion vectors, is mainly responsible for ME being so time consuming. Therefore one strategy for optimizing BMA is the \emph{fast-search}, which looks only in specific points of the search window, while a similar block is being searched. Another strategy is to perform ME hierarchically, computing motion vectors for a specific frame region, and refining them in each level, which is known as \emph{multi-resolution} motion estimation. Other strategies look into finding parallelism in BMAs, in order to run ME stages simultaneously. For all strategies there are also hardware implementations, based on optimized functional units (such as vector operations) or based on replication of functional units, to explore parallelism.

% P3
Block-Matching Algorithms using fast-search improve time performance of ME, but they can find suboptimal motion vectors because they do not search in all positions of the search window. Multi-resolution ME works with different resolutions of one frame, successively refining the found motion vectors. This increases the ME time if the search is performed sequentially as in \cite{ChiaChunLin:FastAlgPlusArch:2006} or demands for replicated hardware functional units, as in \cite{ChiaChunLin:PMRME:2007}. Similarly, parallel and hardware implementations come at the cost of replicated or dedicated functional units.

% P4
The search for new methods to optimize motion estimation is an important issue to enable the construction of real-time H.264 encoders and the implementations of encoders in devices with less computational resources, since those optimizations aim to reduce ME complexity. Two other strategies used to reduce ME complexity are macroblock subsampling and sample truncation during the block-matching. Macroblock subsampling means that, during block-matching, just some samples of a macroblock (or macroblock partition) are taken into consideration. Sample truncation is a technique for pixel decimation, where a sample can be represented only by its most significant bits (MSB). 

% P5
In this paper we have proposed and evaluated the combination of macroblock subsampling and sample truncation in order to speed up motion estimation, keeping a good video quality - which is measured by the Peak Signal to Noise Ratio (PSNR). We aimed to evaluate these two strategies in an optimal algorithm (i.e. which always finds the best motion vectors), therefore we have used a full-search algorithm instead of a fast-search one. However these strategies can also be applied in fast-search algorithms since they are orthogonal to the block-matching algorithm used.
% Dizer aqui do critério do 0.5 dB e da melhor combinação encontrada?

% P6
% + paper structure(chapters' description)
The next sections of this article are organized as follows: section~\ref{sec:related} makes an overview of issues and strategies for ME optimization; section~\ref{sec:proposal} presents the proposed ME optimizations; section~\ref{sec:JM} describes the implementation of the proposed optimization for the JM H.264 Reference Encoder. Section~\ref{sec:results} evaluates the results obtained from the proposal's evaluation using the JM encoder. The final considerations are presented in section~\ref{sec:conclusion}.

% -----------------------------------------------------------------------------
%\section{Related Work}\label{sec:related}
%\section{Overview of strategies for ME optimization}\label{sec:related}
\section{Strategies for ME optimization}\label{sec:related}
% P1
% + description of the problem

There are two major goals in motion estimation optimization: to improve the compression rate and to reduce the total encoding time. Improving the compression rate is achieved by finding the best possible motion vectors, which means motion vectors that will generate the smallest residual difference during the motion compensation (MC). Reducing the total encoding time is achieved by finding the motion vectors in the smallest possible period of time. Several tools in H.264 are used to find the best possible motion vectors; besides looking in all positions of a search window (i.e. full-search), it is possible to search in several reference frames (backwards or forwards), and it is possible to perform block-matching using sub-pel precision (half and quarter of a pel) \cite{citeulike:1269699}. Finding the best motion vectors, very often, goes against finding the motion vectors more quickly. In this work we focus on motion estimation optimizations which aim to reduce the total encoding time, therefore we are not going into the details of techniques for finding the best motion vectors possible, but they can be found in \cite{YuWenHuang:Complex:2006}, \cite{YepingSu:MF:2006}, \cite{Ma:MF:2009}, and \cite{XiangLi:MF:2004}. It is important to notice that all techniques for ME optimization must take into consideration keeping the video quality of the generated bitstream.

% P2
% Como otimizar a ME - estratégias.
There are many strategies to optimize the time performance of motion estimation: fast-search algorithms, macroblock subsampling, sample truncation, multi-resolution ME, subsampled motion-field estimation, and parallel and hardware implementations of algorithms.

% P3 ... Pn-1
% Um paragrafo para cada estratégia dizendo:
% + how these solutions match/ contribute to Goals { g1, g2, .., gn} and Features {f1 , f2 , ..., fn}
% + And what set of features F is still missing? (GAP)
%
% P3 - fast-search
\emph{Fast-search algorithms} are block-matching algorithms that look only in specific positions of the search window, during block-matching \cite{SunNingning:TSS:2009}, \cite{LaiManPo:4SS:1996}, \cite{ShipingZhu:DS:2009}, \cite{Tourapis:PMVFAST:2001}, \cite{HoiMingWong:EPMVFAST:2005}, \cite{LiangGeeChen:TDL:1991}.
Search window is the region of the reference frame where a macroblock partition similar to the current block is searched. The motion vectors correspondent to the match with the lower \emph{motion cost} are chosen. The main drawback of this approach is that, since some positions of search window are discarded, it is possible to find suboptimal motion vectors.

% P4 macroblock subsampling and sample truncation
Two other strategies to optimize ME during block-matching are macroblock subsampling and sample truncation. Macroblock subsampling means taking into consideration only some samples of a macroblock, or macroblock partition, while the matching for a specific position of the search window is been made. Sample truncation is performed by ignoring the least significant bits of a sample. These strategies have been used separately in \cite{liu:sub:1993} (subsampling) and in \cite{DBLP:journals/tcsv/HeTCL00}, and \cite{ChiaChunLin:PMRME:2007} (truncation). In this work we have combined these strategies to optimize ME. Section \ref{sec:proposal} explains these strategies in detail.

% P5 multi-resolution ME
\emph{Multi-resolution motion estimation} is the strategy where the motion vectors are computed for distinct resolutions of one same frame. Motion vectors computed in a more coarse level can be successively refined until the finest level (higher resolution). If the search is performed sequentially as in \cite{ChiaChunLin:FastAlgPlusArch:2006}, the time of ME can be increased due to the dependencies between distinct levels. On the other hand, if the search is executed in parallel for each resolution level, as in \cite{ChiaChunLin:PMRME:2007}, hardware functional units need to be replicated. 
A similar technique is \emph{subsampled motion-field estimation} \cite{liu:sub:1993}. This technique is based on the assumption that motion vectors of neighboring blocks are intent to be similar thus, for each block, only a set of motion vectors (motion-field) is computed and the others are interpolated.

% P7 | P6 parallel and hardware implementations of algorithms
Other strategies for optimizing motion estimation are based on finding parallelism in ME stages, especially in the block-matching algorithms, in order to execute them simultaneously. These parallel strategies commonly have hardware implementations. The Sum of Absolute Differences (SAD) is a metric of error used in the block-matching algorithms, that is frequently parallelized using functional units in hardware \cite{ChiaChunLin:PMRME:2007}, and \cite{HoyoungChang:HW:2009}. Hardware implementations of shared buffers for reference picture data is also common \cite{HoyoungChang:HW:2009}, \cite{HaibingYin:HW:2010}. Although these solutions can achieve the best time performance, they come at the cost of using replicated or dedicated functional units.

% -----------------------------------------------------------------------------
\section{Proposed Optimizations} \label{sec:proposal}
% Geral: Explicar subsampling e truncation. Explicar o que é cada uma e porque usamos cada uma delas e elas em conjunto.
%
% O que foi feito. Onde foi feito.

We envisioned two major opportunities to optimize matching operations within block-based Motion Estimation algorithms: macroblock subsampling and sample truncation. Both were applied in the block-matching algorithm to speedup the whole process of motion estimation. More specifically they are applied in the SAD computation, which is the error metric used to compute the distortion term in the Lagrangian cost function used in H.264 \cite{1101854}.

Equation \ref{eq:sad} shows the bi-dimensional SAD used for block-matching algorithms in video coding. \textit{C} represents the current \textit{NxN} block that is being searched in the reference frame and \textit{R} is the \textit{NxN} block of the reference where the BMA is looked into.

\begin{equation} \label{eq:sad}
SAD = \sum_{i = 0}^{N - 1} \sum_{j = 0}^{N - 1} \left | C_{ij} - R_{ij} \right |
\end{equation}

The Lagrangian cost function used in H.264 motion estimation is shown in \ref{eq:lagrangian}. For simplicity details of the equations are omitted, but they can be seen in \cite{1101854}. The \textit{Rate} term of the equation is the number of bits necessary to encode the motion vectors and the reference frame identification. The distortion term (\textit{SAD}) is computed as shown in \ref{eq:sad}.

\begin{equation} \label{eq:lagrangian}
Motion Cost = Rate + SAD
\end{equation}

\subsection{Subsampling}
% Subamostragem afeta áreas (macroblocos).
%    Analizando 1 frame, quanto mais redundância espacial, menos se perde em qualidade.
%    Analizando 2 frames, vídeos de menos movimento, deveriam ter menos perda de qualidade. %[não é verdade]
%    
%    Quantos menos amostras são analizadas em uma região, poderia-se deixar escapar os pixels semelhantes, aumentar o ruído (e perder qualidade).
%    Entretanto isto é amenizado pela alta redundancia espacial dos vídeos fotograficos. E pela baixa redundancia temporal? Não, apenas pela redundancia espacial.
%

Subsampling aims at reducing the time needed to compute a matching
criterion, like SAD, by applying the corresponding operation only to a
subset of the pixels in a macroblock. The optimization relies on the
assumption that neighboring pixels in a macroblock should have similar
values (spatial redundancy) and thus computing the matching criterion from a 
regular subset should yield comparable results. This assumption is confirmed by the
experiments presented in section~\ref{sec:JM}. Figure
\ref{fig:subsampling} illustrates the process of 4:1 subsampling in a 16x16
macroblock. The dark pixels are the pixels taken into
consideration. Instead of comparing 256 pixels (16x16), the algorithm
compares only 64 pixels (8x8), speeding up the process.
% The choice of 4:1 subsampling was based on practical experiments and also on data reported by Liu~\cite{liu:sub:1993}.

\fig{.5}{subsampling}{Illustration of 4:1 subsampling}

\subsection{Truncation}
% Truncagem afeta todos os pixels, todos.
%    Analizando 1 frame, mais ou menos redundancia espacial não altera no processo.
%    Analizando 2 frames, regiões dos frames que eram ligeiramente diferentes passam a
% serem iguais.
%
% Logo acha-se o a região mais próxima mas cedo.
% [ calcula-se menos SADs (early termination) e tem-se um speedup. ]
% 
%     Analizando 1 frame, o ruido é inserido de forma homogena (igualmente distribuída).
%     Analizando 2 frames, 
%         Se tem bastante movimento F1 não vai ficar parecido com F2, não importa o
%  truncamento
%         Se tem pouco movimento F1 fica mais parecido com F2. Acho que não afeta o ruído
%  de forma diferente.
%
% ---
% MotionCost = RateTerm + SAD
% 
% minimum_motion_cost = 'X'
% motion_cost = rate_term()
% if motion_cost 
% 
%
% Explicar / definir truncation
% Dizer pq usamos truncation. Pode ser a balela daqui de baixo, ou a questão 
% do early termination... Daí mostrar a formula do Lagrange aqui

Similarly to subsampling, truncation also aims at reducing the computational cost of block matching by eliminating redundant data. As basis for this optimization we took the assumption that the main information of a sample is stored in its most significant bits (MSB) thus ignoring the least significant bits (LSB) should generate a small noise in the encoded video sequence. The main information of a pixel in YCbCr format means the light variation in the luminance channel (Y) and color variation in the chrominance channels (Cb and Cr).

Our experiments with the JM H.264 Reference Encoder demonstrate that truncation
can also improve soft\-ware-im\-ple\-ment\-ed algorithms, because the 
Full-Search block-match\-ing algorithm in JM features an early termination 
mechanism. The motion cost in H.264 is calculated using the Lagrangian 
rate-distortion cost function shown in \ref{eq:lagrangian}. The Full-Search 
block-matching algorithm in JM first computes the rate component of the motion 
cost for a specific position in the search window. If the rate component value 
is greater than or equal to the previous minimum motion cost (cost of a previous
compared block), the distortion component of motion cost (given by the SAD function)
is not computed, and the motion cost computation is abbreviated for that block. When
bits are truncated, numbers that once were slightly different from each other become
equal. Consequently, the number of occurrences in which the previous minimum cost and
the rate component of the current cost are equal increases and the SAD does not need
to be computed. The speedup is then caused by the reduction in the frequency of
calls to the SAD function.

%-----------------------------------------------------------------------------
\section{Implementation in the JM H.264 Reference Encoder}\label{sec:JM}
% P: Dizer o que é o JM
% P: Dizer como realizamos os experimentos. E/ou quais as variáves observadas
% qualidade e speedup.
%

We implemented the optimizations described in the previous section in
the JM H.264 Reference Encoder~\cite{site:jm} to assess their impact on
the final video quality. Being the reference software implementation
for the H.264 standard, JM includes both encoding and decoding
functionality. Our experiments were carried out with JM version 14.2
and consisted of encoding a set of reference video sequences with the
original encoder and subsequently with the modified one, therefore
enabling us to measure variations in the Peak Signal to Noise Ratio
(PSNR) and in the encoding time.

% P: Dizer pq focamos em luma
For inter macroblock modes in H.264 (i.e. modes related to the Motion Estimation),
the motion cost for chrominance components derives from the motion cost for 
luminance components~\cite{1101854}. Consequently the PSNR for chrominance components derives 
from the PSNR for luminance components. For this reason, in this paper we focus 
on the PSNR variation of the luminance component.

% P: Falar sobre os videos
The video sequences chosen for the experiments encompass different resolutions and frame rates: Foreman QCIF, Foreman CIF, Mobile \& Calendar CIF, City 4CIF, Stockholm 720p, Sunflower 1080p, and Crown Run 1080p. These are all raw video sequences in YUV format. Their key features are summarized in table~\ref{tab:sequences}.


\begin{table*}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Sequence} & \textbf{Resolution} & \textbf{Frame rate (fps)} & \textbf{Duration (s)} \\
\hline
Foreman & QCIF (176 x 144) & 30 & 10 \\
\hline
Foreman & CIF (352 x 288) & 30 & 10 \\
\hline
Mobile & CIF (352 x 288) & 30 & 10 \\
\hline
City & 4CIF (704 x 576) & 60 & 10 \\
\hline
Stockholm & 720p (1280 x 720) & 60 & 10 \\
\hline
Sunflower & 1080p (1920 x 1080) & 25 & 20 \\
\hline
Crown Run & 1080p (1920 x 1080) & 50 & 10 \\
\hline
\end{tabular}
\caption{Video sequences used in the experiments}
\label{tab:sequences}
\end{center}
\end{table*}

%P: Falar como implementados subamostragem e como implementamos a truncagem.
% Dizer que usamos Full-Search
Subsampling was implemented in JM as proposed in
section~\ref{sec:proposal}. Samples are taken from macroblocks following
a regular, symmetrical pattern. For instance, a 4:1 subsample is
obtained by having the iteration loop to skip columns and rows as shown
in Figure~\ref{fig:subsampling}. Truncation was done in JM by assigning
zero to the least significant bits of each sample, since actual register
and memory truncation are meaningless to software implementations.  Both
techniques, subsampling and truncation, were implemented during the SAD
computation. The block-matching algorithm used was Full-Search.

% P: Falar todos os testes realizados
% Testamos subamostragem simétrica de macroblocos nas relações: 2:1, 4:1 e 8:1
% Testamos truncamento de amostras de 8 bits, truncando 1, 2, 3, 4, 5, 6 e 7 bits menos 
% significativos
% Testamos também todas as combinações de subamostragem e truncagem, cujos valores
% individuais de subamostragem e truncagem estivesem abaixo de 0.5 dB.
Modifications to JM were implemented so that subsampling and
truncation could be evaluated both in separation and together, thus
rendering more detailed results.
We tested 2:1, 4:1, and 8:1 subsampling. And we tested truncation on 8-bit 
samples varying from 1 to 7 LSB. We took the cases which had generated a small
noise (0.5 dB) and tested their combinations.

%-----------------------------------------------------------------------------
\section{Result Analysis}\label{sec:results}

Our results show that subsampling and LSB truncation both improve video
encoding performance while degrading quality, either deployed separately
or in combination. Both parameters: performance and quality vary
proportionally to the extending of the applied optimizations as can be seen
in figures~\ref{fig:jm_sub}
to~\ref{fig:jm_tru_qual}. Figure~\ref{fig:jm_sub_perf} shows the
performance improvement for the chosen video sequences as a function of
a growing subsampling factor, while Figure~\ref{fig:jm_sub_qual} shows
the corresponding quality loss measured as a decrease in
PSNR. Figures~\ref{fig:jm_tru_perf} and~\ref{fig:jm_tru_qual}
illustrate the facts for truncation. 

%\fig{0.6}{jm_sub_perf}{Impact of subsampling on encoding performance}
%\fig{0.6}{jm_sub_qual}{Impact of subsampling on encoding quality}
\multfigtwoh{.65}{jm_sub_perf}{jm_sub_qual}
{jm_sub}
{Impact of subsampling on encoding performance (a) and encoding quality (b)}


%\fig{0.6}{jm_tru_perf}{Impact of truncation on encoding performance}
%\fig{0.6}{jm_tru_qual}{Impact of truncation on encoding quality}
\multfigtwoh{.65}{jm_tru_perf}{jm_tru_qual}
{jm_tru}
{Impact of truncation on encoding performance (a) and encoding quality (b)}


The PSNR degradation as computed as the absolute PNSR difference between the
original encoder and the optimized ones. In order to measure the PNSR variation
we have fixed the encoding bit-rate for all video sequences. We have chosen 
values of bit-rate which result in a compression ratio around 10:1. 
Table \ref{tab:config} shows the bit-rate used for each encoded sequence.

\begin{table}
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Sequence} & \textbf{Bit-rate (Mbit/s)} \\
\hline
ForemanQCIF & 1 \\ % Dados de Setembro de 2010 (usando YUV 402i)
\hline
ForemanCIF & 2.4 \\ % Dados de Setembro de 2010 (usando YUV 402i)
\hline
MobileCIF & 2.4 \\ % Dados de Janeiro de 2010 (ainda usando Y4M)
\hline
City4CIF & 30 \\ % Dados de Janeiro de 2010 (ainda usando Y4M)
\hline
Stockholm720p & 66.8 \\ % Dados de Janeiro de 2010 (ainda usando Y4M)
\hline
Sunflower1080p & 66.8 \\ % Dados de Setembro de 2010 (usando YUV 402i)
\hline
Crown Run1080p & 133.6 \\ % Dados de Setembro de 2010 (usando YUV 402i)
\hline
\end{tabular}
\caption{Bit-rate used in the experiments}
\label{tab:config}
\end{center}
\end{table}

We have noticed that subsampling has more influence in the encoding speedup than truncation. We have a mean speedup of 2.07 times for subsampling against 1.80 times from truncation, considering all subsampling and truncation strategies tested and taking into account the \emph{valid cases} (i.e. cases where the quality loss is less than 0.5 dB).

Subsampling generates more noise than truncation. Again, considering all subsampling and truncation strategies and the \emph{valid cases} we got a mean quality loss of 0.27 dB for subsampling and a mean quality loss of 0.12 dB for truncation. Although considering the mean and the worst case only 8:1 subsampling exceeds 0.5 dB of noise. In the mean case for truncation the noise becomes bigger than 0.5 dB only after 4 LSB bit truncation, and after 3 bit truncation considering the worst case.

From the obtained data, we noticed that a combination of 4:1 subsampling
and 2 LSB truncation would result in the bigger speedup while keeping 
relatively small quality loss. Indeed, we looked into the obtained data
for a combination that would cause no more than 0.5dB decrease in PSNR
and has the highest speedup.  Truncation of
2 LSB incurs in an average PSNR reduction of less than 0.1dB, while 4:1
subsampling has a higher toll on quality, about 0.31db. Subsampling,
however, is the major speedup source for JM, since $3/4$ of the data in
each macroblock is simply ignored (as explained in
section~\ref{sec:proposal}, speedups from truncation on software ME
implementations arise from early termination mechanisms). This leads to
speedups of up to 3.18 times (for the Stockholm sequence).
The charts in Figures~\ref{fig:jm_perf} and~\ref{fig:jm_qual} detail the combination of 4:1 subsampling and 2 LSB truncation. The average speedup for the combined approach
was of 2.64 times, with an average impact on PSNR of less than
0.5db.

%\fig{0.5}{jm_perf}{Optimizations speedup on JM}
%\fig{0.5}{jm_qual}{PSNR degradation due to optimization on JM}
\multfigtwov{.65}{jm_perf}{jm_qual}
{jm_opt}
{Speedup (a) and PSNR degradation (b) due to optimization on JM}


% Sobre RD curves
%The proposal combining 4:1 macroblock subsampling and 2 LSB truncation per sample is 
In order to evaluate in details the behavior of our proposal for distinct values 
of encoding bit-rate, we have used the BD-PSNR (Bjøntegaard Delta PSNR) metric
using the following values of QP (Quantization Parameter): 16,20,24,28, as 
described in \cite{gisle_bjntegaard_calculation_2001}. It is important to 
evaluate quality (PSNR) for distinct bit-rates to test whether the approach can
be used in distinct scenarios of application.
Figure \ref{fig:bd_psnr} shows the rate-distortions (RD) curves using the 
original JM encoder and the optimized encoder using our proposal. The video
sequence used for this curves was Crowd Run which has a high quantity of motion
and is a HD (1080p) sequence. % - the same resolution specified 
Lower values of bit-rate are obtained for higher values of QP since using 
higher values for QP more data is discarded and there is an increasing on the
compression ratio. The two curves are very near from each other which indicates
the proposal presents a good rate-distortion performance for all the evaluated
bit-rates. We have evaluated also the speedup obtained in the encoding time while
using our proposal for the same QP values we used for BD-PSNR. 
Figure \ref{fig:bd_speedup} shows the obtained values. A speedup of near 3 times
is obtained for all bit-rate values.

%\fig{0.5}{bd_psnr}{The RD curve of 1080p sequence}
%\fig{0.5}{bd_speedup}{Speedup vs bit-rate of 1080p sequence}
%
\multfigtwoh{.65}{bd_psnr}{bd_speedup}
{bd}
{RD curve (a) and speedup vs bit-rate (b) of 1080p sequence}

The quality loss is small when compared to the speedup mainly because of the spatial redundancy of photographic video sequences. For the case of subsampling one would think that decreasing the number of samples taken into consideration in the block matching, would let escape similar samples, worsening ME precision and increasing the generated noise. However because of the spatial redundancy this increase of noise remains small. The truncation is applied to all samples of the video sequence, thus it does not affect the quality aspect of the matching algorithm. The noise generated by truncation is homogeneous and does not influence in ME.



% -----------------------------------------------------------------------------
\section{Conclusions}\label{sec:conclusion}

In this article, we combine two complementary optimizations for block-based Motion Estimation in video encoding: macroblock subsampling and truncation of the two least significant bits per sample. The proposed optimizations were developed around the Full-Search block-matching algorithm and the SAD matching criterion, yielding a block-matching engine that was implemented in the JM Reference Encoder.

The evaluation of the proposed optimizations in the JM H.264 Reference Encoder assess ME quality and good performance gains. It also demonstrates the best combination between subsampling and truncation. The combination of 4:1 subsampling and 2 LSB truncation presents a quality loss of less than 0.5dB for all considered sequences and an average speedup of 2.64.

Since the proposed strategies were implemented in a full-search algorithm, the developed ME engine avoids the problem of finding suboptimal motion vectors originated by skipping positions of the search window. However, the proposed approach is independent of the BMA used, so it can also be applied in fast-search BMAs.

The proposed approach was applied in a single-resolution motion estimation, then there is no need of extra hardware resources to compute ME for distinct levels of resolution. Either way, it is possible to adapt subsampling and truncation together in any of the levels of resolution in a multi-resolution ME strategy.

The proposed method is essentially algorithmic decreasing ME complexity and freeing hardware resources. Although it is possible to develop parallel versions of the proposed method and implement those developing dedicated hardware architectures.

The combination of the proposed approach with other methods for ME optimization could be a matter for further evaluations

% -----------------------------------------------------------------------------
% \section{Acknowledgments} % [Removed for blind review]
% We would like to thank Ronaldo Husemann and Valter Roesler for the early idea of using subsampling and truncation applied to MPEG-2 video coding. 

\bibliographystyle{abbrv}
% \nocite{*}
\bibliography{mm}

\end{document}
