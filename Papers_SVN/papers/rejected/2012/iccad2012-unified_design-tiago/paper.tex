%\documentclass[10pt,journal,final,letterpaper]{IEEEtran}
%\pdfpagewidth=8.5in
%\pdfpageheight=11in
\documentclass[10pt,conference]{IEEEtran}

\usepackage[latin1]{inputenc}	% for Latin languages
\usepackage[T1]{fontenc}	% for ISO and UTF characters
\usepackage[english]{babel}	% for multilingual support
\usepackage{graphicx}
%\usepackage{multirow}
%\usepackage[caption=false,font=footnotesize]{subfig}
%\usepackage{natbib}
\usepackage{color}
\definecolor{Red}{rgb}{.9,0,0}

\include{utils} %new commands 

\begin{document}

\title{On AOP techniques for C++-based HW/SW component implementation}

%\author{Tiago Rogério Mück and Antônio Augusto Fröhlich\\
%\IEEEauthorblockA{Software/Hardware Integration Lab\\
%Federal University of Santa Catarina\\
%Florianópolis, Brazil\\ 
%Email: \{tiago,guto\}@lisha.ufsc.br}
%}

\author{Authors omitted for peer review}


\maketitle

\begin{abstract}
The increasing complexity of embedded system applications is leading to a convergence between
hardware and software development. In this paper we aim to close the gap between
hardware and software implementation by proposing guidelines for handling both domains in a
unified fashion. We leverage on aspect-oriented programming~(AOP) concepts to
provide unified C++ descriptions that can be both compiled to software or synthesized to dedicated
hardware using high-level synthesis tools. Our results show that our strategy leads to reusable and
flexible components at the cost of a small overhead when compared to software-only C and
hardware-only C++ implementations.
\end{abstract}

\begin{IEEEkeywords}
System-level design; HW/SW co-design; High-level synthesis; Aspect-oriented system design;
\end{IEEEkeywords}


%TODO mexer nas figuras: diminuir o tamanho (mas aumentar a fonte do texto - princ. código)

\section{Introduction}
\label{sec:introduction}
       
Embedded systems are becoming increasingly complex as the advances of the semiconductor industry
allow the use of sophisticated computational resources in a wider range of applications. Depending
on the application's requirements (e.g. performance, energy consumption, cost, etc.), the
development of such systems may encompass an integrated hardware and software design that can be
realized by several different computer architectures, ranging from simple 8-bit microcontrollers to
complex \textit{multiprocessor system-on-chips}~(MPSoCs).

In order to deal with this complexity, embedded system designs are being pushed to higher levels of
abstraction, such as \emph{system-level design}. In this scenario, a convergence between hardware
and software design methodologies is desirable, since a unified modeling approach would allow one
to take decisions about hardware/software partitioning later in the design process, maybe even
automatically. In the last few years, advances in \textit{electronic design automation}~(EDA) tools
are allowing hardware synthesis from descriptions at the behavioral level. These tools
allow designers to describe hardware components using languages like C++, and higher-level
mechanisms, such as \textit{Object-Oriented Programming}~(OOP) techniques. The focus of these tools,
however, is hardware synthesis, and they do not provide a clear design methodology for developing
components which could be implemented as both hardware and software.

Aiming to narrow this gap and move towards a real unified implementation approach, in this paper we
describe
some guidelines and mechanisms which allow the implementation of both hardware and software
components from a single C++ description. Our guidelines are built upon the
\textit{Application-driven Embedded System Design}~(ADESD) methodology\cite{Froehlich:2001}. ADESD
leverages on OOP and \textit{aspect-oriented programming}~(AOP) concepts, defining a domain
engineering strategy which allows us to clearly separate the core behavior and the structure of a
component from aspects which are specific of software and hardware scenarios. In order to
generate descriptions that can be efficiently synthesized to hardware or compiled to a software
binary, the implementation of both the components and the mechanisms which adapt them  make
extensive use of C++ \emph{generative programming}\cite{Czarnecki:2000} techniques such as
\emph{static metaprogramming}. To evaluate the efficiency of our approach, we present the
implementation of a \textit{Private Automatic Branch Exchange}~(PABX) SoC of which some components
were implemented using our unified design strategy.

The remaining of this paper is organized as follows: section \ref{sec:related_work} presents a
discussion about works related to the integration of hardware and software design; section
\ref{sec:adesd} presents an overview of ADESD; in
section \ref{sec:proposal} we present our approach for the proper separation and implementation of
software and hardware scenario aspects; section \ref{sec:evaluation} describes our case studies and
shows our experimental results; and section \ref{sec:conclusion} closes the paper with our
conclusions.

\section{Related work}
\label{sec:related_work}

Several design methodologies were proposed in order to provide more tightly coupled
hardware and software design flows. Most of them are based on the concept of building
a system by assembling pre-validated components. The \emph{Metro-II}~\cite{Davare:2007} framework
follows the \emph{Platform-based design} (PDB) \cite{Vincentelli:2001} methodology, and propose the
use of a metamodel with formal semantics to capture designs. An environment to support simulation,
formal analysis, and synthesis is also provided. However, the hardware/software partitioning is
defined in the early design stages and is limited by the platform specification. Also, this
methodology does not define a clear guideline to design new components which can be reused in a wide
range of applications. Thus, one must focus on closing the actual gap between the design of software
and hardware components. State-of-the-art EDA tools support hardware synthesis from high-level
C++/C-based constructs and several works have already demonstrated the applicability of
\textit{high-level synthesis}~(HLS) for implementing hardware components~\cite{Fingeroff:2010}. Our
aims are different however. We want to describe algorithms in a high level of abstraction, but those
should be implementable in hardware as well as in software, and with performance close to
software-only and hardware-only implementations.

On this track, the OSSS+R methodology~\cite{Schallenberg:2009} improves \textit{register transfer
level}~(RTL) models in SystemC by adding new language constructs to support synthesizable
polymorphism and high-level communication. However, hardware/software partitioning must still be
done in the beginning of the design process~\cite{Gruttner:2008}, and the inclusion of non-standard
language constructs reduces the compatibility of the design with available compilers and hardware
synthesis tools. In the \emph{Saturn}~\cite{Mischkalla:2010} design flow, the authors propose
\emph{SysML}, an extension of UML for system-level design, and a tool which generates C++ for
software and RTL SystemC for hardware. However, Saturn has the same limitations of OSSS+R described
previously.

SystemCoDesigner~\cite{Keinert:2009} is a tool which integrates a HLS flow with
design space exploration. The design entry of SystemCoDesigner is a data flow model implemented
using a SystemC-based library. After design space exploration, this model can be either
converted to synthesizable SystemC or to C++ for software compilation. However, as the authors
claim, SystemCoDesigner targets mostly data-flow-based applications. Directions regarding a more
general deployment are not provided. The System-on-chip environment~(SCE)~\cite{Rainer:2008} takes
SpecC models as input and provides a refinement-based tool flow.  Guided by the designer, the SCE
automatically generates a set of \textit{Transaction-level models}~(TLM)~\cite{Cai:2003} that are
further refined to pin- and cycle-accurate system implementations.

Other works focus mainly on interfacing software and hardware. The \emph{HThread}
project~\cite{Anderson:2007} provides a unified interface for both domains. A task performed in
hardware is seen with the same semantics as a software thread, and a system call interface is
provided to hardware components. However, an enormous gap still exists between the way the hardware
and software threads themselves are implemented. The work of \textit{Rincón et
al}~\cite{Rincon:2009} is based on concepts from distributed object platforms such as CORBA and Java
RMI and provides a tool which generates the communication glue necessary so that hardware and
software components can communicate seamlessly.
     
\section{Application-driven Embedded System Design}
\label{sec:adesd}
The ADESD~\cite{Froehlich:2001} methodology elaborates on commonality and variability analysis to
add the concept of aspect identification and separation at early stages of design. It defines a
domain engineering strategy focused on the production of families of \emph{scenario-independent
components}. Dependencies observed during domain engineering are captured as different aspects, thus
enabling components to be reused on a variety of execution scenarios with the application of
\emph{aspect programs}. The design artifacts proposed by ADESD facilitates the separation of
concerns within embedded system components making hybrid implementations possible. This was
initially explored by the idea of \emph{Hybrid Components}~\cite{Marcondes:2009}, in which a common
architecture for communication between components living in hardware and/or
software was developed. This architecture defines interfaces that, when implemented, allow for
components to communicate independently of whether they are in software or in hardware. 

In this work we aim to show how ADESD's aspect separation mechanisms can be used to yield
components susceptible to both hardware and software generation. ADESD proposes the use of
constructs called \emph{Scenario adapters}~\cite{Froehlich:2000} to perform aspect
weaving. Scenario adapters were developed around the idea of components getting in and out of an
execution scenario, allowing actions to be executed at these points. Figure
\ref{fig_scenario_adapter} shows how this is achieved. The \emph{Scenario} class represents the
execution scenario and incorporates, via aggregation, all of the aspects which define its
characteristics. The adaptation of the component to the scenario is performed by the
\emph{Scenario\_Adapter} class via inheritance. 

\fig{.3}{fig_scenario_adapter}{UML diagram showing component adaptation using a scenario adapter.}

In the next sections we demonstrate how aspects specific of a \emph{hardware scenario} or a
\emph{software scenario} can be isolated from the core behavior and the interface of a component. By
following this approach, the same component description can be tailored by the scenario adapter in
order to feed either a software compilation flow or a hardware high-level synthesis flow.

         
\section{Unified hardware/software design}
\label{sec:proposal}

HLS tools allow for hardware synthesis from algorithms described in languages such as C++. When
aiming at this goal, the implementation of the algorithm itself is usually very similar to what is
seen in software. However, at component level, several aspects arise which distinguish descriptions
aiming at hardware and software. 

Component communication is the primary concern. In the software domain, components may be objects
which communicate using method invocation (considering an OOP-based approach), while in the hardware
domain, components communicate using input/output signals and specific handshaking protocols. For
communication through different domains, the software must provide an appropriate run-time support
usually composed by \textit{hardware abstraction layers}~(HAL) and \textit{interrupt service
routines}~(ISR), while the hardware must cope with such run-time support when it requests a software
operation.

Another important aspect that distinguishes hardware from software is resource allocation. The
hardware is frozen and common software features, such as dynamic memory allocation, are not
available. Therefore, in code suitable for hardware synthesis, all data structures must reside in
statically allocated memory. Some works focus on this problem by relying on dynamic reconfiguration
technologies of FPGAs to support hardware components instantiation at run-time\cite{Abel:2010}.
However, this is not the focus of our current work. We aim at providing more general guidelines
for describing components.

\subsection{Defining C++ unified descriptions}
\label{sec:proposal:unified_design}

A unified description of components can be obtained from implementations that are largely
separated from hardware and software scenario details. This can be achieved through careful domain
engineering and system design. \textit{Pizani et al}~\cite{Pizani:2011} has already shown how
the ADESD methodology was used to provide a C++ implementation a resource scheduler in hardware. In
the next sections we show how one can further leverage on ADESD's artifacts to provide C++ unified
descriptions and efficient hardware/software aspects separation.

\subsubsection{Components implementation}
\label{sec:proposal:unified_design:unified_descriptions}
C++ code unified and suitable for automatic implementation in both hardware and software must
follow a careful design process so it does not contain aspects specific of hardware or software.
To illustrate how ADESD yields such components, we describe in more details one of our case
studies: the design and unified implementation of the EPOS~(\textit{Embedded Parallel Operating
System})\cite{Froehlich:2001} thread scheduler. EPOS is a case study on which the design artifacts
proposed by ADESD were implemented and validated. The OS is implemented in C++ and leverages on
\emph{generative programming}\cite{Czarnecki:2000} techniques such as \emph{static metaprogramming}
in order to achieve high reusability with low overhead. EPOS's domain engineering simplified our
work by providing a good \emph{separation of concerns} around the scheduler. Figure
\ref{fig_epos_scheduler} shows a simplified class diagram of the scheduling-related classes in EPOS.

\fig{.59}{fig_epos_scheduler}{Simplified class diagram of scheduling-related classes in EPOS.}

The \emph{Scheduler} class is responsible only for keeping ordered queues, with the ordering defined
by the scheduling criterion. An object of the \emph{Scheduler} class allows its callers to
insert and remove clients from the queues, as well as to get the current and next owners of the
resource. In our case study, we have implemented a scheduler for threads. However, the scheduler
code is largely independent of the type of resource being scheduled (in fact, \emph{Scheduler} is a
\emph{class template}). Furthermore, concerns such as timing interrupt generation and context
switching are handled separately by the OS. 

Among all classes in Figure \ref{fig_epos_scheduler}, we've adapted the original implementation of
the
\emph{Scheduler} class (and also its base classes), so that it can now serve as input for both
hardware and software implementation flows. These adaptations were necessary not due to specific
hardware or software aspects, but due to some limitations of HLS tools. The main limitation is
related to \emph{pointers}. Pointers have no intrinsic meaning in hardware. They are mapped by HLS
tools to indices of the storage structures to which they point. Thus, \emph{no null or otherwise
invalid pointers} are allowed in the source code. However, the original scheduler implementation
used null pointers to report failures. To avoid this, we've changed the code to utilize \emph{option
types}. An option type is a container for a generic value, and has an internal state which
represents the presence or absence of this value. We implemented an option type in the C++ class
template \emph{Maybe\textless T\textgreater}, which has the following constructors:

\scriptsize\begin{verbatim}
Maybe(): _exists(false), _thing(T()){}
Maybe(T obj): _exists(true), _thing(obj){}
\end{verbatim}\normalsize

One constructor represents the absence of a value in the container while the other represents its
presence. By replacing all occurrences of simple pointers (\emph{T*}) in the scheduler code with
\emph{Maybe\textless T*\textgreater} values, we completely avoided passing invalid pointers around.

HLS tools also limits the use of C++ features that rely on dynamic structures in software (e.g.
heaps, stacks, virtual method tables), such as \emph{new} and \emph{delete} operators, recursion,
and dynamic polymorphism. In section \ref{sec:proposal:unified_design:aspects} we show how resource
allocation can be implemented as a separated \emph{aspect}, however recursion and polymorphism can
be implemented using static metaprogramming techniques, yielding code supported by HLS tools.
For example, static polymorphism can be implemented as shown below:

\scriptsize\begin{verbatim}
template <class derived_class> class Base {
  void interface() {
    static_cast<derived_class*>(this)->implementation();
  }
};
class Derived : public Base<Derived> {
  void implementation();
};
\end{verbatim}\normalsize

Classes can derive from template instantiations of the base class using themselves as template.
This is also known as \textit{Curiously Recurring Template Pattern}~(CRTP)~\cite{Coplien:1995}, and
allows the static resolution of calls to virtual methods of the base class.

\subsubsection{HW/SW aspects encapsulation}
\label{sec:proposal:unified_design:aspects}
Throughout the domain decompositions of our case studies we have identified two aspects that must be
handled differently whether the component is in hardware or in software: \emph{storage allocation}
and \emph{method call interface}. Figure \ref{fig_hw_sw_scenarios} shows how we have used scenario
adapters to isolate such aspects. 

\fig{.59}{fig_hw_sw_scenarios}{Software and hardware scenarios' aspects}

The \emph{HW Scenario} is composed by the aspects \emph{Static Alloc} and \emph{Dispatch}, whom are
responsible, respectively, for storage allocation and method call dispatch. The former is a storage
allocator used to deal with the absence of dynamic memory allocation in hardware. Handling memory
allocation externally is only possible because our components implement solely their
\emph{core behavior}. For example, the \emph{List} class (Figure \ref{fig_epos_scheduler}) is a
linked list, but it is not responsible for the allocation of space for links and the objects it
stores. It implements only the list algorithms and deals with references to such elements.
Therefore, all components operations go through the allocator which reserves and releases storage
space on demand. The example below shows how the \emph{insert} and \emph{remove} methods of the
list are implemented using this approach:

\scriptsize\begin{verbatim}
Link insert(Object obj) {
    Link link = Scenario::allocate(obj);
    Base::insert(link);
    return link;
}
Object remove(Link link) {
    Object obj = Scenario::get(link);    
    Base::remove(link);
    Scenario::free(link);
    return obj;
}
\end{verbatim}\normalsize

In hardware implementations, \emph{Scenario::allocate(obj)}, \emph{Scenario::get(link)},
and \emph{Scenario::free(link)} map to operations implemented in the \emph{Static Alloc} aspect. In
this scenario, the number of storage slots for links and objects is defined at synthesis-time and
allocation requests are just mapped to a free slot. In a software implementation, dynamic memory
allocation is available, thus, storage allocation can be handled by either the \emph{Static
Alloc} or the \emph{Dynamic Alloc} aspect, as shown in figure \ref{fig_hw_sw_scenarios}. 

The \emph{Dispatch} aspect is used, in \emph{HW Scenario}, to define an entry point for the
component so it will be compliant with HLS tools requirements. For the toll used in our case
studies (Calypto's CatapultC~\cite{Calypto:Catapult}), the top-level interface of the resulting
hardware block (port directions and sizes) is inferred from a \emph{single function signature}.
This function is defined by \emph{Dispatch} and receives a \emph{method id} as its first parameter,
interprets its value, performs the necessary type conversions and calls the appropriate method of
the component. The value returned by the called method is also inspected, converted if necessary and
assigned to one of the dispatcher output parameters. A dispatch mechanism is not necessary in
the software scenario since operations are requested using direct method calls.

Finally, it is worth mentioning that the aspects, scenario, and adapters are implemented using
static metaprogramming and are highly generic. The scenario to which the component is adapted is,
in fact, defined using metaprogramming, as shown in figure \ref{fig_hw_sw_scenarios}.  Special
template classes called \emph{Traits} are used to define which characteristics of each component is
activated. The code sample below shows an example of a \emph{Trait} class:

\scriptsize\begin{verbatim}
template <> struct Traits<Component> {
    static const bool hardware = true;
};
\end{verbatim}\normalsize

It defines that \emph{Component} has a \emph{hardware} characteristic that is used to
define which domain the component is on (hardware or software). In figure
\ref{fig_hw_sw_scenarios}, this characteristic is used to conditionally modify the scenario
adapter's base scenario. This decision is statically determined using a metaprogram. The
implementation of \emph{IF} metaprogram is shown below:

\scriptsize\begin{verbatim}
template<bool condition, typename Then, typename Else>
struct IF { typedef Then Result; };

template<typename Then, typename Else>
struct IF<false, Then, Else> { typedef Else Result; };
\end{verbatim}\normalsize

\subsubsection{Wrapping communication}
\label{sec:proposal:unified_design:stubs}

% In OOP the original structure will be ``disassembled'' if different objects in the
%same class hierarchy represent components that are to be implemented in different domains. For
%example, \emph{C2} is ``inside'' \emph{C1} in the OO model in Figure \ref{fig_tlm_vs_oop}, but, in
%the final implementation, \emph{C1} could be implemented as a hardware component while \emph{C2}
%could run in a software processor.

Issues related to communication cannot be completely handled using only the mechanisms described so
far. For example, in the OO model in Figure \ref{fig_oop_example}, an instance of \emph{C2} is an
attribute of \emph{C1}, thus \emph{C2} will be compiled/synthesized together with \emph{C1}.
However, if the designer intends to have instances of \emph{C1} and \emph{C2} as two independent
components implemented in different domains, then an additional mechanism is necessary. 

\fig{0.59}{fig_oop_example}{Simple OOP model showing composition}

\fig{0.58}{fig_remote_invocation}
{Communication between components in different domains. The leftmost components request
operations from the rightmost ones (the scenario adapters are omitted for simplicity).}

A way to overcome this issue is to use to use concepts from distributed object
platforms~\cite{Rincon:2009}. Figure \ref{fig_remote_invocation} illustrates possible interactions
between components \emph{C1} and \emph{C2}. The called component is represented in the domain of the
caller by a \emph{proxy}. When an operation is invoked on the component's proxy, the arguments
supplied are marshaled in a request message and sent through communication \emph{channel} to the
actual component. In the \emph{HW->SW} interaction, an \emph{agent} receives requests, unpacks
the arguments and performs local method invocations. The whole process is then repeated in the
opposite direction, producing reply messages that carry eventual return arguments back to the
caller. An \emph{agent} is not required by the \emph{SW->HW} interaction since the \emph{dispatcher
aspect} can play its role.

\figTC{.59}{fig_adesd_flow_v2}{Summary of the implementation flow}

Another issue is how to make these mechanisms transparent in the components' descriptions. An
efficient solution is to use template metaprograms to replace the definition of a component by its
proxy when necessary. For example, in the software domain, \emph{C2} can be defined as an empty
class that inherits from its actual implementation depending on the configuration defined by the
component's \emph{Traits}:

\scriptsize\begin{verbatim}
class C2 : 
  public IF<Traits<C2>::hardware, 
            C2_SW_Proxy, C2_Scenario_Adapter>::Result {};
\end{verbatim}\normalsize

There are still more implementation aspects to be considered. The mechanisms
proposed above are only general guidelines that can span several specific implementations. The
implementation of \emph{channels}, \emph{proxies} and \emph{agents} can be realized in several
different ways (e.g. specific using buses, DMA, \emph{Network-on-Chips}~(NoCs) ). In section
\ref{sec:evaluation} we describe our case studies and the chosen architecture to implement the
mechanisms above.

\subsection{Implementation flow summary}
\label{sec:proposal:summary}

Figure \ref{fig_adesd_flow_v2} summarizes a possible implementation flow. Aspects, scenarios, and
the unified implementation of components made up the inputs. Proxies and agents can be automatically
generated from the components' interface by a tool (EPOS syntactical analyzer~\cite{Froehlich:2001}
can be used to obtain the operation signatures of all components). Once the hardware/software
partitioning is defined (by the components' Traits), the adapted components are fed to either the
hardware or the software generation flow.

In the software flow, components are compiled along with EPOS. Apart of basic RTOS features, EPOS is
also responsible for the implementation of
the run-time support required by the mechanisms mentioned in section
\ref{sec:proposal:unified_design:stubs}. Software components that exist only in the
scope of hardware components are instantiated by this run-time support. When a hardware component
requests operations through a proxy, the software is interrupted and the run-time support handles
the communication between the proxy and the component's agent in software.

In the hardware flow, an HLS tool is used to generate RTL descriptions. These descriptions are
bound with the hardware platform library and fed to the RTL synthesis tool. The platform library
contains the components required to run the software (softcore processor, memories, and peripherals)
and the communication infrastructure that allows application's components to communicate with each
other. Details of the features available in both the EPOS and the platform library are given in the
description of our case study in the next section.

It is worth pointing out that this work focuses only on general implementation guidelines and not a
whole design methodology. Issues such as design space exploration and design verification are not
in the scope of this work.

\section{Evaluation}
\label{sec:evaluation}
In order to evaluate our approach, we have analyzed a PABX application from one of our
industry partners and designed some of its basic building blocks using the proposed implementation
guidelines. We've selected and reimplemented the following components using unified C++
descriptions: a \textit{Dual-Tone Multi-Frequency}~(DTMF) detector~\cite{Xinyi:2010}, an IMA ADPCM
encoder/decoder~\cite{ITUT:ADPCM}, and the EPOS's scheduler, which was described in section
\ref{sec:proposal:unified_design:unified_descriptions}. The use of the EPOS's scheduler as a case
study is motivated by its complex behavior. A scheduler may perform operations both synchronously
(upon request by another component) or asynchronously (by preempting the execution of another
component). Furthermore, a hardware-implemented scheduler has deterministic execution time,
eliminating jitter and improving the support of real-time applications.

Figure \ref{fig_pabx_soc} shows the final block diagram of the PABX SoC. It is a NoC-based SoC and
uses the \emph{RTSNoC}~\cite{Berejuck:2011} as the core communication infrastructure. Each hardware
component is implemented as a single node connected to the NoC. Software components run in a
\emph{processing node} that consists of a MIPS32 core and memories. The SoC also contains an
\emph{IO peripheral node}. The components selected as case studies are highlighted and are
shown appear as hardware and software, since they can move between both domains depending on the
final hardware/software partitioning.

\fig{.5}{fig_pabx_soc}{PABX SoC block diagram}

The upper part of figure \ref{fig_pabx_soc} shows the structure of the software domain. EPOS's
\emph{Component Manager} implements the runtime support mentioned in section
\ref{sec:proposal:summary}. Operations request from software to hardware are marshaled and sent
through the \emph{NoC proxy}. Requests in the opposite direction are captured by the \emph{Component
Manager} which forwards the operation to the target component in software (it implements the
software agents described in section \ref{sec:proposal:unified_design:stubs}).

In order to demonstrate that unified implementations can be as efficient as dedicated
implementations, we compare software scenario-adapted components against the original C
implementations (C++ for the scheduler), and hardware scenario-adapted components against components
manually tailored for high-level synthesis. Table \ref{tab_sw_metrics_reduced} compares the original
software-only C (ADPCM and DTMF) and C++ (Scheduler) codes before being modified into unified C++
descriptions. The footprints were obtained from the object files generated after compiling each
component in isolation (except the scheduler, which is the core component of EPOS, thus it does
not makes sense to compile it in isolation), while the execution times were measured from the
running application using a timestamp counter. Everything was compiled with \emph{gcc 4.0.2} using
\emph{level 2} optimizations. 

The results show an average increase of about 7.2\% in code size when we use the unified C++, while
the average execution time increased by about 7.7\%. In the case of the scheduler, the additional
overhead can be explained by the introduction of the \emph{option types} and the use of a more
generic mechanism for storage allocation (the \emph{Static/Dyn Alloc} aspect). For the remaining
case studies, most of the overhead comes from additional code required to encapsulate the behavior
into more reusable OOP classes with a clear method interface.

Table \ref{tab_hw_metrics_par_slices} compares the hardware generated from
unified C++ against hardware-only C++. \emph{Calypto's CatapultC} HLS tool was used to obtain RTL
descriptions of the components. The descriptions were then synthesized using \emph{Xilinx's ISE
13.1} targeting a \emph{Virtex6 XC6VLX240T} FPGA. CatapultC was configured to minimize circuit area
considering a target operating frequency of 100 MHz (the operating frequency of the SoC). ISE was
also configured to minimize circuit area and its place-and-router to map only to look-up tables and
registers, so we can use a single metric to compare area (the number of \emph{FPGA slices}).

The results show that the difference in area and performance depends on the case study. The maximum
number of clock cycles required to perform an operation tends to increase due to extra cycles
required by the coupling between proxy and the agent implemented by the \emph{Dispatch} aspect.
Only the unified implementation of the DTMF detector was not able match the target operating
frequency. However, these are only estimations given by ISE. After the final integration in the
SoC, we have obtained a fully routed design without violating any timing constraint. When
considering area, the unified C++ yielded smaller circuits in two of the case studies. This is an
unpredicted result since, the \emph{Dispatch} aspect was expected to introduce an additional area
overhead in the scenario-adapted implementations. A possible explanation can be related to the
influence of the dispatcher's regular structure over HLS optimization algorithms which generates
designs with patterns that can further affect the final RTL synthesis and FPGA placement algorithms.

Finally, we provide the total software and hardware footprint of our
PABX SoC considering different hardware/software partitionings of our case studies. Table
\ref{tab_soc_results} shows the total footprint considering the following partitionings: all the
case studies are in software; all the case studies are in hardware; and a
hybrid partitioning in which only the scheduler is in software. As we can see in table
\ref{tab_soc_results}, the hybrid partitioning resulted in a better tradeoff between software and
hardware size.

\tabTC{tab_sw_metrics_reduced}
{Software-only implementations X Unified implementations adapted to the software domain}

\tabTC{tab_hw_metrics_par_slices}
{Hardware-only C++ X Unified C++ adapted to the hardware domain}

\tabTC{tab_soc_results}{SoC area footprint. In the hybrid partitioning, the Scheduler is in
software while the ADPCM codec and the DTMF detector are in hardware.}


\section{Conclusion}
\label{sec:conclusion}

In this paper we have explored a methodology based on AOP and OOP concepts in order to produce
unified implementations of hardware and software components. Specific characteristics of both
domains are captured as separated aspects and weaved with the unified source code only in the final
stages of the design process. Also, our mechanisms are implemented using only standard C++ features,
thus assuring compatibility with different C++/C-based HLS tools. Furthermore, we have
demonstrated the utility of our approach by redesigning some functional blocks of a PABX system.
The resulting components confirmed that a unified code can be almost as efficient as a
software-only one. The generated hardware was slightly slower than its hand-coded counterpart in
terms of the number of clock cycles required to perform an operation, while requiring less FPGA
resources. Such figures confirm that, through careful design, we can use C++ as a unified language
to implement both hardware and software in an elegant and straightforward way.

%\section*{Acknowledgments} Pizani for the scheduler, Berejuck for the NoC and PABX support. CAPES
%RHTVD grants ...

%\newcommand{\bibfont}{\footnotesize}
%\bibliographystyle{abbrv}
\bibliographystyle{IEEEtran}
\scriptsize
\bibliography{paper}

\end{document}
