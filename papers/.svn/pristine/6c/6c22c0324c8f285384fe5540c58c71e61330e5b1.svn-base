Thank you for your submission to HotSWUp 2008. On behalf of the program 
committee,
we would like to inform you that your paper has been *conditionally* 
accepted for
presentation at the workshop.  This is due to major issues pointed out 
by the
reviewers (e.g., English problems, or too much emphasis on your 
previously published
work). You will have until September 29 to address the reviewers' 
comments. Shortly
after September 29, a "shepherd" will read your revised paper and decide 
whether you
have addressed the reviewers' points satisfactorily. Based on the 
shepherd's
decission, your paper will be finally accepted or rejected.

Best regards,


Tudor Dumitras, Danny Dig, and Iulian Neamtiu


---------------------------------------------

Paper: 6
Title: An Operating System Infrastructure for Remote Code Update in 
Deeply Embedded
Systems


-------------------- review 1 --------------------

PAPER: 6
TITLE: An Operating System Infrastructure for Remote Code Update in 
Deeply Embedded
Systems
 
OVERALL RATING: 3 (Borderline)   
----------------------- REVIEW --------------------

--- Summary of the paper (sent to the authors)
*** SUMMARY:
This paper presents an infrastructure for dynamic code upgrades in 
embedded systems.
The infrastructure is a relatively simple extension of an existing 
operating system.
Although it is not completely clear, the idea seems to be that an entire 
"component"
is upgraded at a time.  All method invocations (which are apparently the 
only way to 
reference memory outside a component) go through a level of indirection.  
This 
indirection is the hook used by the upgrade infrastructure to enable 
dynamic 
upgrades.

--- Evaluation of the paper, including points in favor
--- and against(sent to the authors)
*** EVALUATION:
On the positive side, efficient dynamic upgrades of deeply embedded 
systems is an 
important topic.  The infrastructure nicely enables such upgrades.  The 
evaluation 
section quantifies some of the overheads of the approach using simple 
benchmarks.

On the negative side, the contribution made in this paper seems to be 
relatively
small; most of the enabling infrastructure was already built into EPOS 
for other
reasons.  Moreover, it is difficult to assess how good the approach is 
from the
results presented.  For example, the evaluation talks about up to 100% 
performance
overheads.  Is this a good or bad result?  I guess that the answer 
depends on how
often such expensive operations are performed in practice.

--- Comments for improvement (e.g., constructive feedback on
--- how this work can be improved for a conference 
--- submission). Sent to the authors.
*** COMMENTS FOR IMPROVEMENT:
In my opinion, this paper could be improved with a larger contribution; 
an 
evaluation based on a real embedded system (rather than synthetic 
benchmarks); 
and improvements to its presentation.  For example, it would be 
interesting to
know how problematic upgrades are handled (e.g., a component upgrade 
that
removes a method used by other components).

Minor points:
* The paper has a few typos that you can easily fix.  I'll only mention 
one because
it is repeated multiple times: you probably mean "invoke" instead of 
"invocate".

* Section 3.1 and Figure 1 confuse more than explain.  Why get into all 
the jargon?
Figure 2 is presented at a much more useful level of abstraction.

* In Table 2, points and commas should be exchanged.

* The term "static metaprogramming" comes out of nowhere late in the 
paper.  Is this
any different than "metaprogramming" as mentioned earlier in the paper?  
How exactly
are all framework dependencies solved during compilation time? 


-------------------- review 2 --------------------

PAPER: 6
TITLE: An Operating System Infrastructure for Remote Code Update in 
Deeply Embedded
Systems
 
OVERALL RATING: 3 (Borderline)   
----------------------- REVIEW --------------------

/* SUMMARY */
The paper describes how the meta-infrastructure in EPOS can be
leveraged to achieve component updates with memory/execution 
overhead that is smaller than in other embedded runtime systems.

/* EVALUATION */
A relevant aspect of the paper is the focus on requirements
for software update that comes specifically from embedded systems.
This is positive in terms of looking at ways of performing
updates in constrained environmens but one may argue that
the lessons from such work do not add much value to the
generic (non-embedded) scenario. 
The system doesn't support the distribution of new code yet,
so the experimental part of the paper is somewhat restricted
in its analysys.

/* COMMENTS FOR IMPROVEMENT */

The writing is reasonable, A careful reading of the paper
should be enough to get rid of small errors, such as:

* several occurrance of "related works" when it should be
"related work"; also "informations" should not be in plural, "bytecodes 
format"
should be "bytecode format"

* several occurrances of a plural being used when we want
a possessive, for example "the nodes energy consumption"
when the authors probably mean "the node's energy consumption",
"messages loss" should be "message loss", "methods table" should be
"method table" or "method's table", "As the methods computation"  ->
"As the method's computation"

* "The figure ..." should be "Figure ..."

* parametrized should be parameterized

* a couple of places with grammar errors such as "This allow". 


-------------------- review 3 --------------------

PAPER: 6
TITLE: An Operating System Infrastructure for Remote Code Update in 
Deeply Embedded
Systems
 
OVERALL RATING: 5 (Strong accept (would champion the paper))   
----------------------- REVIEW --------------------

--- Summary of the paper (sent to the authors)
/* SUMMARY */

This paper describes a new framework (called metaprogramming framework) 
to
supporting remote code updates in sensor networks. The evaluation 
consists of
running a test application on the Mica platform and benchmarking the 
approach
against corresponding results with MantisOS and SOS. 

--- Evaluation of the paper, including points in favor
--- and against(sent to the authors)
/* EVALUATION */

The paper does have some nuggets. The authors appear to know their field 
fairly
well, and have implemented a framework/middleware to support remote code 
updates.
Obviously, this being a workshop paper, the results are fairly 
preliminary, but
nevertheless, it is refreshing and commendable that the authors have 
actually
benchmarked their approach against two contemporary approaches (SOS and 
MantisOS).
My biggest concern is readability and the use of the English language. I 
think that
the paper's writing needs considerable improvement. Also, I am sure that 
the authors
know, and can articulate, the novel ideas behind their approach. I just 
don't see
them in the paper. I think that it's a matter of getting the authors to 
write down
the novel ideas and research contributions clearly, and also to explain 
why their
approach is different/superior. If the paper can be shephered, I would 
bet that it
could made to read really well. I am particularly impressed by the 
benchmarking
effort,!
  especially for a workshop paper.  I would even go so far as to 
encourage the
authors to complete the distributed part of their remote code-update 
protocol (see
the Future Work section) and to submit this to IPSN or some other top 
conference. 

--- Comments for improvement (e.g., constructive feedback on
--- how this work can be improved for a conference 
--- submission). Sent to the authors.
/* COMMENTS FOR IMPROVEMENT */

Introduction:
There are several remote code-update protocols out there, including MNP, 
MOAP,
Deluge, Infuse, Sprinkler, and even secure versions of these, such as 
Sluice,
SecDeluge, etc. The introduction part of any paper should really 
emphasize what
makes that paper's work different. I am not sure, after reading the 
introduction,
what makes your work different. More specifically, traditionally, the 
code-updates
research in sensor networks has indeed focused on being sensitive to 
memory
consumption, CPU overhead and latency. So, those goals, in themselves, 
are not
anything new. It's okay for your research to have the same goals (memory
consumption, latency, overhead, security) as other people do in the 
field, but you
should articulate what differentiates your work, i.e., what your 
specific research
contributions are, what is innovative/different in your approach (as 
compared to the
other approaches that have gone before you), and what precise problem 
you are
attempting to solve. 

I would also add that you do want to refer to one of the terms, "network
reprogramming", commonly used in the field to describe your work. You do 
want to
have your work cited by others, ultimately, and it's better to use 
accepted
terminology so that people searching on specific keywords are likely to 
find your
papers. Perhaps you could state, "remote code updates (or network 
reprogramming, as
it is known in the wireless sensor networks domain)", the first time you 
introduce
the concept; after that, you can simply stick to "code updates" in the 
rest of your
paper. 

Related Work:
The related work section was well written and well organized, in terms 
of
classifying the available literature into three categories: virtual 
machines, data
dissemination protocols and operating systems. Your related work is 
missing some of
the research in the field. I would recommend that you look at two 
surveys of code
updates that are known in the field. Look at
[1] http://www.ee.ucla.edu/~simonhan/simon_paper/ijnm05.pdf
(official citation is
http://www3.interscience.wiley.com/journal/110550990/abstract?CRETRY=1&SRETRY=0)
[2] http://www.ece.cmu.edu/~planigan/research/cmu-isri-05-122.pdf
(not sure if there is an official citation, other than technical report)

Infrastructure for Remote Code Update:
There is typo in the first paragraph: "the components replacement" 
should be
replaced by "the components' replacement" (apostrophe missing).

In Section 3.1, what do you mean by "receives a system abstraction as a 
parameter."
This was not clear to me at all. Please provide an example. What sorts 
of system
abstractions do you support, and what does it mean to receive an 
abstraction as a
parameter? Typically, objects, data structures, functions can be 
received as
parameters, either passed-by-reference or passed-by-value. It's not 
clear how an
abstraction (which is a concept, not a realization) can be passed as a 
parameter,
unless the term "abstraction" has been redefined by you elsewhere. 

In the second paragraph of Section 3.1, replace "responsible to verify" 
with
"responsible for verifying". 

Figure 1 suggests that you are implementing some sort of middleware, 
rather than a
pure operating system (which, to me, implies something that is 
single-node
operation, rather than distributed operation). Is your metaprogrammed 
framework
essentially middleware? Why not simply use the term "middleware", unless 
your
framework purports to do something different?


I would have liked to have seen an Assumptions section that outlined 
various things.
For example, are you assuming that the old and new hardware are 
unmodified? Are you
assuming that the old and new hardware and software are configured with 
the same
endianness? Are you assuming that there is no virtual memory running on 
the system?
What kinds of code-updates can you handle? Which ones are outside your 
scope? Some
of the memory-indirection procedures you use can be affected by 
assumptions of that
sort. 

Preliminary Results: 
I would recommend not using the word "prove" in that first sentence, but 
rather, the
word "evaluate" instead. I believe that you mean "a dining philosopher's
application" rather than "a philosopher's dinner application". You 
mention that you
use this test application, but what is the nature of the code-update? 
How many extra
bytes of memory are required to support a new component method? 

I appreciate the fact that you benchmark your framework against SOS and 
MantisOS. I
would have liked to have read more on this, e.g., how difficult/easy was 
it to
implement the test application on these other two approaches, in a way 
that made it
easy for you to benchmark your approach against them? 

In this section, you use phrases like "an overhead of 100%". It's not 
clear what
this is a percentage of. Is it of the original latency? Also, overall, 
how long does
it take to perform a remote code-update? The latency numbers here break 
down the
code-update latency numbers on a single node. How does this perform when 
you have to
update N nodes? 

The last sentence of Section 4 is cryptic, and I am not sure how to 
interpret it.
Also, do you really believe, intrinsically, that most sensor nodes and 
embedded
systems will support runtime memory allocation/deallocation? In the 
automotive
world, for instance (you cite the automotive domain up front, and also 
provide a
citation in your list of references), most code is statically compiled 
and
malloc()'s are avoided. 

Typos:
There is a large number of typographical errors in this paper. I am not 
listing all
of them here since that would take a lot of time. However, the ones 
listed below
give you the general idea. These typos should be fixed. 
* Sentence 2 of Section 3.2: "invocation ..... pass" -> "invocation .... 
passes"
* Sentence 3 of Section 3.2: "After the method execution" -> "After the 
method's
execution"
* Section 3.2: "aware of component's" -> "aware of the component's"
* Section 3.2: "created in the system boot" -> "created during the 
system's
bootstrapping" (unless you meant something else?)
* Section 3.2: "updates the new methods addresses received" -> "updates 
the received
addresses of the new methods"
* Section 3.2: "before and after of a component update" -> "before and 
after a
component update"
* Section 3.2: "there are an extra memory consumption" -> "there is 
additional
memory consumption" OR "there is extra memory consumed"
* Section 4: "invocated" -> "invoked"
* Section 4: "presented an overhead" -> "incurred an overhead"
* Section 4: "methods computation time increase" -> "method's 
computation time
increases"
* Section 4: "solves all framework dependencies" -> "resolves all 
framework
dependencies" (what kinds of dependencies are these? symbol 
dependencies? library
dependencies? other?)
* Section 4: "values average obtained in 1000 execution" -> "average of 
the values
obtained in 1000 experimental runs"
* Section 5: "composed by" -> "composed of"
* Section 5: "low consumption" -> "low memory consumption"
* Section 5: "solve all dependencies" -> "resolve all dependencies"
* Section 5: "in compilation time" -> "at compilation time"
* Section 5: "future works" -> "future work"
* Section 5: "sending just the changes between the new and old codes" ->
"disseminating just the incremental differences between the new and old 
versions of
the code" 

