%\documentclass{acm_proc_article-sp}
%\documentclass[10pt,conference,final]{IEEEtran}
%\documentclass[preprint,10pt]{sigplanconf}
%\documentclass[10pt]{sigplanconf}
\documentclass[letterpaper]{sig-alternate}
\pdfpagewidth=8.5in
\pdfpageheight=11in

\usepackage[latin1]{inputenc}	% for Latin languages
\usepackage[T1]{fontenc}	% for ISO and UTF characters
\usepackage[english]{babel}	% for multilingual support
\usepackage{graphicx}
%\usepackage{multirow}
%\usepackage[caption=false,font=footnotesize]{subfig}
%\usepackage{natbib}
\usepackage{color}
\definecolor{Red}{rgb}{.9,0,0}

\include{utils} %new commands 

%\appto\bibfont{\itshape}

\begin{document}

\hyphenation{sched-ul-er plat-form de-sign meth-od-ol-o-gy sce-nar-i-o-in-de-pend-ent}

%\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden -
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden


\title{Unified Design of Hardware and Software Components}

%\numberofauthors{2}
%\author{
%  \alignauthor
%  Tiago Rogério Mück
%  \alignauthor
%  Antônio Augusto Fröhlich
%  \and\alignauthor
%  \affaddr{Software/Hardware Integration Lab}\\
%  \affaddr{Federal University of Santa Catarina}\\
%  \affaddr{Florianópolis, Brazil}
%  \email{\{tiago,guto\}@lisha.ufsc.br}
%}

\author{\alignauthor
Authors omitted for blind review}


\maketitle

%Original
%\begin{abstract}
%The increasing complexity of current embedded systems applications is pushing their design to
%higher levels of abstraction, leading to the convergence between hardware and software development
%methodologies. In this paper we aim to close the gap between hardware and software design by
%developing a methodology that handles both domains in a unified fashion. We leverage on AOP and OOP
%techniques in order to provide unified C++ descriptions of components. By simply applying
%aspect programs, these descriptions can be both compiled to software binaries or synthesized to
%dedicated hardware using high-level synthesis tools. Our results show that, when compared to
%dedicated software (C) and hardware (VHDL) components, our strategy leads to an improved tradeoff
%between efficiency, flexibility and reusability.
%\end{abstract}

%Reduced abstract (100 words)
\begin{abstract}
The increasing complexity of embedded systems applications is leading to a convergence between
hardware and software development. In this paper we aim to close the gap between
hardware and software design by developing a methodology that handles both domains in a unified
fashion. We leverage on AOP and OOP techniques to provide unified C++ descriptions of components.
These descriptions can be both compiled to software or synthesized to dedicated hardware using
high-level synthesis tools. Our results show that, when compared to dedicated software (C) and
hardware (VHDL) development, our strategy leads to an improved tradeoff between efficiency,
flexibility and reusability.
\end{abstract}



\category{B.6.3}{LOGIC DESIGN}{Design Aids}[Automatic synthesis]

\terms
Design, Languages

\keywords
System-level design; Unified design; High-level synthesis


\section{Introduction}
\label{sec:introduction}
       
Embedded systems are becoming increasingly complex as the advances of the semiconductor industry
allow the use of sophisticated computational resources in a wider range of applications. Depending
on the application's requirements (e.g. performance, energy consumption, cost, etc.), the
development of such systems may encompass an integrated hardware and software design that can be
realized by several different computer architectures, ranging from simple 8-bit microcontrollers to
complex \textit{multiprocessor system-on-chips}~(MPSoCs).

In order to deal with this complexity, embedded system designs are being pushed to higher levels of
abstraction, such as \emph{system-level design}. In this scenario, a convergence between hardware
and software design methodologies is desirable, since a unified modeling approach would allow one
to take decisions about hardware/software partitioning later in the design process, maybe even
automatically. In the last few years, advances in \textit{electronic design automation}~(EDA) tools
are allowing hardware synthesis from descriptions at the behavioral level~\cite{Calypto:Catapult}.
These tools allow designers to describe hardware components using languages like C++, and
higher-level mechanisms, such as \textit{Object-Oriented Programming}~(OOP) techniques. The focus of
these tools, however, is hardware synthesis, and they do not provide a clear design methodology for
developing components which could be implemented as both hardware and software.

Aiming to narrow this gap and move towards a real unified design approach, in this paper we describe
some design guidelines and mechanisms which allow the implementation of both hardware and software
components using a single C++ description. The principles of our design methodology are based on
OOP and \textit{aspect-oriented programming}~(AOP) concepts, defining a domain engineering strategy
which allows us to clearly separate the core behavior and structure of a component from the aspects
which are specific of a software or a hardware scenario. In order to generate descriptions that can
be efficiently synthesized to hardware or compiled to a software binary, the implementation of both
the components and the mechanisms which adapt them for the final execution scenario make extensive
use of C++\emph{generic programming}~\cite{Czarnecki:2000} techniques such as \emph{static
metaprogramming}. To evaluate the efficiency of our approach, we present the implementation of a
\textit{Private Automatic Branch Exchange}~(PABX) SoC of which some components were redesigned using
our unified design strategy.

The remaining of this paper is organized as follows: section \ref{sec:related_work} presents a
discussion about works related to the integration of the hardware and software design flows; in
section \ref{sec:proposal} we discuss the aspects that are part of a software or a hardware
scenario and present our approach for their proper separation; section \ref{sec:evaluation}
describes our case studies and shows our experimental results; and section \ref{sec:conclusion}
closes the paper with our conclusions.

\section{Related work}
\label{sec:related_work}
Several design methodologies were proposed in order to provide more tightly coupled
hardware and software design flows. Most of them are based on the concept of building
a system by assembling pre-validated components. The \emph{Metro-II}~\cite{Davare:2007} framework
follows the \emph{Platform-based design} (PDB) \cite{Vincentelli:2001} methodology, and propose the
use of a metamodel with formal semantics to capture designs. An environment to support simulation,
formal analysis, and synthesis is also provided. However, this methodology does not define a clear
guideline to design new components which can be reused in a wide range of applications. Also, the
hardware/software partitioning is defined in the early design stages and is limited by the platform
specification. The \textit{Application-driven Embedded System Design}~(ADESD)~\cite{Froehlich:2001}
elaborates on OOP and AOP concepts, defining a domain engineering strategy focused on the production
of scenario-independent components. This was explored by the idea of Hybrid
Components~\cite{Marcondes:2009}, in which a common architecture for the implementation and
communication between components living in hardware and/or software was developed. However,
components implemented in different domains still follow distinct design flows.

In order to overcome these issues, one must focus on closing the gap between software and hardware
design. State-of-the-art EDA tools support hardware synthesis from high-level C++/C-based constructs
and several works have already demonstrated the applicability of \textit{high-level synthesis}~(HLS)
for implementing hardware components~\cite{Fingeroff:2010}. Our aims are different however. We
want to describe algorithms in a high level of abstraction, but those should be implementable in
hardware as well as in software, and with performance close to software-only and hardware-only
implementations. On this track, the OSSS+R methodology~\cite{Schallenberg:2009} improves
\textit{register transfer level}~(RTL) models in SystemC by adding new language constructs to
support synthesizable polymorphism and high-level communication. However, hardware/software
partitioning must still be done in the beginning of the design process~\cite{Gruttner:2008}, and the
inclusion of non-standard language constructs reduces the compatibility of the design with 
available compilers and hardware synthesis tools. In the \emph{Saturn}~\cite{Mischkalla:2010} design
flow, the authors propose \emph{SysML}, an extension of UML for system-level design, and a tool
which
generates C++ for software and RTL SystemC for hardware. However, Saturn has the same limitations of
OSSS+R described previously.

SystemCoDesigner~\cite{Keinert:2009} is a tool which integrates a HLS flow with
design space exploration. The design entry of SystemCoDesigner is a data flow model implemented
using a SystemC-based library. After design space exploration, this model can be either
converted to synthesizable SystemC or to C++ for software compilation. However, as the authors
claim, SystemCoDesigner targets mostly data-flow-based applications. Directions regarding a more
general deployment are not provided. The System-on-chip environment~(SCE)~\cite{Rainer:2008} takes
SpecC models as input and provides a flow similar to the one of SystemCoDesigner, but without
automatic design space exploration.

Other works focus mainly on interfacing software and hardware. The \emph{HThread}
project~\cite{Anderson:2007} provides a unified interface for both domains. A task performed in
hardware is seen with the same semantics as a software thread, and a system call interface is
provided to hardware components. However, an enormous gap still exists between the way the hardware
and software threads themselves are implemented. The work of \textit{Rincón et
al}~\cite{Rincon:2009} is based on concepts from distributed object platforms such as CORBA and Java
RMI and provides a tool which generates the communication glue necessary so that hardware and
software components can communicate seamlessly.
              
\section{Unified hardware/software design}
\label{sec:proposal}

%To save space, this paragraph can be removed or merged with the next one
HLS tools allow for hardware synthesis from algorithms described in languages such as C++. When
aiming at this goal, the implementation of the algorithm itself is usually very similar to what is
seen in software. However, at component level, several aspects arise which distinguish descriptions
aiming at hardware and software. In the following sections we first discuss these aspects. Then, we
present our strategy for the separation of hardware and software concerns and how we achieved
efficient and flexible unified C++ descriptions.

%This subsection can be merged with the top-level one if the above paragraph is removed
\subsection{Differences between hardware and software}
\label{sec:proposal:hw_sw_differences}

%Table \ref{tab_comm_interface} summarizes the most common communication bahaviors between
%components. 
In the software domain, components may be objects which communicate using method invocation
(considering an OOP-based approach), while in the hardware domain, components communicate using
input/output signals and specific handshaking protocols. For communication through different
domains, the software must provide appropriate \textit{hardware abstraction layers}~(HAL) and
\textit{interrupt service routines}~(ISR), while the hardware must be aware that it is requesting a
software operation.

%\tab[ht]{tab_comm_interface}
%{Usual communication bahvior between components implemented in different domains. The \emph{Master}
%requests operations from the \emph{Slave}.}

In some system-level approaches, such as \textit{Transaction-level modeling}~(TLM)~\cite{Cai:2003}
components communicate by reading and writing data from/to \emph{channels}. Latter in the design
process, these channels can be mapped to buses, point-to-point signals, or function calls , whether
the communicating components are in hardware or in software. This strategy provides a clear
separation between communication and behavior, but it is still too hardware-oriented since it
basically provides higher-level versions of RTL signals. Figure \ref{fig_tlm_vs_oop} highlights this
by comparing a TLM and a more software-oriented OO model of the same system. In the OO model, a
component can be either implemented as a global object (\emph{C1} and \emph{C3}) or as a part of
another object (\emph{C2}). Also, components which perform more than one operation and have complex
interactions with another components may not be easily modeled using the data-flow semantics shown
in the left side of Figure \ref{fig_tlm_vs_oop}.

\fig{.6}{fig_tlm_vs_oop}{Communication between components in transaction level (left) and
object-oriented (right) models.}

\figTC[ht]{.6}{fig_adesd_flow}{Proposed embedded system design flow.}

However, the structure of TLM-like models is much closer to final physical implementations. In OOP
the original structure will be ``disassembled'' if different objects in the same class hierarchy
represent components that are to be implemented in different domains. For example, \emph{C2} is
``inside'' \emph{C1} in the OO model in Figure \ref{fig_tlm_vs_oop}, but, in the final
implementation, \emph{C1} could be implemented as a hardware component while \emph{C2} could run in
a software processor. In this paper we propose a solution for this problem since we focus on an
OOP-based methodology. This is explained in section \ref{sec:proposal:unified_design:stubs}.

Another important aspect that distinguishes hardware from software is resource allocation. The
hardware is frozen and common software features, such as dynamic memory allocation, are not
available.
Therefore, in code suitable for hardware synthesis, all data structures must reside in statically
allocated memory. Some works focus on this problem by relying on dynamic reconfiguration
technologies of FPGAs to support hardware components instantiation at run-time~\cite{Abel:2010}.
However, this is not the focus of our current work. We aim at providing a more general methodology
for describing components.

\subsection{Defining C++ unified descriptions}
\label{sec:proposal:unified_design}

A unified description of components can be obtained from algorithm implementations that are largely
separated from hardware and software scenario details. This can be achieved through careful domain
engineering and system design. A related work~\cite{Pizani:2011} have shown how the
ADESD~\cite{Froehlich:2001} methodology was used to provide a unified description of a resource
scheduler. ADESD elaborates on commonality and variability analysis---the well-known domain
decomposition strategy behind OOP---to add the concept of aspect identification and separation at
early stages of design. It defines a domain engineering strategy in which dependencies from
specific scenarios are captured as different aspects, thus enabling components to be reused on a
variety of execution scenarios with the application of proper aspects.

In this paper we also demonstrate how ADESD's artifacts can be used to provide C++ unified
descriptions.
The design flow in Figure \ref{fig_adesd_flow} shows some aspects of our proposed approach. The
input for the design flow is a scenario-independent C++ description of the components (a). The next
step (b) is the aspect weaving process in which the components are adapted to the target execution
scenario (hardware or software). Then, the hardware/software partitioning is defined along with the
communication interface of components (c). Finally, the final platform is generated (d). The next
sections explain each step in more details.

\subsubsection{Components implementation}
\label{sec:proposal:unified_design:unified_descriptions}
C++ code unified and suitable for automatic implementation in both hardware and software must
follow a careful design process so it will not contain aspects specific of hardware or software.
To illustrate how ADESD yields such components, we will describe in more details one of our case
studies: the design and unified implementation of the EPOS~(\textit{Embedded Parallel Operating
System})~\cite{Froehlich:2001} thread scheduler. EPOS is a case study on which the design artifacts
proposed by ADESD were implemented and validated. The OS is implemented in C++ and leverages on
\emph{generic programming}~\cite{Czarnecki:2000} techniques such as \emph{static metaprogramming} in
order to achieve high reusability with low overhead. EPOS's domain engineering simplified our work
by providing a good \emph{separation of concerns} around the scheduler. Figure
\ref{fig_epos_scheduler} shows a simplified class diagram of the scheduling-related classes in EPOS.

\fig{.6}{fig_epos_scheduler}{Simplified class diagram of scheduling-related classes in EPOS.}

The \emph{Scheduler} class is responsible only for keeping ordered queues, with the ordering defined
by the scheduling criterion. An object of the \emph{Scheduler} class also allows its callers to
insert and remove clients from the queues, as well as to get the current and next owners of the
resource. In our case study, we implemented a scheduler for threads. However, the scheduler code is
largely independent of the type of resource being scheduled (in fact, \emph{Scheduler} is a
\emph{class template}). Furthermore, concerns such as timing interrupt generation and context
switching are handled separately by the OS. 

Among all classes in Figure \ref{fig_epos_scheduler}, we've adapted the original implementation of
the
\emph{Scheduler} class (and also its base classes), so that it can now serve as input for both
hardware and software implementation flows. These adaptations were necessary not due to specific
hardware or software aspects, but due to some limitations of HLS tools. The main limitation is
related to \emph{pointers}. Pointers have no intrinsic meaning in hardware. They are mapped by HLS
tools to indices of the storage structures to which they point. Thus, \emph{no null or otherwise
invalid pointers} are allowed in the source code. However, the original scheduler implementation
used null pointers to report failures. To avoid this, we've changed the code to utilize \emph{option
types}. An option type is a container for a generic value, and has an internal state which
represents the presence or absence of this value. We implemented an option type in the C++ class
template \emph{Maybe\textless T\textgreater}, which has the following constructors:

\scriptsize\begin{verbatim}
Maybe(): _exists(false), _thing(T()){}
Maybe(T obj): _exists(true), _thing(obj){}
\end{verbatim}\normalsize

One constructor represents the absence of a value in the container while the other represents its
presence. By replacing all occurrences of simple pointers (T*) in the scheduler code with
\emph{Maybe\textless T*\textgreater} values, we completely avoided passing invalid pointers around. 

\subsubsection{HW/SW aspects encapsulation}
\label{sec:proposal:unified_design:aspects}
Dependencies observed during domain engineering are captured as \emph{aspects}, thus enabling
components to be reused on a variety of execution scenarios. This aspect weaving is performed by
constructs called \emph{Scenario adapters}\cite{Froehlich:2000}. Scenario adapters were developed
around the idea of components getting in and out of an execution scenario, allowing actions to be
executed at these points. Figure \ref{fig_scenario_adapter} shows how this is achieved. The
\emph{Scenario} class represents the execution scenario and incorporates, via aggregation, all
of the aspects which define its characteristics. The adaptation of the component to the scenario is
performed by the \emph{Scenario\_Adapter} class via inheritance. 

\fig{.33}{fig_scenario_adapter}{Component adaptation using a scenario adapter.}

The upper part of Figure \ref{fig_adesd_flow}b shows how we have used scenario adapters to isolate
aspects related only to hardware implementations. The aspects \emph{Static Alloc} and
\emph{Dispatch} are responsible, respectively, for storage allocation and method call dispatch. The
former is a storage allocator used to deal with the absence of dynamic memory allocation in
hardware.
Handling memory allocation externally is only possible because our components implement solely their
\emph{core behavior}. For example, the \emph{List} class (Figure \ref{fig_epos_scheduler}) is a
linked list, but it is not responsible for the allocation of space for links and the objects it
stores. It implements only the list algorithms and deals with references to such elements.
Therefore, all components operations go through the allocator which reserves and releases storage
space on demand. Finally, the \emph{Dispatch} aspect is used to define an entry point for the
component so it will be compliant with HLS tools requirements. For our specific case study 
(Calypto's CatapultC~\cite{Calypto:Catapult}), the top-level interface of the resulting hardware
block (port directions and sizes) is inferred by the tool from a \emph{single function signature}.
There must be only one function in the code with the pragma \emph{hls\_design top}. This function
receives a \emph{method id} as its first parameter, interprets its value, performs the necessary
type conversions and calls the appropriate method of the component. The value returned by the called
method is also inspected, converted if necessary and assigned to one of the dispatcher output
parameters.

The lower part of Figure \ref{fig_adesd_flow}b shows the software scenario aspects. A dispatch
mechanism is not necessary since operations are requested using direct method calls. Also, storage
allocation can now be handled by either the \emph{Static Alloc} or the \emph{Dynamic Alloc} aspect.

Finally, it is worth mentioning that the aspects, scenario, and adapters are implemented using
static metaprogramming and are highly generic. That is, they are C++ class templates, parameterized
by the adapted component and the size of the pre-allocated storage space.

\subsubsection{Wrapping communication}
\label{sec:proposal:unified_design:stubs}
Issues related to communication cannot be completely handled using only the mechanisms described so
far. For example, in the OO model in Figure \ref{fig_tlm_vs_oop}, the \emph{C2} is an attribute of
\emph{C1}, thus \emph{C2} will be compiled/synthesized together with \emph{C1}. If the designer
intends to have
\emph{C1}, \emph{C2}, and \emph{C3} as three separated and independent components, an additional
mechanism is necessary. 

One of the ways to overcome these issues is to use C++ templates to replace the definition of
\emph{C2} inside \emph{C1} by a \emph{stub} (step \emph{(c)} in Figure \ref{fig_adesd_flow}). This
\emph{stub} is a proxy to \emph{C2} and is responsible for forwarding operation requests to the
component whether it is in hardware or in software. Figure \ref{fig_cpp_templates} shows how we
implement these stubs. \emph{C2} is a template parameter of \emph{C1}. When both are in the same
domain, \emph{C1} can be used with \emph{C2} itself as its parameter. When \emph{C1} is in software
and \emph{C2} in hardware, \emph{C1} is used with \emph{C2\_SW\_Stub} which forwards the operations
to the real component in hardware. In the opposite situation, \emph{C2\_HW\_Stub} must forward the
operations to the component in software. In order to do so, it uses the \emph{Call\_Chan} and the
\emph{Ret\_Chan} channels. These channels are just references to parameters of the \emph{hls\_design
top} function defined by the dispatcher (section \ref{sec:proposal:unified_design:aspects}). These
references are passed to \emph{C1}'s constructor which forwards them to \emph{C2\_HW\_Stub}.

\fig{0.60}{fig_cpp_templates}{HW and SW stubs implemented as C++ templates.}

\subsubsection{Platform synthesis}
\label{sec:proposal:unified_design:platform}
After the definition of the hardware/software partitioning and stubs binding (Figure
\ref{fig_adesd_flow}c), the final platform can be synthesized(Figure \ref{fig_adesd_flow}d). In the
software side, components wrapped with the software scenario adapter are fed to the compiler
along with EPOS. Apart of basic RTOS features, EPOS is also responsible for the implementation of
the run-time support required by the mechanisms mentioned above. For example, a software component
that exists only in the scope of a hardware component is instantiated by this run-time support. When
the hardware component requests operations through the stub, the software is interrupted and the
run-time support handles the communication between the stub and the component in software.

In the hardware side, a HLS tool is used to generate RTL descriptions. These descriptions are
bound with the hardware platform library and fed to the RTL synthesis tool. The platform library
contains the components required to run the software (softcore processor, memories, and peripherals)
and the communication infrastructure that allows application's components to communicate with each
other. Details of the features available in both the EPOS and the platform library are given in the
description of our case study in the next section.

\section{Evaluation}
\label{sec:evaluation}

In order to evaluate our approach, we have applied the proposed mechanisms in the design of a PABX
SoC. We've selected and reimplemented the following components using unified C++ descriptions: a
DTMF
detector, an IMA ADPCM encoder/decoder, and the EPOS's scheduler, which was described in section
\ref{sec:proposal:unified_design:unified_descriptions}. The use of the EPOS's scheduler as a case
study is motivated by its complex behavior. A scheduler may perform operations both synchronously
(upon request by another component) or asynchronously (by preempting the execution of another
component). Furthermore, a hardware-implemented scheduler has deterministic execution time,
eliminating jitter and improving the support of real-time applications. 

Figure \ref{fig_pabx_soc} shows the block diagram of the SoC. The \emph{RTSNoC}~\cite{Berejuck:2011}
is the core communication infrastructure. The software which implements the PABX application runs
on the EPOS operating system in a MIPS core. The \emph{NoC Proxy} components bridge the RTSNoC with
EPOS and implement the run-time support described in section
\ref{sec:proposal:unified_design:platform}.

\fig{.5}{fig_pabx_soc}{PABX SoC block diagram. Highlighted components were implemented using a
unified C++ description and can move between hardware and software.}

Table \ref{tab_sw_metrics_reduced} compares the original software-only C (ADPCM and DTMF) and C++
(Scheduler) codes before being modified into unified C++ descriptions. The ADPCM and DTMF footprints
were obtained by compiling the components in isolation, while the Scheduler's footprint is actually
the full EPOS footprint. The task scheduler is the core component of an OS, thus it does not makes
sense to compile it in isolation. Everything was compiled with \emph{gcc 4.0.2} using \emph{level 2}
optimizations. The results show an average increase of about 4.2\% in the total memory footprint
when we used the unified code, while the average execution time increased by about 7.7\%.

\tabTC[ht]{tab_sw_metrics_reduced}
{Software-only implementations X Unified implementations adapted to the software domain}

Table \ref{tab_hw_metrics_par_slices} compares the RTL descriptions generated from the unified C++
using \emph{Calypto's CatapultC} HLS tool against hand-coded RTL. In order to provide a fair
comparison, we had provided synthesis directives to guide CatapultC in the generation of RTL
microarchitectures which were as close as possible to the hand-coded ones. The results were
obtained by synthesizing each component in isolation using \emph{Xilinx's ISE 13.1} targeting a
\emph{Virtex6 XC6VLX240T} FPGA. The components obtained from HLS required about 43\% more FPGA
resources than the hand-coded ones and also reached a lower maximum operating frequency (about
10\%). The average maximum number of clock cycles required per operation was, however, 9\% smaller,
thus yielding faster components (considering that both implementations meet the minimum frequency
requirements).

\tabTC[ht]{tab_hw_metrics_par_slices}
{Hand-coded RTL X Unified implementations adapted to the hardware domain}

We also provide the total software and hardware footprint of our PABX SoC considering different
hardware/software partitionings of our case studies. Table \ref{tab_soc_results} shows the total
memory footprint of the software and the number FPGA slices required by the hardware when: all the
case studies are in software; all the case studies are in hardware; and a hybrid partitioning in
which only the scheduler is in software. As we can see in table \ref{tab_soc_results}, the hybrid
partitioning resulted in a better tradeoff between software and hardware size.

\tab[ht]{tab_soc_results}{SoC area footprint. In the hybrid partitioning, the Scheduler is in
software while the ADPCM codec and the DTMF detector are in hardware}

\section{Conclusion}
\label{sec:conclusion}

In this paper we have explored a methodology based on AOP and OOP concepts in order to produce
unified implementations of hardware and software components. Specific characteristics of both
domains are captured as separated aspects and weaved with the unified source code only in the final
stages of the design process. Also, our mechanisms are implemented using only standard C++ features,
thus assuring compatibility with different C++/C-based HLS tools. Furthermore, we have
demonstrated the utility of our approach by redesigning some functional blocks of a PABX system.
The resulting components confirmed that an unified code can be almost as efficient as a
software-only one. The generated hardware was slightly faster than its hand-coded counterpart, but
at the cost of a considerable ammount of additional area. Nevertheless, this limitation is expected
to be overcomed by the advances in HLS techniques.

%\newcommand{\bibfont}{\footnotesize}
%\bibliographystyle{abbrv}
\bibliographystyle{IEEEtran}
\scriptsize
\bibliography{paper}

\end{document}
