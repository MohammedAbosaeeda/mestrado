\documentclass{ufscThesis}
\usepackage{graphicx}
\usepackage[labelsep=endash]{caption} % O separador de legenda é um -
\usepackage{color,graphicx}
\usepackage[lined,ruled,linesnumbered,portuguese]{algorithm2e}
\usepackage{listings}
\usepackage{verbatim}
\usepackage[printonlyused,smaller]{acronym}

\lstloadlanguages{C,HTML}
\lstdefinestyle{prg}{basicstyle=\small\sffamily, lineskip=-0.2ex, showspaces=false}

\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}

\SetKwInput{KwData}{Dados}
\SetKwInput{KwResult}{Resultado}
\SetKwInput{KwIn}{Entrada}
\SetKwInput{KwOut}{Sa\'{i}da}
\SetKw{KwTo}{para}
\SetKw{KwRet}{retorne}
\SetKw{Return}{retorne}
\SetKwBlock{Begin}{in\'{i}cio}{fim}
\SetKwComment{tcc}{/*}{*/}
\SetKwComment{tcp}{//}{}
\SetKwIF{If}{ElseIf}{Else}{se}{ent\~{a}o}{sen\~{a} se}{sen\~{a}o}{fim}
\SetKwSwitch{Switch}{Case}{Other}{comute}{faça}{caso}{caso contr\'{a}rio}{fim da comutaç\~{a}o}
\SetKwFor{For}{para}{fa\c{c}a}{fim}
\SetKwFor{While}{enquanto}{fa\c{c}a}{fim}
\SetKwFor{ForEach}{para cada}{fa\c{c}a}{fim}
\SetKwRepeat{Repeat}{repita}{at\'{e}}

\titulo{Automação da execução de testes de software embarcado} % Titulo do trabalho
\autor{Rita de Cássia Cazu Soldi} % Nome do autor
\data{16}{maio}{2014} % Data da publicação do trabalho

\orientador{Prof. Dr. Antônio Augusto Medeiros Fröhlich} % Nome do orientador e (opcional)
%\departamento[a]{Faculdade de Ciências do Mar}
%\curso[a]{Atividade de Extensão em Corte e Costura}

\begin{acronym}
\acro{ADESD}{\textit{Application-Driven Embedded System Design}}
\acro{DD}{\textit{Delta Debugging}}
\acro{DMEC}{\textit{Distributed Motion Estimation Component}}
\acro{DID}{\textit{Discovery Interface Device}}
\acro{EPOS}{\textit{Embedded Parallel Operating System}}
\acro{GCC}{\textit{GNU Compiler Collection}}
\acro{GDB}{\textit{GNU Project Debugger}}
\acro{ICE}{\textit{In-circuit emulator}}
\acro{IDD}{\textit{Iterative Delta Debugging}}
\acro{IEEE}{\textit{Institute of Electrical and Electronics Engineers}}
\acro{JTAG}{\textit{Joint Test Access Group}}
\acro{MCO}{\textit{The Mars Climate Orbiter}}
\acro{MPL}{\textit{The Mars Polar Lander}}
\acro{RSSF}{Redes de Sensores Sem Fio}
\acro{TAP}{Troca Automática de Parâmetros de \textit{Software}}
\acro{TBT}{\textit{Target Based embedded system Testing}}
\acro{SUT}{\textit{Software Under Test}}
\acro{XML}{\textit{eXtensible Markup Language}}
\end{acronym}

\newcommand{\fig}[4][h]{
  \begin{figure}[#1] {\centering{\includegraphics[#4]{fig/#2}} \par}
    \caption{#3\label{fig:#2}}
  \end{figure}
}


\newcommand{\progcpp}[3][h]{
 \begin{figure}[#1]
     \lstinputlisting[language=C,style=prg]{fig/#2.h}
   \caption{#3\label{progcpp:#2}}
 \end{figure}
}

\newcommand{\progxml}[3][h]{
 \begin{figure}[#1]
     \lstinputlisting[language=XML,style=prg]{fig/#2.xml}
   \caption{#3\label{progxml:#2}}
 \end{figure}
}


%%% Sobre a Banca
\numerodemembrosnabanca{3} % Isso decide se haverá uma folha adicional
\orientadornabanca{sim} % Se faz parte da banca definir como sim
\bancaMembroA{Prof. Presidente da banca} %Nome do presidente da banca
\bancaMembroB{Prof.  membro1} % Nome do membro da Banca
\bancaMembroC{Prof.  membro2} % Nome do membro da Banca
%\bancaMembroD{Prof.  membro3} % Nome do membro da Banca

\dedicatoria{Dedico este trabalho à minha familia: meus amados pais Célia Regina Cazu Soldi e Luis Carlos Soldi, minha irmãzinha Luiza Helena Cazu Soldi e meu companheiro para todas as horas, Marcelo Ribeiro Xavier da Silva.}

\agradecimento{Ainda não escrevi.}

\epigrafe{How often have I said to you that when you have eliminated the impossible, whatever remains, however improbable, must be the truth?}{ Sherlock Holmes}

\textoResumo {O número de sistemas embarcados já superam a quantidade de habitantes do nosso planeta e este número continua crescendo em ritmo acelerado. Ademais, o projeto de \textit{hardware} e \textit{software} está cada vez mais sofisticado e com requisitos mais rígidos para atender o exigente mercado.

O aumento da complexidade do sistema dificulta a validação e verificação dos sistemas embarcados. As consequências desta sofisticação afetam muito o desenvolvimento de \textit{software} embarcado que, mesmo representando uma parcela minoritária  do sistema, tornou-se responsável por cerca de 80\% dos erros encontrados nos sistemas.

Teste e depuração de \textit{software} não é trivial, uma vez que é necessária a inspeção completa de todo o código fonte para se certificar de que o comportamento não difere das expectativas. Realizar essas atividades em sistemas embarcados é ainda mais desafiador, uma vez que os desenvolvedores precisam para descobrir como otimizar o uso dos recursos, pois o teste em si tende a competir com o aplicativo sob teste pelos escassos recursos do sistema.

Esta monografia apresenta uma maneira de ajudar os desenvolvedores no processo de testar e depurar sistemas embarcados. Ela apresenta a ferramenta \ac{TAP}, cuja ideia consiste em emular as possíveis configurações do sistema a fim de tentar encontrar erros na aplicação. Uma vez detectado um comportamento não especificado, \ac{TAP} automaticamente executa a compilação, depuração e emulação de acordo com um arquivo de especificação.

\ac{TAP} é avaliada de maneira quantitativa para os critérios de tentativas realizadas \textit{versus} a configuração de granularidade, o consumo de tempo para realizar o teste/depuração e o consumo de memória para suportar a ferramenta. A ferramenta também foi avaliada de maneira qualitativa em um comparativo com ferramentas e técnicas correlatas. 

Os resultados mostraram que a estratégia proposta resultou em uma ferramenta flexível e com grande cobertura dos desafios propostos para atingir os desafios associados à automação de testes de \textit{software}. Além disso, \ac{TAP} apresenta soluções equivalentes às de outras ferramentas e cobre inclusive características que não faziam parte do escopo inicialmente proposto.}

\palavrasChave {Execução de testes automática, testes de \textit{software} embarcado, depuração de \textit{software}embarcado}

\textAbstract {The number of embedded systems already exceed the number of inhabitants of this planet and this number continues to grow. Moreover, the design of \textit {hardware} and \textit {software} are increasingly sophisticated and more stringent requirements to meet the demanding market.

Increasing system complexity hampers validation and verification of embedded systems. The consequences of this sophistication greatly affect the development of the embedded software, even representing a minority of the system, became responsible for about 80 \% of the errors found.

Testing and debugging embedded software is non-trivial, once it needs a thorough inspection of the entire source code to make sure that there is no behavior beyond expectations. Perform these activities on embedded systems are even more defiant, once developers need to find out how to optimize the use of the scarce resources since the test itself will compete with the application under test by the scarce system resources. 

This monograph presents a way to help the developers to test and debug embedded system process. It features the \ac{TAP} tool, whose the basic idea is to emulate various possible system configurations to try to find errors in the application. Once detected an unspecified performance, \texttt{TAP} automatically perform compilation, emulation and debugging accordingly to the specification file.

\ac{TAP} is evaluated quantitatively for the criteria of trials performed \textit{versus} the granularity, the time consumption for testing/debugging and memory consumption to support the tool. The tool was evaluated in a qualitative manner in comparison with related tools and techniques.

Results showed that the proposed strategy has resulted in a flexible and extensive coverage of the challenges faced tool to achieve the challenges associated with testing automation of software. Moreover, \ac{TAP} presents equivalent solutions to the other tools and even covers features that were not part of the originally intended scope.}

\keywords {Automatic testing execution, embedded software testing, embedded system debugging}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Início do documento
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%--------------------------------------------------------
% Elementos pré-textuais
\capa
\folhaderosto % Se nao quiser imprimir a ficha, é só não usar o parâmetro
\folhaaprovacao
\paginadedicatoria
%\paginaagradecimento
\paginaepigrafe
\paginaresumo
\paginaabstract
\listadefiguras
\listadetabelas
\listadeabreviaturas
%\listadesimbolos
\sumario

\chapter{Introdução}
\label{cap:introducao}
Sistemas embarcados podem ser apresentados como uma combinação de \textit{hardware} e \textit{software} concebida para realizar uma tarefa específica. Estes sistemas estão amplamente acoplados a inúmeros dispositivos e suas funcionalidades estão cada vez mais intrínsecas no cotidiano das pessoas~\cite{carro2003sistemas}. Atualmente interagimos com mais de um sistema embarcado por dia e o número destes sistemas já superam o número de habitantes do nosso planeta, ainda, este número continua crescendo em ritmo acelerado~\cite{Marcondes:MSC:2009}.

Como em qualquer sistema computacional, as soluções embarcadas também basearam-se na premissa de que cada componente utilizado está efetuando corretamente as suas atividades e que a integração entre os mesmos não se desvia do comportamento esperado. Caso contrário, o sistema pode apresentar erros. 

É comum que a consequência de um erro resulte em perdas financeiras, como por exemplo a perda de uma determinada quota de mercado, corrupção de dados do cliente, etc~\cite{tassey2002economic}. Os danos materiais são inconvenientes, mas colocar em perigo a vida humana é um risco inaceitável. Infelizmente não faltam exemplos de erros em sistemas que resultaram em risco de morte, como a falha do sistema de defesa contra mísseis (Patriot), a ruptura do oleoduto de Bellingham - Washington, ou nos casos de overdose de radiação no tratamento de câncer ocasionadas pelo Therac-25 ~\cite{zhivich2009real}. Também existem vários exemplos relacionados à erros em sistemas embarcados, como por exemplo as tragédias aeroespaciais de Ariane 501, \ac{MCO}, \ac{MPL}, entre outros ~\cite{leveson2009software}. 

Grande parte destas tragédias possui um relatório descrevendo como ocorreu o acidente, os quais indicaram que a causa mais comum das falhas continua sendo subestimar a complexidade do sistema e superestimar a eficácia dos testes~\cite{frola1984system,leveson2004role,leveson2009software}. Mesmo depois de várias perdas relacionadas à erros em sistemas computacionais, ainda há muita complacência quando um sistema desvia do comportamento esperado, o que acaba subestimando a consequência deste erro. Para garantir que os componentes vão agir de acordo com o requisitado, uma boa prática é testar de maneira pragmática cada detalhe do sistema e sem subestimar a complexidade do mesmo.

Durante o planejamento e desenvolvimento dos testes, é necessário lembrar que o teste em si não é um comportamento do sistema e nunca deve interferir no fluxo de atividades que está sendo testado. Quando este teste tem como alvo um sistema embarcado é importante ressaltar que tanto a complexidade do sistema quanto a do teste são maiores, pois estes sistemas costumam ser mais restritos em termos de memória, capacidade processamento, tempo de bateria, prazos para executar uma determinada atividade, entre outros. 

Além da dificuldade da própria atividade de teste, os desenvolvedores ainda precisam se adaptar a uma grande variedade de plataformas, sistemas operacionais, arquitetura, fornecedores, ferramenta de depuração, etc~\cite{schneider2004ten}. 

Existem diversas ferramentas de apoio ao desenvolvimento de \textit{software} embarcado que tentam minimizar o impacto destas variações. A escolha e integração destas ferramentas é uma etapa importante na construção de sistemas embarcados e deve ser feita de maneira criteriosa, uma vez que pode simplificar todo o processo de desenvolvimento.

\section{Motivação}
Além da quantidade, a complexidade dos sistemas embarcados é um fator que nunca para de crescer. O projeto de \textit{hardware} e \textit{software} está cada vez mais sofisticado e com requisitos mais rígidos. Para atender a esta demanda, o \textit{software} embarcado deixou de ser composto por um conjunto limitado de instruções \textit{assembly} e deu espaço à novas possibilidades, que antes era oferecidas apenas pelas linguagens de alto nível. 

Mesmo com este acúmulo de atividades, o \textit{software} embarcado ainda representa uma parcela minoritária do sistema~\cite{ebert2009embedded}. Então apesar de sua crescente complexidade, ainda são poucas as ferramentas de auxílio ao desenvolvimento de sistemas embarcados que focam em validação e verificação do \textit{software}.

Ainda, constatou-se que as ferramentas disponíveis para automação da execução de testes não são de fácil compreensão/execução e poucas possuem resposta satisfatória para os casos de falhas do caso de teste. Um ponto de melhoria seria pausar a execução no exato momento em que o \textit{software} apresentar o comportamento inesperado, fornecer um relatório com os testes já realizados e oferecer dicas para que se possa detectar o \textit{bug}.

Trabalhos recentes apontam que mais de 80\% dos erros de um sistema embarcado provém do \textit{software}, não do \textit{hardware}, e que tanto o teste quanto a depuração são de suma importância para a qualidade do projeto embarcado~\cite{torri2010evaluation}. Desta forma, a motivação deste trabalho está em diminuir a dificuldade para realizar-se a verificação de sistemas embarcados, para que seja possível aproveitar melhor as oportunidades que são oferecidas pela indústria e tecnologia.

\section{Objetivo}
O principal objetivo deste trabalho é identificar o estado da arte do processo de teste e depuração de \textit{software} de sistemas embarcados. A partir deste estudo, será proposta uma ferramenta para execução automatizada de testes de \textit{software}. Além disso, esta ferramenta deve integrar-se automaticamente com um sistema de depuração de maneira simples e produzir informações que auxiliem na manutenção da qualidade do \textit{software}.

\subsection{Delimitações}
O presente trabalho não tem como objetivo a geração de casos de teste para um determinado \textit{software}, limitando-se apenas em executá-los de maneira automatizada. Sendo assim, qualquer erro presente nos testes recebidos pelo protótipo para execução automática serão considerados como erro do próprio \textit{software}.

\subsection{Objetivos Específicos}
Para atender o objetivo geral, os seguintes objetivos específicos devem ser concluídos:
\begin{itemize}
 \item Planejar e executar uma revisão sistemática dos trabalhos relacionados, formando uma base de conhecimento da área de teste e depuração de sistemas embarcados.
 \item Desenvolver uma arquitetura que realize a automação da execução de testes de maneira simples, sem que seja necessário configurar cada teste a ser executado.
 \item Especificar de um ambiente capaz de integrar a execução automática dos testes e a depuração de um \textit{software}.
 \item Realizar uma avaliação qualitativa e quantitativa da arquitetura proposta, comparando o presente trabalho com os trabalhos relacionados.
 \item Apresentar o trabalho desenvolvido em forma de artigo científico em conferências e periódicos, para que especialistas da área de sistemas embarcados possam corroborar os resultados obtidos e a contribuição técnica/científica.
\end{itemize}


%\section{Organização do texto}
%\begin{itemize}
% \item \textbf{Capítulo \ref{cap:conceitosBasicos}}: apresenta os conceitos fundamentais da área, compondo uma base teórica para auxiliar no desenvolvimento das ideias e na assimilação das técnicas apresentadas neste trabalho.
% \item \textbf{Capítulo \ref{cap:trabalhosRelacionados}}: possui os trabalhos que representam o estado da arte da literatura e que servem de inspiração para o desenvolvimento desta dissertação. Todos os trabalhos aqui apresentado se relacionam diretamente com o tema abordado.
	%\item[Capítulo]
	%\item[Capítulo] é o capítulo de desfecho da dissertação e apresenta as conclusões extraídas durante o desenvolvimento deste trabalho, além de alguns pontos de melhoria para trabalhos futuros.
%\end{itemize}

\chapter{Conceitos básicos}
\label{cap:conceitosBasicos}
%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
%%%%%%%%%%%%%%%%%%%%%
\section{Terminologia}
Nesta seção serão apresentados alguns termos e conceitos que serão necessários para a completa compreensão da proposta.

\subsection{Defeitos, erros e falhas}
Estes três termos estão diretamente relacionados ao teste de \textit{software} e seus termos foram definidos pela \ac{IEEE}.

\begin{itemize}
 \item \textbf{Defeito} é um ato cometido por um indivíduo ao tentar entender uma determinada informação, resolver um problema ou utilizar um método ou uma ferramenta. Por exemplo, uma instrução ou comando incorreto.
 \item \textbf{Erro} é uma manifestação concreta de um defeito num artefato de \textit{software}. A diferença entre o valor obtido e o valor esperado, ou seja, qualquer estado intermediário incorreto ou resultado inesperado na execução de um programa constitui um erro.
 \item \textbf{Falha} é um comportamento operacional do \textit{software} diferente do esperado pelo usuário. Uma falha pode ter sido causada por diversos erros e alguns erros podem nunca causar uma falha.
\end{itemize}

Defeito é um ato inconsistente cometido por um indivíduo ao tentar entender uma determinada informação, resolver um problema ou utilizar um método ou uma ferramenta. Por exemplo, uma instrução ou comando incorreto.

Erro é uma manifestação concreta de um defeito num artefato de software. Diferença entre o valor obtido e o valor esperado, ou seja, qualquer estado intermediário incorreto ou resultado inesperado na execução de um programa constitui um erro.

Falha é o comportamento operacional do software diferente do esperado pelo usuário. Uma falha pode ter sido causada por diversos erros e alguns erros podem nunca causar uma falha.

Apesar de contemplarem ideias parecias, os termos não são sinônimos e são utilizados para designar conceitos distintos. A Figura~\ref{defeito_erro_falha} apresenta um resumo visual dos conceitos de defeito, erro e falha.

\fig{defeito_erro_falha}{Defeito versus erro versus falha \cite{neto2012introduccao}}{scale=.8}
%%%%%%%%%%%%%%%%%%%%%
\end{comment}
%%%%%%%%%%%%%%%%%%%%%

\section{Teste de \textit{software}}
A primeira conferência com foco em teste de \textit{software} ocorreu há apenas 42 anos, em junho de 1972~\cite{Gelperin:1988}. Desde então há um esforço para definir melhor os conceitos relacionados à área e também para chegar-se a um consenso sobre a pontos chave como nomenclatura, documentação, especificação e execução de testes.

A definição com maior aceitação apresenta o teste de \textit{software} como o processo de análise de um item de \textit{software} para detectar as diferenças entre as condições existentes e exigidas (isto é, os erros), e avaliar as características do item de software~\cite{ieee87}. Sendo assim, esta atividade é amplamente utilizada para assegurar que o \textit{software} contempla as funcionalidades especificadas e quem todas elas estão funcionando corretamente.

Segundo Myers, os objetivos do teste de \textit{software} podem ser expressos a partir da observação de três regras\cite{Myers:2004:AST:983238}:
\begin{itemize}
 \item A atividade de teste é o processo de executar um programa com a intenção de descobrir um erro.
 \item Um bom caso de teste é aquele que apresenta uma elevada probabilidade de revelar um erro ainda não descoberto.
 \item Um teste bem sucedido é aquele que revela um erro ainda não descoberto.
\end{itemize}

Estas três regras ressaltam o objetivo do teste de \textit{software}, que visa salientar a presença dos erros e não sua ausência. Isto significa que o sucesso de um teste em encontrar um desvio de comportamento em um determinado \textit{software} não garante que todas as possíveis falhas tenham sido encontradas. O teste que não encontra erros é meramente inconclusivo, pois não se sabe se há ou não desvio no comportamento do \textit{software} analisado.

Segundo Pressman, muitas estratégias de testes já foram propostas na literatura e todas fornecem um modelo para o teste com as seguintes características genéricas ~\cite{pressman}:
\begin{itemize}
 \item Para executar um teste de maneira eficaz, deve-se fazer revisões técnicas eficazes. Fazendo isso, muitos erros serão eliminados antes do começo do teste.
 \item O teste começa no nível de componente e progride em direção à integração do sistema computacional como um todo.
 \item Diferentes técnicas de teste são apropriadas para diferentes abordagens de engenharia de \textit{software} e em diferentes pontos no tempo.
 \item O teste é feito pelo desenvolvedor do \textit{software} e (para grandes projetos) por um grupo independente de teste.
 \item O teste e a depuração são atividades diferentes, mas depuração deve ser associada a alguma estratégia de teste.
\end{itemize}

Testar um \textit{software} é essencial para revelar o número máximo de erros a partir do menor esforço, ou seja, quanto antes forem detectadas divergências entre o que foi requisitado e o que foi entregue menor será o desperdício tempo e esforço do retrabalho para adequar o \textit{software}. 

Os testes devem ser adotados desde o início do projeto de \textit{software} a partir da definição dos requisitos a serem testados, escolha da abordagem utilizada, da política de testes, critérios para a conclusão do teste, entre outros. Para que o processo de teste alcance seu objetivo é necessária uma estratégia de testes, suficientemente flexível para modelar-se às peculiaridades do \textit{software} e rígida o bastante para um acompanhamento satisfatório do projeto.

\subsection{Classificação dos níveis de teste}
As atividades de teste de \textit{software} são normalmente classificados em níveis. Dentre os mais tradicionais estão a categorização baseada no processo de processo de \textit{software} e a categorização baseada na maturidade de pensamento testadores\cite{Ammann:2008:softwareTestig}.

\subsubsection{Modelo V}
A classificação baseada no processo genérico do desenvolvimento do \textit{software} e incentiva o projeto dos testes simultâneo com cada etapa de desenvolvimento, mesmo que o software só possa ser executado após a fase de implementação~\cite{Rook:vMovel}. Nela cada atividade do processo de construção de um \textit{software} é acompanhado de uma atividade de teste, ou seja, a informação de entrada do teste é normalmente derivada de uma atividade de desenvolvimento do \textit{software}. 

A Figura~\ref{fig:modeloV} apresenta um mapeamento típico entre as atividades \textit{Modelo V}, nela é possível visualizar como cada tipo de teste se relaciona com o processo genérico do desenvolvimento de \textit{software}.
\fig{modeloV}{Mapeamento entre as atividades de desenvolvimento e teste de \textit{software}.}{scale=.3}

\textbf{Análise de requisitos e Teste de aceitação}: No desenvolvimento de \textit{software}, a fase de análise de requisitos é quando se captura as necessidades do cliente, sendo assim, o teste de aceitação foi concebido para determinar se o \textit{software} atingiu o objetivo e realmente satisfaz estas necessidades. Este tipo de teste geralmente são executados por um grupo restrito de usuários que simulam operações de rotina do sistema, de modo a verificar se seu comportamento está de acordo com o solicitado.
 
\textbf{Especificação funcional e Teste de sistema} - A fase de especificação funcional é quando arquitetura e os componentes são selecionados e, juntos, vão compor o \textit{software}. Então, o teste de sistema é projetado para determinar se o sistema funciona conforme estipulado. Este nível de teste procura falhas no projeto e na especificação do \textit{software} através de sua execução nos mesmos ambientes e nas mesmas condições que um usuário final o utilizaria.
 
\textbf{Especificação técnica e Teste de integração} - A fase de especificação técnica é voltada para o projeto da arquitetura do \textit{software}, definindo a estrutura, comportamento e papel dos subsistemas que compõem a arquitetura geral do \textit{software}. Seguindo a mesma linha, o teste de integração é projetado para avaliar se as interfaces entre subsistemas são consistentes e se a comunicação ocorre corretamente. Este teste geralmente é de responsabilidade dos membros da equipe de desenvolvimento e visa provocar falhas de comunicação entre os módulos integrados para construir o \textit{software}.
 
\textbf{Implementação e Teste de unidade} - Implementação é a fase do desenvolvimento de  \textit{software} que realmente produz o código fonte. Portanto, o teste de unidade tem como alvo o código desenvolvido, ou seja, métodos, procedimentos (\textit{procedures}) ou até mesmo mesmo pequenos trechos de código. Tanto a implementação quanto o teste são de responsabilidade dos membros da equipe de desenvolvimento.
 
\subsubsection{Modelo de maturidade}
A classificação de níveis baseada na maturidade do processo de teste propõe que o nível dos testes seja derivado do objetivo do teste, que podem ser ~\cite{Beizer:1990}:
\begin{itemize}
 \item \textbf{Nível 0} - Não há nenhuma diferença entre teste e depuração. Um teste com o nível zero não tem um propósito específico.
 
 \item \textbf{Nível 1} - possui o objetivo de mostrar que o \textit{software} funciona. Normalmente este nível é utilizado quando a corretude do \textit{software} ainda não foi alcançada/demonstrada, então é selecionado um conjunto de dados de teste que faz o \textit{software} passar em determinados testes e falhar em outros. Apesar de ser uma técnica menos ingênua que o \textit{Nível 0}, este tipo de teste pode não propiciar a descoberta de defeitos.
 
 \item \textbf{Nível 2} - possui o objetivo de mostrar que o \textit{software} não funciona. Normalmente se seleciona um conjunto de dados para chegar pontos específicos do sistema como, por exemplo,  checar a fronteira superior e inferior de um determinado dado de entrada. A transição do \textit{Nível 1} para o \textit{Nível 2} demanda cautela, pois apesar da descoberta de erros fazer parte linha raciocínio dos testadores, grande parte dos desenvolvedores possui linha de raciocínio mais próxima do nível anterior. Ou seja, esta mudança de nível pode gerar conflitos e afetar negativamente a moral da equipe.
 
 \item \textbf{Nível 3} - não possui o objetivo de reduzir o risco de utilizar \textit{software}, sem provar que o \textit{software} funciona ou não. Ao atingir a consciência de que testes não mostram ausência de falhas no \textit{software} percebe-se também que sempre há um risco do \textit{software} não funcionar corretamente. A partir deste nível, desenvolvedores e testadores compartilham o objetivo de reduzir o risco de utilizar o sistema, pois compreendem que embora o ideal seja testar todas as possibilidades, isto pode não ser possível.
 
 \item \textbf{Nível 4} - o teste é considerado como uma ferramenta que auxilia no desenvolvimento de um \textit{software} com maior qualidade. O ato de testar não é um simples ato, mas sim uma maneira de produzir um \textit{software} de baixo risco com pouco esforço. Neste nível, a geração de código é realizada de maneira a suportar a concepção e o desenvolvimento de testes, facilitando também o reuso e manutenção do sistema.
\end{itemize}

%\subsection{Teste de \textit{software} embarcado *** estou fazendo}


\section{Depuração de \textit{software} embarcado}
A depuração é a arte de diagnosticar erros em sistemas e determinar a melhor forma de corrigi-los. Em geral, o ponto de partida para a depuração de um sistema é a ocorrência de algum erro, portanto, é muito comum que a depuração ocorra como consequência de um teste bem sucedido (isto, que encontrou erros).

Erros podem ser encontrados por qualquer pessoa em qualquer etapa do ciclo de vida do \textit{software}. Isto implica que tanto o formato do relatório de um resultado inesperado, quanto as características dos erros podem variar de acordo com o conhecimento do autor do relato. Sendo assim, para realizar uma depuração eficaz deve-se ser capaz de identificar a técnica apropriada para analisar diferentes tipos de relatórios e obter as informações necessárias para eliminar o problema.

A depuração \textit{software} embarcado é uma tarefa complexa, cuja dificuldade varia de acordo com o ambiente de desenvolvimento, linguagem de programação, tamanho do sistema e disponibilidade de ferramentas disponíveis para auxiliar o processo. Para um suporte de depuração eficaz, existem algumas diretrizes a serem seguidas~\cite{debugSuport}:
\begin{itemize}
	\item O suporte à depuração não deve alterar e nem interferir no comportamento do sistema sob teste (em inglês, \ac{SUT}).
	\item Deve existir uma infraestrutura de observação do estado interno do sistema e de possíveis pontos críticos.
	\item Garantia de acesso externo para controlar o estado interno do sistema e de seus recursos (incluindo periféricos).
	\item O impacto do custo do sistema deve ser o mínimo possível, principalmente quando são necessárias mudanças no \textit{hardware}.
\end{itemize}

O apoio à depuração de \textit{software} normalmente ocorre a partir do monitoramento do \textit{software} compilado e instrumentado. A instrumentação pode ser aplicada e suportada de várias maneiras, dentre as mais frequentes estão a execução do \textit{software} em modo de depuração, o uso de tratadores de interrupções e o uso de instruções de suporte à depuração.

\subsection{Imprimir dados em dispositivos de saída}
Um exemplo de instrumentação \textit{software} é utilizar instruções de impressão para exibir/registrar variáveis, informações sobre o estado do sistema ou até o seu progresso através do código do programa. 
Esta técnica de depuração é um tanto primitiva e bastante intrusiva, pois normalmente está associada à mudanças no código fonte e recompilação do \textit{software}.

Para realizar este tipo de depuração é necessário que o erro possa ser reproduzido e que ele não se altere com as impressões. Dependendo de como utilizada, esta técnica pode retardar a execução do sistema, modificando inclusive requisitos do próprio \ac{SUT}. 

Como a própria tentativa encontrar erros pode apresentar efeitos colaterais que mascaram o verdadeiro problema, torna-se difícil identificar erros relacionados com operações temporais, paralelismo e alocação de recursos.

\subsection{Emulador em circuito}
\ac{ICE} é um \textit{hardware} utilizado em depuração de projeto de sistemas embarcados, fornecendo recursos e conectividade que ajudam a superar as limitações de teste e depuração tanto do \textit{software} quanto do \textit{hardware}. 

Este equipamento é específico para cada microprocessador, por isso permite controle total do processador e fornece a observação das operações do sistema de maneira consistente e eficaz. A informação coletada por ele fica disponível em tempo de execução e, a princípio, o equipamento extra não exerce nenhum impacto sobre o comportamento do \ac{SUT}. 

As placas \ac{ICE} conseguem integrar o controle de execução do microprocessador, acesso à memória e monitoração em tempo real. Por isso é uma estratégia muito utilizada no início do desenvolvimento dos sistemas embarcados. Entretanto, o aumento da complexidade do sistema pode exigir adaptações no projeto de integração dos \ac{ICE}s ao sistema. No caso de sistemas complexos o esforço e o custo para realizar tal adaptação pode ser tão grande que tornam a depuração proibitiva~\cite{debugSuport}.

\subsection{Depuradores}
Depuradores são ferramentas que auxiliam no monitoramento da execução de um programa, incluindo opções como: executar o programa passo-a-passo, pausar/reiniciar a execução e, em alguns casos, até voltar no tempo e desfazer a execução de uma determinada instrução.

A conexão entre o programa e o depurador pode ocorrer localmente ou remotamente. Ambas possuem vantagens e pontos de melhoria que devem ser considerados na construção de um ambiente de depuração estável.

No método local o programa é executado na mesma máquina que o depurador, isto implica em um processo com latência menor e com grande influência entre ambos. Por exemplo, se um processo provoca um \textit{crash} no sistema, o depurador perde grande parte das informações de deputação, pois pertence ao mesmo ambiente que sofreu a parada e só poderia formar a hipótese de \textit{crash} porque ele mesmo realizou um comportamento inesperado (travar ou reiniciar).

Já na depuração remota não ocorre este tipo de interferência, uma vez que a aplicação sob depuração e o depurador encontram-se em máquinas separadas. Do ponto de vista do ambiente de depuração, a depuração remota é semelhante a uma depuração local com duas telas conectadas em um único sistema.

\section{Projeto de sistemas orientado a aplicação}
A metodologia de projeto de sistemas orientado a aplicação, a \ac{ADESD}, tem como objetivo principal a produção de sistemas para aplicações de computação dedicada e adaptados para atender exigências específicas da aplicação que irá utilizá-lo~\cite{Froehlich:2001}. 

Esta metodologia permite manter o foco nas aplicações que utilizarão o sistema desde o início do projeto. Desta forma, tanto a arquitetura quanto os componentes podem ser definidos a fim de maximizar a reutilização e a configurabilidade do sistema de acordo com as peculiaridades da sua aplicação. Os principais conceitos envolvidos em sua utilização são:
\begin{description}
	\item[Famílias de abstrações independentes de cenário]  \hfill \\
	Durante a decomposição de domínio as abstrações identificadas são agrupadas em famílias de abstrações e modeladas como membros desta família. As abstrações devem ser modeladas de forma totalmente independente de cenários, garantindo que sejam genéricas o suficiente para que sejam reutilizadas para compor qualquer sistema. Dependências ambientais observadas durante a decomposição de domínio devem ser separadamente modeladas como aspectos de cenário.
	
	\item[Adaptadores de cenário]  \hfill \\
	Utilizados para aplicar os aspectos de forma transparente às abstrações do sistema. Eles funcionam como uma membrana, que envolve uma determinada abstração e se torna um intermediário na comunicação dessa abstração, inserindo as adaptações necessárias para cada requisição que seja dependente de um cenário.
		
	\item[Características Configuráveis]  \hfill \\
	Utilizadas quando uma determinada característica pode ser aplicada a todos os membros de uma família, mas com valores diferentes. Então, ao invés de aumentar a família modelando novos membros, esta característica compartilhada é modelada como uma configurável. Desta forma é possível definir o comportamento desejado e aplicá-lo às abstrações de forma semelhante aos aspectos de cenário.
	
	\item[Interfaces infladas]  \hfill \\
	Resumem as características de todos os membros da família em um único componente de interface, permitindo que a implementação dos componentes de \textit{software} considerem sempre uma interface bem abrangente e, desta forma, postergando a decisão sobre qual membro da família utilizar. Esta decisão pode ser automatizada através de ferramentas que identificam quais características da família foram utilizadas e selecionam o membro dessa família que implementa o subconjunto da interface inflada.
\end{description}

\fig{aosd}{Visão geral da metodologia de projeto de sistemas orientado à aplicação~\cite{Froehlich:2001}}{scale=.6}

A Figura~\ref{fig:aosd} mostra uma visão geral da \ac{ADESD}, metodologia na qual é possível visualizar a decomposição do domínio em famílias de abstrações independentes de cenários e das dependências ambientais - separadamente modeladas como aspectos de cenário. 

A arquitetura do sistema é capturada pelos \textit{frameworks} dos componentes modelados a partir do domínio. Somente estes componentes serão reunidos para formar o sistema, pois somente eles são necessários para fornecer suporte à aplicação.

\chapter{Trabalhos relacionados}
\label{cap:trabalhosRelacionados}
Desde a formulação da área de testes de \textit{software}, muitos estudos surgiram com as mais variadas soluções para a automação deste processo. Apesar de existir uma vasta literatura de apoio, a maior parte dela relaciona-se à sistemas de propósito geral e, portanto, apenas alguns conceitos podem ser aplicados à sistemas embarcados. 

Os trabalhos que focam na automação de teste de \textit{software} embarcado procuram soluções em que o teste não prejudique a execução do \ac{SUT} e ainda consiga contornar as restrições inerentes ao próprio sistema embarcado.

\section{Justitia}
Esta ferramenta de testes de \textit{software} embarcado é capaz de detectar automaticamente falhas na interface, gerar casos de testes completos - com entradas, estados internos, valores de variáveis, saídas - e emular a execução do \textit{software} na arquitetura alvo~\cite{seo}.

$Justitia$ possui a hipótese de que a interface é um critério essencial para um teste de \textit{software} embarcado, e para defendê-la utiliza uma solução que une as seguintes técnicas:
\begin{itemize}
	\item{\textbf{Técnica de teste de interface}},  na qual os casos de teste são gerados através da análise do arquivo (imagem) executável do sistema. Como o próprio nome sugere, a técnica foca nas interfaces do sistema embarcado, em especial as referentes às camadas do sistema operacional e às camadas do \textit{hardware}. Quando teste é executado são extraídas as informações de depuração, tais como símbolos,  relações entre os componentes, informações do \textit{driver} de dispositivo, etc.
	\item{\textbf{Técnica de emulação dos casos de teste}}, uma combinação entre o monitoramento e a depuração do sistema. A ideia é definir \textit{breakpoints} para os casos de teste da interface e monitorar  as variáveis ??de interface para definir o sucesso ou falha do teste. As variáveis de interface desempenham o papel de indicador para o funcionamento do sistema embarcado,verificando se alguma camada está instável e encapsulando a influência do \textit{hardware} sobre falhas em \textit{software} embarcado
\end{itemize}

A solução foi analisada sob três pontos de vista: a densidade da interface, a complexidade do \textit{software} e a relação interface \textit{versus} falhas. Os pontos de análise surgiram de uma premissa que aponta o forte acoplamento entre \textit{hardware} e \textit{software} como a razão para aumento de dificuldades no teste de \textit{software} embarcado. 

Sendo assim, $Justitia$ apresenta uma análise da densidade da interface, na qual é estabelecida uma relação entre o grau de acoplamento \textit{software} e sua testabilidade. Já a complexidade do \textit{software} é atualmente uma das principais métricas para a previsão de falhas no sistema e no caso de $Justitia$ pode ser extrapolada para estimar a probabilidade de falhas na interface. O último ponto de vista aponta a análise da relação entre interface \textit{versus} falhas como base para os resultados encontrados pela ferramenta.

O primeiro protótipo apresentou resultados satisfatórios para as questões acima e chegou-se a conclusão de que a interface deve ser utilizada como um \textit{checkpoint} para encontrar falhas. A solução foi novamente corroborada por uma versão mais recente~\cite{KiSCL08}, agora aplicada ao teste de um \textit{driver} de um dispositivo embarcado e com a capacidade de suportar um número ainda maior de testes.

\begin{description}
\item[Resumo]  \hfill \\
Este trabalho ganhou destaque ao apontar que a maior parte das falhas nos testes de \textit{software} embarcados são oriundos da integração de componentes heterogêneos e ao propor que a interface seja um ponto de intersecção entre os testes de \textit{software} e \textit{hardware}.

Outro diferencial encontra-se na infraestrutura de execução dos testes baseada em emulação, na qual tanto o resultado da execução do \ac{SUT} quanto o monitoramento da tabela de símbolos são utilizados para determinar o sucesso ou falha do teste.
\end{description}

\section{ATEMES}
$ATEMES$~\cite{atemes} é uma ferramenta para automação de teste para sistemas embarcados \textit{multicore}. Dentre os tipos de teste suportados estão os aleatórios, de unidade, cobertura, desempenho e condições de corrida. A ferramenta também prevê instrumentação do código, geração de casos de uso e de dados de entrada para sistemas de múltiplos núcleos. 

Para desempenhar todas estas funções $ATEMES$ conta com os seguintes componentes:
\begin{itemize}
	\item{\textbf{PRPM}} - módulo de pré-processamento - cujas atribuições consistem em a análise de código fonte, geração automática de casos de teste, geração automática dos dados de entrada de teste e instrumentação do código fonte. %Suas funções são automáticas, mas também é possível intervir manualmente nos testes através de uma interface.
	
	\item{\textbf{HSATM}} - módulo de teste automático do lado \textit{host} - é responsável por gerar automaticamente testes baseados em uma biblioteca pré-definida, compilar o código fonte para uma determinada arquitetura de \textit{hardware} e enviar a imagem executável para a plataforma alvo.
	
	\item{\textbf{TSATM}} - módulo de teste automático da plataforma de \textit{hardware} alvo - tem como principal função a execução da imagem recebida do $HSATM$, além de monitorar o andamento dos testes e enviar os dados desta execução. 
	
	\item{\textbf{POPM}} - módulo de pós-processamento - que analisa todos os resultados e dados coletados durante o teste.
\end{itemize}

A partir destes componentes é possível executar os testes em uma plataforma alvo a partir de uma estação de trabalho remota, diminuindo restrições quanto ao uso de recursos dos sistemas embarcados. Para tanto, o \textit{software} passa por uma compilação cruzada no lado \textit{host} (estação de trabalho) e é enviado automaticamente para a plataforma alvo onde é executado. 

As atividades são gravadas em um registro, dentre estes registros estão os dados de execução do sistema, o tempo de utilização de cada núcleo da CPU durante a execução dos testes, o resultado de saída, entre outros. O registro pode ser passado para o lado \textit{host} em tempo de execução, onde pode ser armazenado, processado e até apresentado de maneira visual através de uma interface.

\begin{description}
\item[Resumo]  \hfill \\
Ao explorar sistematicamente a automação de testes de \textit{software} embarcado e componentizar cada operação necessária, $ATEMES$ apresenta uma solução de grande desempenho para sistemas multiprocessados. A ferramenta é tão robusta que é possível inclusive automatizar a geração de casos de testes à partir da análise do código fonte.

Conforme será visto no Capítulo~\ref{ref:ambiente}, a abordagem de execução automática de testes  de $ATEMES$ é similar ao deste presente trabalho. Ambos utilizam depuração cruzada para compilar o código fonte para uma determinada arquitetura de \textit{hardware} e monitoram a execução desta imagem à partir de uma conexão remota. O registro dos dados de execução dos testes e a apresentação de um relatório para o usuário também é uma semelhança notória.
\end{description}

\section{Automação da execução de testes baseada na interface do sistema alvo}
Este trabalho apresenta uma abordagem o testes de sistemas embarcados heterogêneos e baseada nas características do \ac{SUT}~\cite{universal:2013}. 

Diferente da escolha tradicional, que normalmente é feita a partir de uma mistura de vários modelos para tentar alcançar o maior número possível de arquiteturas, a \ac{TBT} reforça que cada sistema embarcado possui características únicas e que devem ser consideradas na escolha do modelo de teste que será aplicado ao sistema.

A \textit{framework} criada utiliza-se de um módulo \ac{DID} que fica conectado diretamente com o sistema embarcado. Este módulo é o responsável por detectar o sistema, descobrir suas características (\textit{drivers} e interfaces) e apontar os testes que melhor se encaixam ao perfil do sistema conectado.  

Entretanto, para que seja possível a extração das informações do sistema alvo e realizar a execução automática dos testes o \ac{SUT} deve ter o projeto de testes baseado em interfaces, ou seja, cada módulo quem compõe o sistema deve implementar uma determinada interface de testes. 

Com estas informações, o mecanismo de teste da \textit{framework} consegue sugerir e executar três tipos de teste. Os testes gerais são sugeridos para sistemas que compõem o sistema embarcado como, por exemplo, capacitores, resistores, \textit{leds}, sensores, etc. Os testes internos verificam cada componente em separado e podem ser realizados com a ajuda de ferramentas que geram algoritmos para sistemas embarcados. Os testes externos verificam o sistema como um todo, contemplando também a integração do sistema.

Em uma nova versão da abordagem~\cite{priyaneural} o mecanismo de teste foi adaptado para considerar um oráculo, composto por uma rede neural de 2 camadas com retroalimentação. O treinamento desta rede neural ocorre a partir de execuções corretas do sistema embarcado até que o oráculo tenha um modelo de simulação do \textit{software} com a precisão desejada. 

Quando novas versões do sistema original forem lançadas, o \textit{software} é novamente executado e sua saída é incorporado através da retroalimentação. O resultado obtido pelo ensaio deve ser comparado com a saída do oráculo para determinar se está correto ou não.

\begin{description}
\item[Resumo]  \hfill \\
O destaque desta abordagem está na escolha de técnicas para teste de sistemas heterogêneos. A \textit{framework} apresenta uma característica que pode facilitar muito a automação de testes para sistemas embarcados, pois desenvolver testes específicos para um sistema embarcado e que ainda sejam independentes do ambiente de implantação (\textit{deploy}) não é uma tarefa trivial. 
	
A adaptação do mecanismo de testes para o uso de um oráculo composto por uma rede neural é com certeza outro diferencial, tornando possível que a \textit{framework} aprenda com os próprios resultados e consiga generalizar ou especializar uma determinada configuração de testes.

No capítulo~\ref{sec:tap} será possível verificar uma grande semelhança no processo de avaliação dos testes para determinar seu sucesso/falha, principalmente quando utilizada a estratégia de comparação entre os resultados das execuções realizadas.
\end{description}

\section{Partição do \textit{software}}
O conceito de partição do \textit{software} surgiu da afirmação de que quando as pessoas estão depurando um \textit{software}, o processo mais comum é fazer abstrações mentais correspondentes a partes do todo. Desta forma desenvolve-se a hipótese de integrar particionadores de código-fonte nos ambientes de depuração~\cite{Weiser:1981}.

Após a definição de Weiser, a partição foi utilizada em diversas áreas da computação, como paralelização, ajuste de níveis de compilação, engenharia reversa,  manutenção de \textit{software}, testes, entre outros. Na área de depuração, focou-se na partição sistemática do \textit{software}, investindo na remoção de estados ou caminhos que são irrelevantes para alcançar o objetivo selecionado, o que no caso da depuração é encontrar um erro~\cite{Xu:2005:BSP:1050849.1050865}. 

Cada trabalho apresenta um critério diferente para particionar, mas todos possuem o conceito de fatia (\textit{slice}) como um subconjunto de predicados do programa que afetam os valores computados, de acordo com o critério de controle. Uma distinção importante para particionar é o tipo de fatia que será realizada: estática, dinâmica ou uma variação delas~\cite{sasirekha2011program}.

A partição estática é o tipo mais rápido e, em contrapartida, aponta apenas uma aproximação do conjunto final de caminhos que podem levar ao erro. Isto ocorre porque o foco é simplificar ao máximo o \textit{software} em questão, reduzindo-o ao ponto de conter todos os estados que poderiam afetar o valor final, mas sem considerar o valor de entrada do \textit{software}. Este tipo de partição é mais utilizada para \textit{software} de pequeno porte e de pouca complexidade, em que o tamanho da partição permanece compatível com a sua simplicidade.

Na partição dinâmica, as informações do critério de corte tradicional não são suficientes, sendo necessária uma informação adicional sobre os valores de entrada do \textit{software}. A partição será realizada a partir destes dados e sequência de valores de entrada no qual o \textit{software} foi executado é determinante para o conjunto de saída. Esta partição é mais utilizada para \textit{software} complexo e de alto grau de acoplamento.

Além dos tipos base de partição, também existem modelos que são variações de um dos dois principais ou até gerados pela união de modelos~\cite{Venkatesh:1991,binkley2005minimal,Sridharan:2007:TS:1250734.1250748,Chebaro:2012}, proporcionando uma maior configurabilidade de depuração e atendendo melhor às características do \ac{SUT}.

\begin{description}
\item[Resumo]  \hfill \\
A automação da partição do código deriva de uma abstração tradicionalmente utilizada por seres humanos durante a depuração. Desde que foi computacionalmente implementado, surgiram inúmeras variações no critério de partição, tamanho da fatiar o programa e alternativas para o cálculo das fatias. A principal razão desta diversidade está na peculiaridade de cada \textit{software}, onde cada característica requer uma maneira diferenciada de realizar a partição.

Independente da abordagem selecionada, a partição do código é uma técnica versátil e muito utilizada, principalmente porque necessita apenas de uma execução com falhas para ser capaz de simplificar o \textit{software} em \textit{slices}, cujo grupo de entradas a serem examinadas é bem reduzido. Poder selecionar pequenos componentes do código-fonte para seres testadas e depuradas em partes é uma das principais características da ferramenta apresentada no capítulo~\ref{sec:tap}.
\end{description}

\section{Depuração estatística}
Trabalhos baseados em depuração estatística utilizam-se de dados estatísticos relacionados a várias execuções do sistema para isolar um \textit{bug}. Esta análise reduz o espaço de busca utilizando-se de recursos estatisticamente relacionados ao fracasso, limitando assim o conjunto de dados até chegar a uma seleção em que o erro se faz presente. 

O primeiro passo deve ser a instrumentação do \textit{software} para coletar dados sobre os valores de determinados tipos de predicados em pontos específicos da execução do \textit{software}. Existem três categorias de predicados rastreados:
\begin{itemize}
\item \textbf{Ramificação} - para cada condicional encontrado são gerados dois predicados: um que indica o se o caminho escolhido foi o da condição verdadeira e outro que indica a escolha do caminho caso a condição seja falsa.
\item \textbf{Retorno de funções} - cada retorno de função com um valor escalar são gerados seis tipos de predicados para rastrear o valor: $>0$, $\geq0$, $=0$, $<0$, $\leq0$, $\neq0$.
\item \textbf{Atribuição} - em toda atribuição escalar também são gerados seis tipos de predicados para comparar os valores: $>$, $\geq$, $=$, $<$, $\leq$, $\neq$.
\end{itemize}

Essas informações são armazenadas em relatórios como um vetor de \textit{bits}, com dois \textit{bits} para cada predicado - um para o resultado observado e outro para o resultado verdadeiro e um bit final que representa o sucesso ou falha da execução. Em sequência, são atribuídas pontuações numéricas para identificar qual foi o predicado que melhor expressa o conjunto de predicados.

Como a análise é realizada a partir de uma depuração estática, estes modelos expõem as relações entre comportamentos do \textit{software} e seu eventual sucesso/fracasso de uma maneira estática. Então é possível fornecer uma identificação aproximada de qual parte do sistema gerou o erro.

\subsection{Depuração estatística baseada em amostras}
É uma das primeiras abordagens que propõe recolher os dados estatísticos através de declarações inseridas no código e, em tempo de execução, consegue coletar dicas sobre os dados que não estão relacionados com as falhas~\cite{zheng2003statistical}.

Um dos desafios desta proposta é coletar os dados necessários sem penalizar a execução do \textit{software} e garantindo a melhor utilização de todos os recursos do sistema. A solução encontrada foi inserir um evento aleatório junto às declarações inseridas no \textit{software}, possibilitando que apenas uma pequena parte delas seja executada para cada nova execução do sistema.

A partir desta probabilidade foi possível reduzir tempo gasto para coletar os dados, já que não é obrigatório executar todas as declarações em todas as execuções do sistema. Além disso, as amostras recebidas são agregadas sem a informação de cronologia e considerando apenas a quantidade de vezes em que o resultado das declarações permaneceu o mesmo, o que minimiza o espaço necessário para armazenar os dados.

%\begin{comment}
\subsection{Depuração estatística baseada em predicados}
Este modelo tem o propósito de identificar a origem dos erros em um \textit{software} com uma modelagem probabilística de predicados, considerando inclusive que o \textit{software} pode conter mais de um erro simultaneamente~\cite{zheng2006statistical}.

A manipulação de predicados espelhados pelo código fonte não é um trabalho trivial, e isso faz com que muitos modelos não consigam selecionar padrões de erros úteis. Para mitigar este problema a depuração estatística baseada em predicados utilizada técnicas semelhantes às dos algoritmos \textit{bi-clusters},  que permite a extração de dados bidirecionais simultaneamente.

A implementação da extração de dados bidirecional executa um processo de votação coletiva iterativo, no qual todos os predicados tem um número que define a qualidade de representação. Este número pode ser modificado durante a execução do algoritmo através da distribuição de votos. Cada execução em que ocorre um erro tem direito a um voto para selecionar o predicado que melhor se encaixa na situação.

Esta solução é interessante porque reduz o problema de redundância, pois o processo de votação só acaba quando houver convergência e quanto maior o número de predicados competindo pelo votos, menor é a quantidade de votos que cada um deles pode ter. 

Depois de cada execução um predicado pode receber tanto um voto completo quando uma parcela do voto. No final, os predicados são classificados e selecionados considerando o número de votos que receberam.

%\subsection{Depuração estatística através do perfil da execução}
%\cite{chilimbi2009holmes}

\begin{description}
\item[Resumo]  \hfill \\
Os trabalhos que utilizam-se de depuração estatística necessitam de um grande volume de dados para realizar uma análise confiável das informações e retornar resultados válidos. Este técnica é de difícil implementação em um sistema embarcado real por não estarem preparados para tal armazenamento. Entretanto, conforme será demonstrado nos capítulos seguintes, é possível coletar e armazenar estes dados no caso da depuração remota.

A depuração estatística baseada em amostras contribui com a discussão sobre a necessidade de ativar todos os possíveis estados do \textit{software} em todas as execuções do sistema para que seja possível descobrir a origem do erro. Sabe-se que ao inserir declarações aleatórias no \textit{software} é possível reduzir a quantidade de dados a serem analisados, visto que apenas uma parte é executada a cada rodada. 

A aleatoriedade pode ser um aliada na depuração do sistema, mas deve-se tomar cuidado com a quantidade de predicados e valores que os mesmos podem atingir. Para eliminar predicados pouco representativos, alternativas como \textit{ranking} e votação foram apresentadas. Levando em conta estes aspectos, o presente trabalho possui no Capítulo~\ref{sec:tap} uma discussão sobre a configuração da do sistema, para que a aleatoriedade não prejudique o resultado desejado.
\end{description}

\section{Depuração por delta}
A técnica de \ac{DD} estabelece uma hipótese sobre o motivo de um \textit{software} parar de funcionar corretamente e, dependendo dos resultados da execução dos testes, esta hipótese deve ser refinada ou rejeitada~\cite{zeller1999yesterday}. A ideia do \ac{DD} é chegar a um mínimo local, onde todos os eventos presentes interferem diretamente no comportamento incoerente do \textit{software}.

Assumindo-se que o erro é determinístico e que pode ser reproduzido automaticamente, é possível refinar a hipótese ao remover de forma iterativa os trechos do \textit{software} que não colaboram na ocorrência do erro. O mesmo ocorre com a rejeição da hipótese, quando um trecho é retirado e o \textit{software} não apresenta mais o erro. 

Para automatizar a escolha, refinamento e rejeição de hipóteses, a \ac{DD} trabalha com dois algoritmos:
\begin{itemize}
\item \textbf{Simplificação} - este algoritmo foca na simplificação da entrada que ocasionou a falha do teste. Para tanto, a entrada é analisada e tenta-se reduzir ao máximo sua complexidade, até que não seja mais possível simplificá-la sem eliminar o fracasso dos testes.
\item \textbf{Isolamento} - algoritmo para encontrar uma configuração na qual a adição ou remoção de um elemento tem influência direta no resultado dos testes. Ele é ideal para encontrar os subconjuntos de um caso de falha.
\end{itemize}

A automação dos testes e da depuração procura determinar as causas do comportamento inadequado a partir da observação as diferenças (deltas) entre versões. Ela pode ser utilizada para simplificar ou isolar causas da falha e pode ser aplicado a qualquer tipo de dado que afete de alguma forma a execução do \ac{SUT}.

Nesta abordagem é comum trabalhar com o teste e a depuração em conjunto, inclusive porque refazer a execução dos testes de um \textit{software} sob novas circunstâncias é uma técnica comum de depuração e, muitas vezes, é a única maneira de provar que as novas circunstâncias realmente podem causar a falha~\cite{zeller2002simplifying}.

\subsection{Depuração por delta com hierarquias}
A técnica genérica de \ac{DD} utiliza os algoritmos de simplificação e isolamento para fornecer um subconjunto onde encontra-se a mudança que possivelmente causou o erro. Porém, em casos mais complexos o \ac{DD} perde um pouco de eficácia e aponta para vários subconjuntos com falha nos testes e cujas entradas não são tão simplificadas.

O HDD - \textit{Hierarchical Delta Debugging} \cite{Misherghi:2006} surgiu para melhorar o desempenho dos algoritmos do \ac{DD}, principalmente quando o código-fonte analisado possui uma estrutura hierárquica e semântica, ou seja, o \ac{SUT} não é apenas uma estrutura de linhas desconexas e independentes. 

A ideia é aproveitar a estrutura hierárquica da entrada para reduzir o número de tentativas inválidas, pois explorando a estrutura dos dados de entrada é possível melhorar a convergência e chegar mais rápido à estrutura simplificada.

Para considera a hierarquia, o algoritmo de simplificação \ac{DD} foi modificado para operar em uma árvore de sintaxe abstrata e sua implementação foi aplicada para avaliar arquivos \ac{XML} e programas escritos em $C$. A versão \ac{XML} explora diretamente a estrutura hierárquica da entrada, extraindo sub-árvores, folhas, atributos e até caracteres. Para a versão $C$ foi necessário gerar um analisador do código-fonte, essencial para manipular o \textit{software} de acordo com a árvore de sintaxe simplificada.

\subsection{Depuração por delta e iterativa}
Para identificar o mínimo local a \ac{DD} necessita de duas versões do \textit{software}: uma falha e uma correta. Contudo, quando um novo erro é descoberto, pode ser que a versão anterior também contenha o mesmo erro e será necessário procurar em versões ainda mais antigas, até encontrar uma versão correta para aplicar o delta. 

A escolha desta de versões foi abordada pelo \ac{IDD}~\cite{artho2011iterative}, o qual automatizou a busca dessa versão correta através de comparações iterativas. O conjuntos de testes também são executados de forma automática para cada iteração e o algoritmo prosseguem até que uma das três condições sejam atingidas:(i) a versão que passa pelos testes é encontrada, (ii) não haja mais versões antigas disponíveis no repositório, ou (iii) foi alcançado o tempo limite da busca.

Durante a comparação, sempre que a execução do \textit{software} não alcança o sucesso porque diverge do esperado (ex. erros de compilação, \textit{looping} infinito, mudanças sintáticas), os algoritmos de \ac{DD} fazem pequenos \textit{patch} para preservar o resultado anterior. No caso de não ser possível aplicar o \textit{patch}, o \ac{IDD} considera o resultado como fracasso.

Para garantir que os algoritmos do \ac{DD} não remova trechos de código que contribuem para o valor do resultado do teste, o \ac{IDD} também automatizou o monitoramento de dados importantes da execução, dos arquivos de log, consumo de memória e o tempo necessário para executar o \textit{software} tanto para ambas versões do delta.

\begin{description}
\item[Resumo]  \hfill \\
A base da \ac{DD} está em analisar a diferença entre duas versões do sistema e isolar/analisar as possíveis causas do comportamento inesperado automaticamente quando alguma divergência é identificada na execução da nova versão.

Se o delta for bem aplicado, a estrutura que resta aponta apenas para os elementos relevantes no fracasso do teste do \textit{software}. Entretanto, no caso de grandes mudanças, a estrutura restante pode ser complexa e apresentar um grande número de dados para explorar. 

Alguns trabalhos subsequentes concentraram em maneiras mais assertivas de reduzir o conjunto de entradas e isolar o problema. Uma delas é a $HDD$, que utiliza-se de dados referentes à hierarquia do programa para agilizar o trabalho realizado pelo algoritmo de redução. Outra alternativa interessante é o \ac{IDD}, que procura o melhor delta entre várias versões disponíveis no repositório.

A comparação de versões no repositório é uma técnica interessante de depuração e pode ser aplicada inclusive para a geração de relatórios e gráficos sobre a consistência do \textit{software}. No capítulo~\ref{sec:tap} será apresentado um algoritmo quem também se utiliza do delta para determinar sucesso/falha dos testes do \ac{SUT}.
\end{description}

%\subsection{Capturing propagation of infected program states}
%\cite{zhang2009capturing}

\section{Captura e Reprodução}
A ideia da técnica de captura e reprodução consiste em selecionar um subsistema do \textit{software} como alvo do estudo, capturar todas as operações entre este subsistema e o resto do \textit{software} e depois reexecutar as operações isoladas do subsistema~\cite{orso2005selective}.

Este tipo de depuração permite que o desenvolvedor controle a nova execução do \textit{software} com execução de passos a frente, voltando passos na execução (contra o fluxo), examinando o contexto de alguma variável, verificando um determinado controle de fluxo, analisando fluxos alternativos, entre outras possibilidades.

A ferramenta $JINSI$ foi implementada para aplicar os conceitos de captura e reprodução para programas na linguagem Java~\cite{orso2006isolating}. Dado um sistema e um componente presente no sistema, $JINSI$ grava as interações entre esse componente e o resto do sistema. Neste contexto, o componente é considerado como um conjunto de classes com uma função definida.

$JINSI$ foi novamente abordada por Burger e Zeller~\cite{burger2008replaying}, adquirindo a capacidade de capturar e reproduzir as interações intercomponentes e intracomponentes. Assim, todas as operações relevantes são observadas e executadas passo a passo, considerando-se todas as comunicações entre dois componentes até encontrar o \textit{bug}.

Um grande desafio nesta técnica é como se adaptar a interrupções, pois toda a estrutura de reprodução do \textit{software} se baseia no fluxo de controle e uma interrupção tem a capacidade de romper esta sequência. Afina, interrupções podem ocorrer a qualquer momento e provocar uma ruptura no fluxo de controle e, desta forma, barrar a execução do programa na instrução atual para continuar a partir da rotina de tratamento de interrupção.

Neste aspecto, a solução de tirar um \textit{snapshot} do contexto de execução quando ocorre uma interrupção~\cite{Sundmark} se mostra uma boa alternativa para que o desenvolvedor possa analisar erros oriundos de interrupções.

%\subsection{Locating failure-inducing environment changes}
%\cite{qi2011locating}

\begin{description}
\item[Resumo]  \hfill \\
Captura e Reprodução sempre foi muito utilizada para testes de interface, em que a interação do usuário com o \textit{software} era armazenada para poder servir como caso de testes. Desta forma torna-se possível realizar testes de funcionalidade do sistema de acordo com o estímulo do usuário.

Já a depuração é um caso mais específico, pois nem todo erro pode ser reproduzido, mesmo que todas as ações sejam reexecutadas na mesma ordem. Contudo, para um erro determinístico em que se tem todas as operações que podem ter causado de um determinado erro, é possível realizar uma investigação baseada no fluxo de controle do \textit{software}.

A ferramenta $JINSI$ foi utilizada para corroborar a técnica, que além de capturar e reproduzir o \textit{software}, agora também incorporou os algoritmos de \ac{DD} para isolar o subconjunto de interações relevantes para simular o erro.
\end{description}

\chapter{Ambiente compartilhado de teste e depuração}
\label{ref:ambiente}
Este capítulo apresenta o ambiente compartilhado de teste e depuração, demostrando de onde as ideias foram extraídas, adaptadas e, em alguns casos, melhoradas. Além disso, serão apresentas instruções para integrar a execução de testes com os possíveis ambientes de depuração, gerando o ambiente compartilhado de desenvolvimento.

Para definir a infraestrutura do ambiente foram analisados vários ambientes de execução automática de testes e de depuração, ambos com foco em sistemas embarcados. Esta especialização tornou-se necessária pois estas atividades compartilharão os recursos do \ac{SUT}, o que no caso de sistemas embarcados é crítico pois geralmente possuem apenas os recursos essenciais para desempenhar uma determinada função. 

Um exemplo de sistema embarcado com um alto grau de dificuldade para atividades de teste e depuração é a \ac{RSSF}. Este tipo de rede pode ser composta por vários sensores que, além de permanecerem espalhados geograficamente por uma grande área de monitoramento, geralmente possuem pouco poder de processamento e apenas alguns \textit{kilobytes} de armazenamento~\cite{pottie2000wireless}.

No caso de muitas \ac{RSSF} é impraticável coletar todos os sensores para realizar testes, pois além da dificuldade de acesso às áreas em que os sensores atuam, as atividades de monitoramento teriam que sofrer uma pausa até o término do teste. A solução mais comum nestes casos é realizar os testes de \textit{software} e \textit{hardware} separadamente, utilizando-se simulação.

Contudo, simular separadamente as componentes não garante o funcionamento de sua integreção. Em sistemas embarcados é comum que \textit{software} e \textit{hardware} trabalhem em conjunto para desempenhar uma tarefa. Aliás, grande parte das falhas nos testes de um \textit{software} embarcado são oriundos da integração de componentes heterogêneos~\cite{seo}. 

Uma das alternativas para se atenuar este efeito é utilizar emulação completa do sistema, que possibilita a visualização do estado do \textit{software} além de permitir o controle de sua execução\cite{KiSCL08}. Desta maneira, é possível analisar a intersecção entre componentes e monitorar a execução dos testes através da tabela de símbolos.

O processo de teste para sistemas heterogênicos é uma tarefa trabalhosa, principalmente quando não se sabe qual ambiente de implantação será utilizado~\cite{universal:2013}. Existem várias alternativas para ajudar na tarefa e aprimorar a qualidade dos testes, como utilizar oráculo como um repositório de testes~\cite{priyaneural}, selecionar \textit{checkpoints} baseados na interfaces dos componentes~\cite{KiSCL08}, módulos de pré-processamento com análise de código fonte~\cite{atemes}, entre outros.

Sabe-se que o processo de depuração também precisa de ferramentas específicas para auxiliar no monitoramento da execução de um programa. O sucesso das técnicas que focam em automação da depuração não dependem apenas dos algoritmos ou dados coletados, mas também da estabilidade fornecida pelo ambiente para desempenhar tais atividades. Por exemplo, nas ferramentas de captura e reprodução~\cite{orso2005selective, orso2006isolating, qi2011locating} é essencial que a etapa de captura grave todas as operações que levam ao erro.

\section{Configuração do ambiente remoto}
As ferramentas utilizadas para a construção deste ambiente remoto podem ser substituídas por qualquer outra equivalente, contudo, a configuração completa será tecnicamente apresentada para que seja possível a reprodução do experimento.

O ambiente compartilhado proposto utiliza o $QEMU$ para emular a máquina com a aplicação alvo a partir de outra máquina, usando tradução dinâmica. Desta forma torna-se possível utilizar um computador pessoal para testar aplicações compiladas para algum outro sistema embarcado. O \ac{GDB} encaixou-se no papel de depurador, pois nele é possível especificar qualquer regra que possa afetar seu comportamento de maneira estática.

A integração da execução dos testes e da depuração é particular para cada máquina hospedeira e alvo, portanto, talvez alguns passos aqui apresentados devam ser adaptados para a arquitetura alvo. 

A Figura~\ref{fig:emulator_debugger_gray} apresenta as atividades necessárias para executar a depuração remota em conjunto com a simulação dos testes.

\fig{emulator_debugger_gray}{Atividades de integração entre emulador e depurador}{scale=.25}

Uma explicação adicional das técnicas e ferramentas utilizadas neste processo estão listados abaixo:

\begin{description}
\item[1. Compilar com informações de depuração] \hfill \\
Este passo realiza uma compilação simbólica e sem otimizações. A otimização correta é importante para a execução do \textit{software}, mas quando o foco é a depuração o ideal é que não haja muita diferença entre o código-fonte e as instruções geradas.

Como entrada é necessário o código-fonte do \textit{software} e como saída esperada encontra-se o código compilado com informações de depuração. O \ac{GCC} realiza esta atividade quando acrescentada a opção $-g$ para compilar. 
	
\item [2. Emular o sistema utilizando um emulador] \hfill \\
É um passo necessário para executar a \textit{software} na arquitetura alvo correta. É importante ressaltar que o \textit{software} a ser emulado não deve iniciar a execução antes que o depurador esteja conectado. Caso isso ocorra, não será possível inspecionar todos os detalhes da execução.

Para executar este passo utilizamos o $QEMU$, que deve ser inicializado com os argumentos $-s -S$. A primeira opção ativa o \textit{stub} para conectar um depurador, a fim de abrir a comunicação entre o emulador e o depurador. A opção $-S$ é utilizada para forçar que o $QEMU$ espere a conexão do depurador antes da inicialização do sistema.
Por exemplo, se uma aplicação compilada com informações de depuração ($app.img$) imprime algo na tela ($stdio$), a chamada do $QEMU$ deve ser semelhante à: $qemu$ $-fda$ $app.img$ $-serial$ $stdio$ $-s$ $-S$
	
\item [3. Conectar-se com o depurador] \hfill \\
Esta conexão é importante para fornecer ações ao usuário, tais como: executar o programa passo-a-passo, pausar/reiniciar a execução, entre outras. Para fornecer a estabilidade necessária para a infraestrutura gerada, a conexão do depurador será realizada de maneira remota.

Para que a depuração seja remota a sessão do depurador deve ser inicializada em um ambiente separado. Então, para se conectar ao depurador ao $QEMU$ o desenvolvedor deve explicitar que o alvo a ser examinado é remoto e informar o endereço da máquina alvo e porta em que se encontra o alvo a ser examinado. Utilizando-se o \ac{GDB}, a tela será iniciada a partir do comando: $target$ $remote$ $[endereço\_alvo]:[porta\_alvo]$

\item [4. Recuperar as informações de depuração] \hfill \\
O arquivo gerado no primeiro passo   contém todas as informações que podem ser retiradas da compilação, como por exemplo o endereço de uma variável, ou os nomes contidos na tabela de símbolos. Então este passo é importante para ajudar os desenvolvedores a encontrarem erros.

O arquivo usado para manter as informações de depuração deverá ser informado para o \ac{GDB} usando o comando: $file$ $[caminho\_do\_arquivo]$
	
\item [5. Encontrar origem dos erros] \hfill \\
Encontrar e corrigir erros é uma atividade depende do programa a ser depurado. A partir desta etapa, o desenvolvedor pode definir \textit{breakpoints}, \textit{watchpoints}, controlar a execução do programa e até mesmo permitir \textit{logs}. 

Existem vários trabalhos com o foco em ajudar a encontrar os erros através da automação de alguns pontos, como a gerarão automática de \textit{breakpoints}~\cite{JSWjsw0803603616} e o controle do fluxo de execução \cite{Chern:2007}.
\end{description}

Após a definição da infraestrutura compartilhada para testes e depuração também foi necessário dividir as funções para cada uma das atividades. A ideia é utilizar o emulador para a automação da execução do \textit{software} e de seus casos de teste. A depuração será iniciadas somente no caso de sucesso em um teste, ou seja, quando um erro é detectado.

\chapter{Troca automática dos parâmetros de \textit{software}}
\label{sec:tap}
No desenvolvimento para sistemas embarcados é comum que uma especificação seja reutilizada, diferenciando apenas alguns requisitos não funcionais. Esta estratégia visa utilizar a propriedade intelectual já adquirida para reduzir o tempo para que um novo produto entre no mercado~\cite{gupta1997introducing}.

Normalmente o núcleo do sistema é formado por componentes previamente concebidos e verificados~\cite{743146} Esta base é conectada à extensões, que são adaptações ou implementação de novos componentes de \textit{software} ou \textit{hardware} para atender à um determinado requisito. Para cada nova extensão, um novo conjunto de testes é gerado para garantir o novo sistema.

Além do reuso, o desenvolvimento deste tipo de sistemas costuma ter o baixo consumo de recursos como um requisito essencial. Logo, meios que possibilitam tanto o reuso de código quanto a menor sobrecarga possível sobre o sistema, são desejáveis~\cite{1704131}. 

O teste de um sistema embarcado deve seguir a mesma linha de raciocínio, para tanto, o algoritmo de \ac{TAP} procura atender estes requisitos ao extrapolar os conceitos da metodologia de projeto orientado aplicação e técnicas de abstração de dados para o universo dos testes. 

Em um projeto orientado à aplicação o sistema é desenvolvido a partir de componentes especificamente adaptados e configurados de acordo com os requisitos da aplicação alvo. Ou seja, o próprio projeto do sistema oferece a garantia de que tudo compõe a aplicação é essencial para seu funcionamento. Os conceitos de \ac{ADESD} na concepção do \textit{software} podem reduzir o tempo gasto com o teste e a depuração do sistema.

Com o uso de \ac{ADESD} pode-se considerar que a entrada do sistema já está simplificada, sendo equivalente à técnicas de depuração delta. Desta forma, não é necessário utilizar técnicas como, por exemplo, partições do código para diminuir a complexidade do sistema. 

Ademais, no desenvolvimento de \textit{software} é importante que cada funcionalidade significativa seja executada em apenas um lugar no código fonte. Caso existam funções semelhantes espalhadas pelo código, é interessante e benéfico combiná-las em uma única abstração e derivar apenas as funcionalidades individuais de cada função~\cite{abelson1996structure}. 

O reuso do projeto do sistema embarcado permite que todo o sistema seja reaproveitado, exigindo apenas um conjunto de testes complementar para cada extensão anexada. Uma vez que o núcleo já possui verificação~\cite{743146}, o conceito de abstração de dados no universo de teste pode ser aplicado nas extensões do núcleo. A abstração de casos de teste deve ser composta por testes da própria abstração e testes relacionados ao comportamento específico de cada requisito não funcional.

Para aproveitar esta vantagem, o algoritmo de \ac{TAP} trabalha com a premissa de que este sistema seja orientado a aplicação, com modelagem baseada em \textit{features} e parametrização. Também é desejável que cada abstração do sistema seja configurada conforme necessário através de \textit{traits} de um modelo de \textit{templates}~\cite{Stroustrup:c++}.

\section{Algoritmo de troca de parâmetros}
No algoritmo~\ref{algoritmo_AEP} são apresentados os passos realizados a partir do momento em que se tem um \ac{SUT} até o retorno do relatório para o usuário. A entrada do algoritmo é o arquivo de configuração que possui o caminho do \ac{SUT} e de seus \textit{traits}. A partir destas informações o algoritmo flui no sentido de tentar encontrar a característica desejada, trocá-la por uma valor predeterminado, executar a nova aplicação e recolher o retorno da aplicação.

\begin{algorithm}
\caption{Algoritmo de troca dos parâmetros de configuração}\label{algoritmo_AEP}
\KwIn{arquivo}
\KwOut{relat\'{o}rio}
propriedades $\Leftarrow$ pegarPropriedadeDoArquivo(arquivo)\;
\eIf{ o arquivo possui valor para configura\c{c}\~{a}o }{
  \ForEach{configura\c{c}\~{a}o no arquivo}{
             linha $\Leftarrow$ pegarConfiguracao(configura\c{c}\~{a}o, propriedades)\;
\ForEach{valor para configura\c{c}\~{a}o}{
        novaPropriedade$\Leftarrow$ modificarValorPropriedade(linha, propriedades) \;
        novaAplicacao$\Leftarrow$ compilar(aplica\c{c}\~{a}o, novaPropriedade) \;
        relat\'{o}rio$\Leftarrow$ relat\'{o}rio + emular(novaAplicacao) \;
             }
}
}{
\eIf{ o arquivo possui n\'{u}mero m\'{a}ximo de tentativas}{
        numMaxTentativas$\Leftarrow$ pegarTamanhoMaximo(arquivo)\;
}{
        numMaxTentativas$\Leftarrow$ gerarValorAleatorio()\;
  }
\While{tentativas $<$ numMaxTentativas}{
    linha$\Leftarrow$ gerarValorAleatorio()\;
	novaPropriedade$\Leftarrow$ modificarValorPropriedade(linha, propriedades)\;
    novaAplicacao$\Leftarrow$ compilar(aplica\c{c}\~{a}o, novaPropriedade)\;
    relat\'{o}rio$\Leftarrow$ relat\'{o}rio + emular(novaAplicacao)\;
  }
}
\Return relat\'{o}rio;
\end{algorithm}

A vantagem de unir \ac{ADESD} e abstrações de dados ao desenvolvimento/teste de sistemas embarcados é poder aplicar um único conjunto de testes para todas as implementações que seguem uma mesma especificação, especializando apenas a configuração desejada. Desta forma, é possível executar o mesmo conjunto de testes para atender uma maior variabilidade de configurações um componente de \textit{software} ou \textit{hardware}.

\section{Detalhes da implementação}
\ac{TAP} é a ferramenta que implementa o algoritmo de troca de parâmetros de execução e utiliza o ambiente compartilhado para realizar a automação da execução dos testes e depuração de sistemas embarcados. 

A implementação do algoritmo deve utiliza como base um sistema operacional com uma grande capacidade de configuração do sistema. O \ac{EPOS} é \ac{EPOS} é um \textit{framework} baseado em componentes que fornece todas as abstrações tradicionais de sistemas operacionais e serviços como: gerenciamento de memória, comunicação e gestão do tempo~\cite{Froehlich:2001}. Além disso, possui vários projetos industriais e acadêmicos que o utilizam como base~\footnote{http://www.lisha.ufsc.br/pub/index.php?key=EPOS}.

Este sistema operacional foi concebido com \ac{ADESD} e é instanciado apenas com o suporte básico para sua aplicação dedicada. É importante salientar que todas as características dos componentes também são características da aplicação, desta maneira, a escolha dos valores destas propriedades tem influência direta no comportamento final da aplicação. 

Neste contexto, a troca automatizada destes parâmetros pode ser utilizada tanto para a descoberta de um \textit{bug} no programa quanto para melhorar o desempenho para a aplicação através da seleção de uma melhor configuração.

Cada aplicação gerada possui um arquivo próprio de configuração de abstrações para definir o seu comportamento. A Figura~\ref{progcpp:traitbuild} mostra um trecho desta configuração, que neste caso foi configurada para executar no modo biblioteca para a arquitetura $IA-32$ (\textit{Intel Architecture, 32-bit}), através de um $PC$ (\textit{Personal Computer}).

\progcpp{traitbuild}{Trecho do \textit{trait} da aplicação \ac{DMEC}.}


Para melhorar a usabilidade da ferramenta, é possível definir um arquivo de configuração com as informações necessárias para executar os testes unitários e de tipagem. O uso de arquivos \ac{XML} para definir as configurações de teste se deu pela facilidade e legibilidade para definir todas as regras necessárias para executar o algoritmo e, além disso, também é facilmente interpretado pelo computador.

A Figura~\ref{progxml:philosopherxml} traz um exemplo do arquivo de configuração de \ac{TAP} para uma aplicação exemplo.

\progxml{philosopherxml}{Exemplo do arquivo de configuração do teste para a \ac{TAP}.}

O arquivo do configuração é responsável pelo teste, então seu conteúdo deve estar sempre atualizado e em concordância com os requisitos da aplicação. O ajuste inicial é manual e simples, uma vez que este arquivo pode ser lido quase como um texto: há um teste para a aplicação "exemplo", dentro dela deseja-se especificar duas propriedades. A primeira é a propriedade identificada como \textit{ARCH} que pode assumir os valores \textit{IA32} ou \textit{AVR8}. A segunda está relacionada à depuração, é um arquivo que contém \textit{breakpoints} que está no seguinte caminho: "\textit{/home/breakpoints.txt}".

\section{Configuração da execução}
Cada configuração do teste interfere diretamente no tempo e eficácia da ferramenta. Prevendo este comportamento, \ac{TAP} oferece três granularidades de configuração para o teste: determinada, parcialmente aleatória e aleatória. Elas devem ser escolhidas de acordo com a finalidade do usuário ao executar a \ac{TAP}, do tipo de teste e das características de aplicação.

Quando se deseja testar uma especificação bem definida, é possível determinar qual valor uma propriedade deve atingir. Toda a especificação pode ser traduzida no arquivo de configuração e \ac{TAP} só considerará sucesso no teste as execuções que seguirem fielmente o descrito. O modo determinado também é interessante quando se deseja otimizar uma configuração, pois uma vez que o comportamento da aplicação e todas suas configurações sejam conhecidas, a única variável do sistema afetará o resultado final.

Testes parcialmente aleatórios são usados para verificar as configurações do sistema que não possuem um valor determinado, ou seja, mais de um valor pode ser considerado correto. Neste caso, a informação faltante na configuração será atribuída pelo \textit{script} no momento do teste. Sem nenhuma informação prévia, o algoritmo não garante que os valores gerados serão válidos e distintos uns dos outros, desta forma pode ser que o teste seja repetido e gere resultados com falsos negativos.

Teste aleatório foi desenvolvido como o pior caso. Ele só deve ser usado quando deseja-se testar valores fora do convencional para verificar a robustez da aplicação. Também é útil caso a aplicação falhe ao passar nos testes e não se tenha dica alguma sobre onde poderia estar o erro no momento de iniciar a depuração. Através dele pode-se encontrar valores errados de configuração e ajudar os desenvolvedores menos experientes a depurar pequenas aplicações.

\chapter{Resultados experimentais e análise}
\label{sec:case_study}
Para validar o algoritmo proposto, foi implementada uma ferramenta de automação da execução da a troca de parâmetros de configuração, que utiliza o ambiente compartilhado para a execução do teste e depuração de sistemas. Todos os experimentos foram elaborados para salientar os pontos positivos da proposta e também seus pontos de melhoria. 

A \ac{TAP} analisada à partir do teste e depuração de uma aplicação real que simula um componente de estimativa de movimento distribuída, o \ac{DMEC}. Este componente executa uma estimativa de movimento explorando a semelhança entre imagens adjacentes numa sequência de vídeo que permite que as imagens sejam codificadas diferencialmente, aumentando a taxa de compressão da sequência de \textit{bits} gerada. 

Estimativa de movimento é uma fase importante para codificação H.264 já que consome cerca de 90\% do tempo total do processo de codificação \cite{DMEC}. O teste de \ac{DMEC} verifica o desempenho de estimativa de movimento usando uma estratégia de particionamento de dados, enquanto os trabalhadores ($Workers$) realizam a estimativa e o coordenador ($Coordinator$) processa os resultados.

A Figura~\ref{fig:dmec} apresenta a interação entre as \textit{threads} coordenador e trabalhadoras. O coordenador é responsável por definir o particionamento de imagem, fornecer a imagem a ser processada e retornar resultados gerados para o codificador, enquanto cada trabalhador deve calcular o custo de movimento e os vetores de movimento.

\fig{dmec}{Interação entre o coordenador e os trabalhadores na aplicação teste do \ac{DMEC}~\cite{DMEC}.}{scale=.4}

\section{Ambiente de testes}
A aplicação \ac{DMEC} possui vários requisitos, dentre eles havia a necessidade de produzir as estimativas consumindo o menor tempo possível. Logo, a ferramenta foi utilizada na tentativa de aumentar o número de trabalhadores para tentar paralelizar o trabalho da estimativa. 

Consequentemente, o arquivo de configuração foi modificado para averiguar a configuração que representa o número de trabalhadores (\texttt{NUM\_WORKERS}). Inicialmente optou-se por um período fechado, iniciando-se em 6 (configuração original) e terminando em 60. 

O teste do limite inferior e superior são demonstrados, respectivamente, na Figura~\ref{fig:qemu_dmec_6_workers} e na Figura~\ref{fig:qemu_dmec_60_workers}. 

\fig{qemu_dmec_6_workers}{Teste do DMEC com configuração \texttt{NUM\_WORKERS} = 6}{scale=.4} \fig{qemu_dmec_60_workers}{Teste do DMEC com configuração \texttt{NUM\_WORKERS} = 60}{scale=.4}

Apesar da troca de parâmetros gerar várias configurações para o teste, apenas compilar o código não garante que a aplicação é livre de \textit{bugs}. No caso do número de trabalhadores igual a 60, o programa foi compilado, mas não foi possível emular sua execução. Nestes casos o depurador é automaticamente chamado para que se possa descobrir o porquê deste comportamento. 

A ferramenta então foi configurada para adicionar pontos de interrupção depois de iniciar cada uma das funções da aplicação, inclusive na função principal, para descobrir se o problema encontrado era resultado de alguma delas. Foram consideradas corretas as execuções que contivessem então a resposta (\textit{continue}) de cada uma delas. 

Para a configuração \texttt{NUM\_WORKERS} com o valor 60 não houve nenhuma resposta positiva de \textit{continue}. Conforme pode ser observado na Figura~\ref{fig:gdb_dmec_60_workers} não há nenhuma resposta da aplicação e que nem mesmo a função principal foi atingida. 

\fig{gdb_dmec_60_workers}{Execução da depuração da aplicação DMEC com a configuração \texttt{NUM\_WORKERS} = 60}{scale=.4}

Ainda, observando-se o relatório final emitido pela ferramenta foi possível descobrir que sempre que a configuração \texttt{NUM\_WORKERS} apresentava um número maior que 10 a aplicação se comportava de maneira anômala. Após a execução da ferramenta e análise do relatório foi possível determinar que existia um limite máximo de trabalhadores, informação esta que ajudou no desenvolvimento do componente.

Entretanto, a qualidade da informação de retorno é inerente à qualidade de informação à priori que é repassada na configuração de \ac{TAP}. A Figura~\ref{fig:comp_report_partial} apresenta um trecho de relatório com algumas configurações geradas.

\fig{comp_report_partial}{Trecho do relatório com a troca da propriedade \texttt{NUM\_WORKERS} por valores gerados aleatoriamente.}{scale = 0.55}

Em casos como o do teste aleatório qualquer propriedade pode mudar, por exemplo, o tamanho da pilha de aplicativos, o valor de um \textit{quantum}, a quantidade de ciclos de relógio, etc. Relatórios gerados com mais dados tendem a ser mais concisos e menos repetitivos, já os oriundos de testes aleatórios tendem a uma menor organização e maior redundância nas informações.

Outro ponto de interesse científico encontra-se na razão entre o consumo de tempo para executar os testes versus a qualidade da informação que pode ser extraída. As Figuras \ref{fig:dmec_results} e \ref{fig:dmec_time_results} apresentam, respectivamente, os resultados dos experimentos relacionados à qualidade da informação devolvida para o usuário e ao consumo de tempo. Neste experimento foram realizadas 50 tentativas para cada tipo de granularidade. Para o teste parcialmente aleatório, foi modificada a propriedade \texttt{NUM\_WORKERS} com valores em aberto e para o teste determinado foi alterada esta mesma propriedade com valores de 1 a 60.

\fig{dmec_results}{Classificação das tentativas realizadas versus a configuração da granularidade.}{scale = 0.7}
\fig{dmec_time_results}{Classificação das tentativas realizadas versus o consumo de tempo.}{scale = 0.4}

A diferença entre as tentativas totalmente aleatórias e as outras duas granularidades foi grande. Este resultado já era esperado, visto que a depuração de uma aplicação sem informação nenhuma à priori tem a sua efetividade ligada à probabilidade de encontrar tanto a falha quanto a sua causa.

Entretanto não houve muita alteração entre os tipos determinado e parcialmente aleatório. Isto ocorreu devido à limitação na quantidade de propriedades e de seus possíveis valores de troca da aplicação, ou seja, com tal restrição as trocas com sucesso foram semelhantes nas duas configurações.

Conforme apresentado na Figura~\ref{fig:dmec_size_results}, a aplicação não tem uma imagem grande, mas quando adicionamos a informação extra em tempo de compilação, o consumo de memória foi aumentado em cerca de 200\%. Em um sistema embarcado real, o tamanho desta nova imagem seria proibitivo.

\fig{dmec_size_results}{Consumo de memória extra para armazenar as informações de depuração.}{scale = 0.7}

\chapter{Análise qualitativa das ferramentas de teste e depuração de \textit{software}}
No Capítulo \ref{cap:trabalhosRelacionados} foram apresentados vários estudos focados em apresentar soluções práticas para os diversos pontos de melhoria na área de teste e depuração de sistemas. Os mesmos trabalhos serão agora o foco de um estudo qualitativo de suas características.

A definição das características a serem analisadas foram inspiradas na pesquisa de Antonia Bertolino~\cite{bertolino:07}, no qual são explicitados os conceitos mais relevantes para a área de testes de \textit{software}, separados em realizações passadas e em metas ainda não atingidas. 

\section{Metas}
Dentre as metas para a pesquisa em teste de \textit{software}, as relacionadas diretamente com o escopo deste trabalho são: teoria de testes universal, modelagem baseada em teste e testes 100\% automatizados. Cada meta é composta por um conjunto de desafios essenciais para o avanço do estado da arte.

\subsection{Teoria de teste universal}
Esta teoria propõe a adoção de um padrão coerente para a criação de modelos ou técnicas de teste. A partir desta padronização será possível averiguar os pontos fortes e as limitações de cada opção e, consequentemente, conseguir optar racionalmente a melhor opção para cada caso. 
	
\subsubsection{Desafio das hipóteses explícitas}
Com a exceção de algumas abordagens formais, normalmente os testes são baseados em aproximações de uma amostra de dados inicial, suprimindo as demais informações das hipóteses. 

Entretanto, é de suma importância tornar estas informações explícitas, uma vez que esses pressupostos podem elucidar o porquê de observamos algumas execuções.

\subsubsection{Desafio da Eficácia do teste}
Este desafio aborda o porquê, como e quantos testes  são necessários para descobrir um determinado tipo de erro. Pois para estabelecer uma teoria útil para a elaboração e execução dos testes é preciso avaliar a eficácia dos critérios para elaboração teste e sua execução. 

É imprescindível conseguir analisar as teorias existentes e das novas técnicas que estão surgindo. Apesar de não haver um padrão para aferir a eficácia, a controvérsia convencional entre a técnica proposta versus técnicas aleatórias é amplamente utilizada até pelos métodos mais sofisticados. 

\subsubsection{Desafio dos testes de composição}
Tradicionalmente, a complexidade de teste tem sido abordada pela decomposição do teste em ensaios que testam separadamente alguns aspectos do sistema. Entretanto, ainda é preciso descobrir se a composição destes ensaios é equivalente ao teste do sistema todo.

Este desafio está relacionado ao teste de sistemas complexos, por focar em entender como podemos reutilizar os resultados da decomposição e quais conclusões podem ser inferidas para o sistema a partir destes resultados.

\subsubsection{Desafio das evidências empíricas}
Na pesquisa de teste de \textit{software}, estudos empíricos são essenciais para avaliar as técnicas e práticas propostas, entender como elas funcionam e aperfeiçoá-las. Infelizmente, grande parte do conhecimento de técnicas de teste existentes são desprovida de qualquer fundamento formal. 

Para contribuir com o estado da arte de forma concreta é necessário realizar experimentos  mais robustos e significativos em termos de escala, contexto e tema abordado. 

O desafio das evidências empíricas procura fomentar a consciência de unir forças para aprimorar os experimentos está se espalhando e já conta com iniciativas como a construção de repositórios de dados compartilhados e de bancos de dados de ensaios experimentais.

\subsection{Modelagem baseada em teste}
A concepção tradicional de testes de \textit{software} é desenvolver os casos de teste à partir do estudo do \textit{software} e procurar alternativas para melhor explorá-lo.

Esta meta defende que um \textit{software} só pode ser efetivamente testado se ele for desenvolvido à partir de um modelo. A ideia é realizar uma inversão de valores, ou seja, migrar de uma geração de casos de testes baseado em modelos para uma modelagem do sistema baseada em teste.

\subsubsection{Desafio dos testes baseados em modelos}
Em sistemas complexos e heterogêneos é comum que se utilize mais de um tipo de modelagem de \textit{software} para definir suas funcionalidades. A meta desse desafio é garantir que os modelos resultantes de diferentes paradigmas possam ser expressos em qualquer notação e serem perfeitamente integrados dentro de um único ambiente. 

Um dos casos promissores de teste baseados em modelos é o ensaio de conformidade, cujo objetivo é verificar se o \ac{SUT} está em conformidade com a sua especificação, considerando alguma relação definida no modelo.

\subsubsection{Desafio dos testes baseados em anti-modelo} 
Este desafio surgiu da hipótese de que pode não existir um modelos do \textit{software}. Isto pode acontecer, por exemplo, em casos em que um modelo é originalmente criados, mas não há manutenção da correspondência entre o modelo e a implementação, tornando-se obsoleto.

Este desafio foca em abordagens de teste anti-modelo. Ou seja, em coletar informações da execução do programa e tentar sintetizar as propriedades do sistema em um novo modelo ao invés de elaborar um plano de teste e comparar os resultados do teste com o modelo original.
			
\subsubsection{Desafio dos oráculos de teste} 
Um oráculo é uma heurística que pode emitir um veredicto de aprovação ou reprovação das saídas de um determinado teste. Este desafio pretende solucionar o problema de derivar os casos de teste e de como decidir se um resultado do teste é aceitável ou não.

A precisão e a eficiência dos oráculos afeta muito custo do teste, pois não é aceitável que falhas nos testes passem despercebidos, mas por outro lado não é desejável que hajam muitos falsos positivos, que desperdiçam recursos importantes.

\subsection{Testes 100\% automáticos}
A automação total dos testes depende de um ambiente poderoso. Ele deve automaticamente providenciar a instrumentação do \textit{software}, a geração e recuperação do suporte necessário (ex. \textit{drivers}, \textit{stubs}, simuladores, emuladores), ser responsável pela geração automática dos casos de teste mais adequados para o modelo, executá-los e, finalmente, emitir um relatório sobre o ensaio executado.

Ainda existem muitos desafios a serem solucionados para atingir este nível de automação, contudo, os que mais se relacionam com o presente trabalho são a geração de dados de entrada para o teste, as abordagens específicas de domínio e a execução de testes \textit{online}.
	
\subsubsection{Desafio da geração de dados de entrada} 
A geração de dados de entrada para os testes sempre foi um tópico de pesquisa muito ativo e utilizados academicamente. Entretanto, este esforço produz um impacto limitado na indústria, onde a atividade de geração de teste permanece em grande parte manual.

Os resultados mais promissores são as abordagem baseada em modelo e a geração aleatória acrescida de alguma técnica com inteligência. Desta forma, ainda se faz necessária uma técnica que possa ser utilizada de maneira mais abrangente.
			
\subsubsection{Desafio das abordagens de teste específicas para o domínio} 
O atual estado da arte aponta para a necessidade executar a fase de testes com abordagens específicas de domínio. 

O intuito deste desafio é encontrar métodos e ferramentas específicas de domínio e poder aprimorar a automação de teste. Neste sentido, alguns trabalhos já conseguiram demonstrar a extração automática de requisitos para o teste a partir de um modelo escrito em uma linguagem fortemente tipada e específica de um domínio.
			
\subsubsection{Desafio dos testes \textit{online}} 
O desafio de testes \textit{online} focam na ideia de monitorar o comportamento de um sistema em pleno  funcionamento, com o \textit{software} executando e recebendo todas as interferências reais.

É um desafio importante e complexo, pois nem sempre é possível realizar este tipo de teste, especialmente para aplicações embarcadas implantados em um ambiente de recursos limitados, onde a sobrecarga exigida pela instrumentação de teste não poderia ser viável.

\section{Análise da ferramenta proposta}
A partir da contextualização das características importantes para a evolução do estado da arte, agora já é possível realizar uma análise qualitativa de \ac{TAP}, ressaltando as contribuições e melhorias da ferramenta. As ferramentas e técnicas propostas nos trabalhos relacionados também serão analisadas sob o mesmo ponto de vista.

\subsection{Meta da teoria de testes universal}
A primeira meta abordada, a teoria de testes universal, possui desafios para impulsionar as pesquisas em projeto de testes de \textit{software}. 

Apesar do foco de \ac{TAP} permanecer na execução dos testes, sua  concepção e a automação da execução possuem pontos em comum. O desafio de hipóteses explícitas, por exemplo, é um critério  originalmente abordado no projeto de testes, mas que possui grande relevância para a execução, pois fazem parte dos dados de entrada. 

\ac{TAP} foi analisada sob a meta de teoria de teste universal e seus resultados encontram-se na Tabela~\ref{ref:tabQuestao1TAP}.

\begin{table*}[h]
\begin{center}
\caption{Análise de \ac{TAP} para a meta de teoria de teste universal}
\begin{tabular}{|p{.3\textwidth}|p{.7\textwidth}|} 

\hline
\textbf{Hipóteses explícitas} & As hipóteses podem ser \textbf{parcialmente} explicitadas através do arquivo de configuração, onde  é possível importar definições semi-formais.\\ 

\hline
\textbf{Eficácia do teste} & Cobertura \textbf{total}, onde a eficácia é testada de forma quantitativa pela controvérsia convencional entre a técnica proposta versus a técnica aleatória.\\ 

\hline
\textbf{Testes de composição} & Testes \textbf{parcialmente} atendidos, pois cada componente pode ser testado como uma aplicação menor e a integração destes componentes forma a aplicação real. Entretanto, a composição dos componentes é apenas simulada.\\ 

\hline
\textbf{Evidências empíricas} & O algoritmo, sua implementação e o conjunto de testes utilizados estão liberadas para o uso de terceiros, mas devido à especificidades na modelagem do sistema \textbf{não foi possível} utilizar testes de repositórios já existentes. \\

\hline
\end{tabular}
\label{ref:tabQuestao1TAP} 
\end{center}
\end{table*}

Nesta primeira análise observa-se que a ferramenta atende a todos os desafios proposto, exceto o desafio de evidências empíricas. Não foi possível realizar a execução de testes de um repositório devido à utilização da modelagem \ac{ADESD}, que possui especificidades que ainda não estão contempladas nos \textit{testbeds} disponíveis. Um ponto de melhoria seria compartilhar o modelo de testes aplicado no Capítulo~\ref{sec:case_study} em outros repositórios, aumentando o volume de dados para a avaliação de outras propostas.

Considerando as mesmas metas e objetivos, vários dos trabalhos relacionados atendem os mesmos quesitos que \ac{TAP} e com a mesma intensidade. Dentre a técnicas que mais se assemelha à \ac{TAP} estão as ferramentas de depuração como as de depuração estatística e depuração delta. Isto ocorre porquê ferramentas que implementam estas técnicas não são voltadas para a geração de casos de teste e  utilizam-se de hipóteses explícitas como dados de entrada para posteriormente realizar a depuração. A eficácia da execução dos testes/depuração são normalmente aferidas levando-se em conta a execução das ferramentas e confrontando-as com modelos aleatórios.

A análise de $Justitia$  também aponta semelhanças na declaração parcial de hipóteses explícitas para os dados de entrada de teste - que são representadas pelas interface do sistema - e na eficácia dos testes. A vantagem de $Justitia$ está nos testes de composição, que não são amplamente contemplados em \ac{TAP} por ser uma características voltada para a geração de casos de testes.

Já a comparação de \ac{TAP} com $ATEMES$ as características só se distanciam nos desafios de eficácia do teste e testes de composição. Ambas ferramentas possuem estratégias diferentes, visto que $ATEMES$ foca em explorar sistematicamente a componentização da própria ferramenta e a robustez no teste do \textit{software} em detrimento da avaliação da eficácia dos testes.

A única técnica avaliada que não apresenta hipóteses explícitas é a captura e reprodução. Isto ocorre porque a entrada das ferramentas não são as hipóteses, e sim o próprio executável, ou seja, observa-se o sistema através da captura de toda a sua execução, não sendo necessário observar execuções relacionadas à uma determinada hipótese.

A Tabela~\ref{ref:tabQuestao1Ferramenta} apresenta um resumo da análise comparativa entre \ac{TAP} e as ferramentas correlatas no quesito teoria de teste universal.

\begin{table*}[h]
\begin{center}
\caption{Resumo comparativo do suporte para a meta de teoria de teste universal}
\begin{tabular}{|p{.29\textwidth}|p{.13\textwidth}|p{.13\textwidth}|p{.15\textwidth}|p{.14\textwidth}|} 
\hline
 & \multicolumn{4}{c}{\textbf{Suporte para o desafio}} \\

\cline{2-5}
\textbf{Técnicas} & \textbf{Hipóteses explícitas} & \textbf{Eficácia do teste} & \textbf{Testes de composição} & \textbf{Evidências empíricas}\\ 

\hline
\ac{TAP} & Parcial & Sim & Parcial & Não\\ 

\hline
$Justitia$ & Parcial & Sim & Sim & Não\\ 

\hline
$ATEMES$ & Parcial & Parcial & Sim & Não\\ 

\hline
Execução de testes por sistema alvo & Não & Parcial & Parcial & Não\\ 

\hline
Partição do \textit{software} & Parcial & Sim & Sim & Não\\ 

\hline
Depuração estatística & Parcial & Sim & Parcial & Não\\ 

\hline
Depuração por delta & Parcial & Sim & Parcial & Não\\ 

\hline
Captura e reprodução & Não & Parcial & Parcial & Não\\ 

\hline
\end{tabular}
\label{ref:tabQuestao1Ferramenta} 
\end{center}
\end{table*}

Um aspecto que ficou bastante realçado que nenhuma das técnica contemplou o desafio das evidências empíricas. Apesar de grande parte dos autores disponibilizam seus trabalhos para o púbico em geral, os dados derivados das pesquisas ainda não são maduros o suficiente parar desenvolver o estado da arte. Ou seja, grande parte dos dados existentes são originados de impressões e deduções dos próprios autores e, muitas vezes,  desprovidos de fundamento formal.

\subsection{Meta da modelagem baseada em testes}
Devido à falta de maturidade na produção de sistemas, hoje há um foco muito grande no desenvolvimento do \textit{software}, e as atividades de teste e depuração são apenas subprodutos que ajudam na confiabilidade do sistema.

Neste contexto, a meta de modelagem baseada em testes se torna muito importante, pois defende um \textit{software} só pode ser completamente testado caso haja um planejamento para a geração dos testes e que sejam originados à partir de um modelo definido.

Uma análise das contribuições de \ac{TAP} na meta de modelagem baseada em testes será apresentada na Tabela~\ref{ref:tabelaModelagemBaseadaTesteTAP}.

\begin{table*}[h]
\begin{center}
\caption{Análise de \ac{TAP} para a meta de modelagem baseada em testes}
\begin{tabular}{|p{.19\textwidth}|p{.81\textwidth}|} 

\hline
\textbf{Teste baseado em modelos} & Atualmente a ferramenta possui uma contribuição \textbf{limitada} à agregação de outros modelos e prevê apenas o ensaio de conformidade a partir de uma configuração de teste.\\ 

\hline
\textbf{Teste baseado em anti-modelo} & Apesar de não ser o foco deste trabalho, o relatório fornecido por \ac{TAP} apresenta todas as características e os valores trocadas em tempo de execução. Estes dados podem ser utilizados para realizar uma modelagem do sistema, portanto a ferramenta \textbf{possui} suporte para o anti-modelo.\\ 

\hline
\textbf{Oráculos de teste} & \ac{TAP} \textbf{não} contém um oráculo de teste, uma vez que não faz parte deste trabalho a geração de casos de teste.\\ 

\hline
\end{tabular}
\label{ref:tabelaModelagemBaseadaTesteTAP} 
\end{center}
\caption{Análise de \ac{TAP} para a meta de modelagem baseada em testes}
\end{table*}

Todos os desafios da meta de modelagem baseada em testes são relevantes para a área de testes de \textit{software}, contudo, grande parte dos desafios são contemplados de maneira parcial em \ac{TAP} por distanciar-se muito dos objetivos específicos deste trabalho. Satisfazer esta meta é um ponto de melhoria que deve ser analisado para implementação futura.

Durante o comparativo entre as ferramentas foi possível identificar que todos os trabalhos abordam de alguma forma o desafio de testes baseados em modelos e anti-modelos, exceto $Justitia$, que só suporta os testes baseados em modelos. $Justitia$ utiliza as interfaces como modelos para a construção dos casos de teste e também como \textit{checkpoint} das atividades do \textit{software}, não sendo possível utilizar outra abordagem de verificação do sistema.

Dentre todas as técnicas analisadas, apenas duas contemplaram a meta por completo, apresentando soluções para todos os desafios propostos: Captura e reprodução e $ATEMES$. 

Na Captura e reprodução, o padrão é o teste baseado em anti-modelos, pois toda a execução do sistema é gravada e utilizada para o teste e depuração do sistema. Embora seja menos comum, algumas ferramentas da técnica ainda oferecem o teste baseado em modelo, que são mesclados os dados do anti-modelo para fornecer um resultado melhor na identificação dos \textit{bugs}.

Já $ATEMES$ se destaca pela quantidade de tipos de teste que podem ser gerados pelo módulo \texttt{PRPM} da ferramenta, sendo que a base destes casos de teste pode ser vir de modelos bem definidos, anti-modelos, agregação de modelos ou até de maneira aleatória. O oráculo de $ATEMES$ processa as informações de execução do sistema e repassa informações para vários módulos, por exemplo, o módulo \texttt{POPM} recebe um conjunto de linhas do código fonte apontadas como prováveis geradoras de erros.

Outra técnica que se destaca pelo oráculo de testes é a Execução de testes por sistema alvo. Além de permitir uma alimentação à partir de execuções consideradas corretas do \textit{software}, recentemente uma das implementações da técnica adaptou-a com um oráculo composto por uma rede neural com \textit{backpropagation}.

Depuração por delta e Depuração estatística são técnicas de depuração e por isso não apresentam um oráculo de testes. Algo semelhante ocorre com a partição de código, pois sua principal característica é particionar o código, respeitando o modelo (ou anti-modelo) do \textit{software}. Este particionamento pode ocorrer de várias formas, mas não é um oráculo quem define qual algoritmo utilizar.

A Tabela~\ref{ref:tabQuestao2Ferramenta} apresenta um resumo da análise comparativa entre as ferramentas e técnicas correlatas para os desafios propostos pela meta de modelagem baseada em teste.

\begin{table*}[h]
\begin{center}
\caption{Comparativo qualitativo do suporte para a meta de modelagem baseada em teste}
\begin{tabular}{|p{.29\textwidth}|p{.2\textwidth}|p{.25\textwidth}|p{.15\textwidth}|} 
\hline
 & \multicolumn{3}{c}{\textbf{Suporte para o desafio}} \\

\cline{2-4}
\textbf{Técnicas} & \textbf{Teste baseado em modelos} & \textbf{Teste baseado em anti-modelos} & \textbf{Oráculos de teste}\\ 

\hline
\ac{TAP} & Parcial & Sim & Não\\ 

\hline
$Justitia$ & Parcial & Não & Parcial \\ 

\hline
$ATEMES$ & Sim & Sim & Sim \\ 

\hline
Execução de testes por sistema alvo & Sim & Não & Sim \\ 

\hline
Partição do \textit{software} & Sim & Sim & Não \\ 

\hline
Depuração estatística & Sim  & Sim & Não \\ 

\hline
Depuração por delta & Sim  & Sim & Não \\ 

\hline
Captura e reprodução & Parcial & Sim & Parcial \\ 

\hline
\end{tabular}
\label{ref:tabQuestao2Ferramenta} 
\end{center}
\end{table*}

Analisando o comparativo é possível identificar que as técnicas e ferramentas que possuem a geração de testes 
dispõem de um oráculo. Esta preocupação é apropriada para que a geração dos testes seja efetiva para encontrar os erros e melhorar cada vez mais a qualidade do código.

Outra perspectiva relevante é a utilizada pelas ferramentas de depuração, que responsabilizam-se por depurar um \textit{software} e descobrir se ele é correspondente a um determinado modelo. Quando não há um modelo disponível, estas ferramentas estão preparadas para comparar as diversas execuções do próprio \textit{software} e efetuar a análise sob os dados obtidos do próprio \ac{SUT}.

\subsection{Meta dos testes 100\% automáticos}
A meta dos testes completamente automatizados permite um controle de qualidade no desenvolvimento e manutenção de um \textit{software}. É de difícil implantação, mas uma vez que a automação esteja em pleno funcionamento é possível manter a confiabilidade do sistema de maneira rápida e eficiente.

A Tabela~\ref{ref:tabQuestao3TAP} mostra a relação de \ac{TAP} com a meta de automação completa da execução de testes de \textit{software}, em que nota-se níveis de automação em todos o desafios propostos.

\begin{table*}[h]
\begin{center}
\caption{Análise de \ac{TAP} para a meta de automação dos testes}
\begin{tabular}{|p{.18\textwidth}|p{.82\textwidth}|} 

\hline
\textbf{Geração de dados de entrada} & O suporte à geração de dados é \textbf{parcial}, pois a informação inicial dos dados de entrada são fornecidos pelo usuário da ferramenta. No caso do teste não ser determinado pelo usuário, a ferramenta inclui dados iniciais aleatórios, sem adição de inteligência. Também existe a opção de retroalimentação.\\ 

\hline
\textbf{Abordagens específicas para o domínio} &  \ac{TAP} consegue importar configurações específicas de domino para realizar a execução de testes, contemplando de forma \textbf{parcial} a extração de dados relacionados ao domínio da aplicação.\\ 

\hline
\textbf{Testes \textit{online}} & Este diferencial é apresentado pela ferramenta através do ambiente integrado de teste e depuração, com suporte \textbf{total} aos testes durante à execução da aplicação. Todavia, quando a execução da aplicação ocorre em ambiente emulado o suporte à testes \textit{online} é considerado parcial.\\ 

\hline
\end{tabular}
\label{ref:tabQuestao3TAP} 
\end{center}
\end{table*}

Para ser considerada uma ferramenta 100\% automática \ac{TAP}, ainda deve-se investir em técnicas para receber a entrada dos dados, seja a partir da extração de valores do modelo ou através de algum tipo de inteligência artificial. Ao integrar \ac{TAP} ferramentas como, por exemplo, a \textit{ADESDTool}~\cite{Cancian:PHD:2011} pode-se fornecer melhores configurações para o próprio sistema embarcado.

A geração de dados de entrada é uma característica que muitas vezes é preterida por ferramentas que não realizam a geração dos casos de teste. Técnicas como a Partição de \textit{software} e Captura e reprodução empregam o modelo do \textit{software} como dado de entrada para o teste/depuração e não são capazes incluir mutabilidade coerente ao modelo.

Conjuntamente, a abordagem específica de domínio também exerce bastante influência para uma automação total dos testes. Existem trabalhos totalmente focados para uma abordagem específica de domínio, como é o caso da Execução de testes por sistema alvo. Nesta técnica considera que cada sistema embarcado possui propriedades que o definem e, portanto, devem ser levadas em conta na escolha do modelo de testes a ser utilizado.

A Tabela~\ref{ref:tabQuestao3Ferramenta} apresenta uma análise comparativa entre as ferramentas e técnicas correlatas para os desafios propostos através de testes 100\% automatizados.

\begin{table*}[h]
\begin{center}
\caption{Comparativo qualitativo do suporte para a meta de testes 100\% automáticos}
\begin{tabular}{|p{.3\textwidth}|p{.19\textwidth}|p{.22\textwidth}|p{.15\textwidth}|} 
\hline
 & \multicolumn{3}{c}{\textbf{Suporte para o desafio}} \\

\cline{2-4}
\textbf{Ferramentas} & \textbf{Geração de entradas} & \textbf{Abordagem específica para domínio} & \textbf{teste \textit{online}}\\ 

\hline
\ac{TAP} & Parcial & Parcial & Sim \\ 

\hline
$Justitia$ & Sim & Não & Sim \\ 

\hline
$ATEMES$ & Sim & Não & Sim \\ 

\hline
Execução de testes por sistema alvo & Parcial & Sim & Sim \\ 

\hline
Partição do \textit{software} & Não & Parcial & Sim \\ 

\hline
Depuração estatística & Não & Parcial & Não \\ 

\hline
Depuração por delta & Parcial  & Parcial & Não \\ 

\hline
Captura e reprodução & Não & Não & Sim\\ 

\hline
\end{tabular}
\label{ref:tabQuestao3Ferramenta} 
\end{center}
\end{table*}

Esta meta deixa em evidência que o ambiente integrado de \ac{TAP} fornece uma grande utilidade para a conseguir realizar tanto o teste quando a depuração \textit{online}. Isto não ocorre com as outras ferramentas de depuração, que deixam a desejar no desafio de execução \textit{online}. 

\chapter{Conclusões}
Neste trabalho foi introduzida \ac{TAP}, uma ferramenta para a troca automática de parâmetros de configuração e apresentado um roteiro para a geração de um ambiente de desenvolvimento de aplicações embarcadas baseadas em requisitos de \textit{hardware} e \textit{software} específicos.

O ambiente de desenvolvimento integrado fornece independência em relação à plataforma física de destino. Desta forma, os desenvolvedores não precisam gastar tempo compreendendo uma nova plataforma de desenvolvimento sempre que alguma característica do sistema embarcado for atualizada. Este é um passo importante, pois alguns sistemas embarcados podem não ser capazes de armazenar os dados adicionais necessários para apoiar a depuração. 

Os experimentos realizados apontaram valores quantitativos do tempo consumido para realizar os teses e da efetividade dos ensaios. Foi confirmada que a eficácia do algoritmo está intimamente ligada à efetividade da configuração dos valores e da granularidade apresentadas à ferramenta. 

Foram avaliados os impactos inerentes ao uso da ferramenta para verificar se existiam pontos de melhoria, que devem ser tratados em trabalhos futuros. Dentre eles estão a redução do uso de memória e do tempo utilizados para recuperar as informações de depuração, que atualmente apresenta um aumento de mais de 500\% no tamanho do código da aplicação e a uma sobrecarga de 60\% para o tempo de execução do teste.

Também foi realizada a análise qualitativa da ferramenta, levando-se em conta os desafios ainda presentes no teste de \textit{software} e metas que necessitam ser atingidas. Os resultados demonstram o comprometimento da ferramenta com o avanço do estado da arte, pois procura oferecer uma solução viável a pelo menos 80\% dos desafios propostos. 

A ferramenta possui resultados promissores se comparada com outras ferramentas correlatas, frequentemente apresentando soluções equivalentes às de outras ferramentas e, eventualmente, cobrindo características que não fazem parte do escopo inicial deste trabalho.

\section{Perspectivas futuras}
Durante o desenvolvimento deste trabalho foram identificados pontos que podem ser otimizados em trabalhos futuros:
\begin{itemize}
	\item Analisar a possibilidade de reduzir o custo de memória e de tempo utilizado para a execução de testes. 
	\item Verificar formas de melhorar a configuração de \ac{TAP} e dos dados de entrada do algoritmo.
	\item Realizar um maior número de experimentos para verificar o desempenho da ferramenta em ambientes com restrições e que apresentem testes mais complexos.
	\item Aprimorar a ferramenta para conseguir atingir os desafios identificados na área de teste e depuração de \textit{software}.
\end{itemize}

O desenvolvimento deste trabalho resultou em artigos publicados em eventos, e que contribuirão para o estado da arte nas áreas de verificação de \textit{software} e de construção de sistemas embarcados. Como perspectiva futura também encontra-se a produção de mais artigos.

\bibliographystyle{ufscThesis/ufsc-alf}
\bibliography{bibliografia}
\end{document}