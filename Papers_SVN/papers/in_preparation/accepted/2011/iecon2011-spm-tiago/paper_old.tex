\documentclass{acm_proc_article-sp}

\usepackage[latin1]{inputenc}	% for Latin languages
\usepackage[T1]{fontenc}	% for ISO and UTF characters
\usepackage[english]{babel}	% for multilingual support
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{verbatim}

\include{utils}


\begin{document}

\numberofauthors{8}

\title{A run-time memory management approach for scratch-pad-based embedded systems}

\author{
\alignauthor
Tiago Rogério Mück and Antônio Augusto Fröhlich\\
\affaddr{Software/Hardware Integration Lab}\\
\affaddr{Federal University of Santa Catarina}\\
\affaddr{Florianópolis, Brazil}\\ 
\email{\{tiago,guto\}@lisha.ufsc.br}
}


\maketitle


\begin{abstract}
\textit{Software-controlled caches}, often called \textit{scratch-pad memories} (SPM), are being increasingly used due to their efficiency. And to exploit all the advantages of SPMs an efficient allocation must be done in software. In this work we propose a runtime operating system management approach for SPMs that do not require compiler support, application profiling or hardware support. The OS will use annotations, inserted into the code by the programmer, as hints to choose the most appropriate level in the memory hierarchy to allocate the data. The results showed that we were able to implement a run-time SPM allocation technique without adding any significant overhead to the system when compared with manual allocation.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Theory}

\keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings


\section{Introduction}

Contemporary embedded system applications are requiring even faster processors and larger memories. Previous studies have shown that the memory subsystem is responsible for 50\%-75\% of the total system power consumption and occupies significant chip area~\cite{Kandemir::2002}, which shows that the memory subsystem is an important optimization point. Most systems rely on cache-based memory hierarchies due to the capacity of caches to exploit the spatial and temporal locality of memory access. However, caches require an additional tag memory and address comparison logic which may significantly increase their power consumption and area cost, thus turning them inappropriate for most embedded applications~\cite{Verma::2006}.

An alternative to caches is the use of \textit{software-controlled caches}, often called \textit{scratch-pad memories} (SPM). The SPMs do not need the extra logic to map data and instructions to it because all of the memory allocation to the SPM is controlled by software, so SPMs are more power and area efficient than caches~\cite{Verma::2006}. However, to exploit all the advantages of SPMs an efficient allocation must be done in software. Several software allocation approaches have been proposed. All of the proposed approaches are compile-based techniques, and most of them rely on profiling information to define the instructions and data to be allocated to the SPM at compile-time. These compile-based approaches have two big drawbacks. First, the use of profiling limits the scope of the mapping techniques not only because of the difficulty in obtaining reasonable profiles but also due to high space and time requirements to generate a profile~\cite{Shrivastava::2009}. This is especially true for dynamic applications where the memory access patterns depends on the application input data~\cite{Cho::2009}. Second, this kind of allocation scheme leads to a more complicated software development and reduced portability because it requires very specific toolchains with modified compilers.

In this work we propose a runtime operating system management approach for SPMs that do not require compile support, profiling or hardware support. We assume that an embedded system targets a specific hardware platform and a specific application, so an embedded OS can receive information about the underlying memory hierarchy and about the kind of access to the application data in order to provide an efficient memory allocation. When an application requires a memory allocation, the OS will use annotations, inserted into the code by the programmer, as hints to choose the most appropriate level in the memory hierarchy to allocate the data. This way the OS can take advantage of the developer's knowledge about the application to provide an efficient data allocation without the drawbacks of the previously proposed techniques. 

\section{Related work}

In the last years many SPM management approaches have been proposed. We separated this approaches in the different categories shown in figure \ref{fig_spm_state_of_art_small}. 

\fig{.35}{fig_spm_state_of_art_small}{Classification of SPM allocation approaches}

The \textit{static} approaches are those in which the contents of the SPM are fixed at compile-time and never change. They can be divided into two categories: \textit{compile-time techniques} where the allocation is made by the compiler~\cite{Avissar::2002}, and \textit{post-compile techniques} where algorithms are applied at the final binary code to change the memory allocation~\cite{Angiolini::2004}. These static allocation approaches either use greedy strategies to find an efficient solution, or model the problem as an \textit{integer-linear programming} problem (ILP) to find an optimal solution.

In the \textit{dynamic} approaches the SPM contents change during the program execution. When the sets of code and/or data that will be moved to/from the SPM are defined at compile-time, we call it a \textit{compile-time} approach~\cite{Verma::2006}. \textit{Verma et al}~\cite{Verma::2006} is a good example of this kind of technique. The authors propose an overlay-based memory allocation approach for both code and data. The proposed solution uses ILP to find the optimal memory allocation and overlay points that minimizes energy consumption for a given profile. They also propose a first-fit algorithm to obtain a near-optimal solution.

If the data sets allocated in the SPM can change or are defined during the program execution, we call it a \textit{run-time} approach. The run-time approaches generally follows one or more of the following three basic methodologies that we have defined: a run-time approach is \textit{compiler-assisted} if actions are taken by the compiler to define the allocation. \textit{Hardware-assisted} approaches are the ones that require special hardware support. Finally there are the approaches that require \textit{run-time software support} provided by a standalone library or by an OS to perform the allocation. In \textit{Shrivastava et al}~\cite{Shrivastava::2009} an approach is proposed that does not require profiling or hardware support. They manage the function's stack frames, allocating them on the SPM when they are in use, thus this approach handles only stack data which represents 65\% of the memory access on multimedia applications, according to the authors. In \textit{Cho et al}~\cite{Cho::2009} an allocation scheme was proposed that integrates compiler, OS, and hardware. All of the previous techniques handled only code and/or global/stack data. The only known technique that allocates heap data to the SPM was proposed in \textit{Dominguez et al}~\cite{Dominguez::2005}. This is a compiler-assisted approach that allocates fixed size parts of heap variables.

\section{The proposed approach}

In our approach we assume that an embedded system targets a specific hardware platform and a specific application, so an embedded OS receive information about the underlying memory hierarchy and about the kind of access to the application data in order to provide an efficient memory allocation. Each memory component is abstracted as a single dynamic heap. When an application requires a memory allocation, the OS uses annotations, inserted into the code by the programmer, as hints to choose the most appropriate level in the memory hierarchy to allocate the data.

We have implemented a framework for the C++ language that provides parameterized versions of the \textit{new} and \textit{delete} operators, allowing the programmer to easily insert allocation hints into the program. The framework was implemented on the \textit{Embedded Parallel Operating System} (EPOS)~\cite{Frohlich::2001}. EPOS relies on the \textit{Application-Driven Embedded System Design Method} (ADESD)~\cite{Frohlich::2001} to design and implement both software and hardware components that can be automatically adapted to fulfill the requirements of particular applications. Low overhead and high performance are achieved by a careful implementation that makes use of \textit{generative programming} techniques, including \textit{static metaprogramming}.

Our framework provides three different types of annotations:

\small
\begin{itemize}
  \item ALLOC\_HIGH
  \item ALLOC\_LOW
  \item ALLOC\_NORMAL
\end{itemize}
\normalsize

When the \textit{ALLOC\_HIGH} annotation is used, it means that particular object has a high memory access priority (i.e. performance/power consumption of read/write operations on it have a major impact over the system efficiency) and should be allocated on the more efficient level of the memory hierarchy (e.g. a SPM). The \textit{ALLOC\_LOW} have the inverse meaning. It means that the object has a low memory access priority and it can be allocated on the less efficient level of the memory hierarchy without a significant impact on the system efficiency. Finally, the \textit{ALLOC\_NORMAL} annotation is used to indicate that the OS should decide the best place to allocate that object. The example in figure \ref{fig_spm_code_alloc} shows how these annotations are passed to the \textit{new} operators. In this example, four arrays of type \textit{int} are allocated using the different annotations and without annotation. When annotations are not used, the OS assumes \textit{ALLOC\_NORMAL}. The usage of the \textit{delete} operator doesn't change.  

\begin{figure}[htbp]
\small
\scriptsize
\begin{verbatim}
int *at_spm = new (ALLOC_HIGH) int[10];
int *at_main_mem = new (ALLOC_LOW) int[10];
int *somewhere = new (ALLOC_NORMAL) int[10];
int *somewhere_else = new int[10];/*equivalent to the
                                   statement above/*

delete[] at_spm;
delete[] at_main_mem;
delete[] somewhere;
delete[] somewhere_else;
\end{verbatim}
  \normalsize
  \caption{Examples of memory allocation requests using the priority annotation}
  \label{fig_spm_code_alloc}
\end{figure}
 
Given an annotation, it may not be possible to allocate the data on the desired location. The pseudo-code in figure \ref{fig_spm_code_alloc_algo} describes the algorithm used to decide where the data will be allocated based on the annotation and the amount of space available on the different memories. If an allocation request can't be accomplished on the preferred memory component, the OS will attempt to allocate on a less optimal memory component. If it is left to the OS to decide where to allocate, the OS will attempt to allocate on the memory with the highest percentage of free space, thus handling exhaustion of a particular memory component. The implementation of the memory deallocation is straightforward. The OS just checks the pointer address to decide if the memory will be deallocated on the main memory or on the SPM.

\begin{figure}[htbp]
\scriptsize
\centering
\begin{verbatim}
memory allocation (size, annotation)

    if annotation = ALLOC_HIGH 
        if fits on spm (size)
            allocate on spm
        else
            allocate on main mem
    
    else if annotation = ALLOC_LOW
        if fits on main mem (size)
            allocate on main mem
        else
            allocate on spm
        
    else if annotation = ALLOC_NORMAL
        if spm free percentage > 
                  main mem free percentage
            if fits on spm (size)
                allocate on spm
            else
                allocate on main mem
        else
            if fits on main mem (size)
                allocate on main mem
            else
                allocate on spm
\end{verbatim}
  \normalsize
  \caption{Algorithm that defines where the allocation will be done}
  \label{fig_spm_code_alloc_algo}
\end{figure}


\section{Evaluation and results}

We used the \textit{Xilinx ML403 Evaluation Board} to build a platform for our preliminary evaluation. The ML403 board features a Xilinx Virtex 4 FPGA with an embedded PowerPC 405 processor that is implemented as a hard-core inside the FPGA (i.e. it is implemented directly in silicon instead of using FPGA logic resources). The ML403 board features an 64 Mb DDR SDRAM external memory that we connected to one of the \textit{Processor Local Bus} (PLB) interface to use as our platform main memory. We implemented the SPM using the Virtex 4 internal block RAM connected to the \textit{On-Chip Memory} (OCM) bus. Another block RAM peripheral is connected to the other PLB bus interface to store the bootloader software that loads the system into the main memory. This bootloader memory is idle after the system is loaded, so we used it as a SPM as well, although its performance may suffer since its PLB bus is shared with other IO peripherals. The PowerPC processor offers two internal 16Kb caches for instructions and data that can be used to cache any memory peripheral connected to the PLB buses. To keep a standard memory hierarchy, we connected only the external memory to the caches. The resulting memory hierarchy is shown in figure \ref{fig_spm_ml403_mem}. Table \ref{results_table_params} summarizes other parameters used on the experiments.

\fig{.3}{fig_spm_ml403_mem}{ML403 memory hierarchy}

%\begin{comment}

\begin{table}
\caption{Configuration parameters used on the experiments}
\label{results_table_params}
\centering
\small
\begin{tabular}{ll}
\hline\noalign{\smallskip}
Parameter & Value \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
Synthesis tool & ISE/EDK 10.1 \\
Compiler & GCC 4.0.2 \\
FPGA clock & 100 MHz \\
Microprocessor clock & 100 MHz \\
\hline
\end{tabular}
\normalsize
\end{table}

%\end{comment}

We have evaluated the performance of the \textit{new} and \textit{delete} operators for each different annotation and compared with the original allocation approach. The algorithm in figure \ref{fig_spm_code_alloc_test} was used to evaluate these operations. With this algorithm we are able to measure the performance using different allocation patterns. We repeated these iterations for the original \textit{new} and \textit{delete} operations without using annotations and for each of the three possible annotations.

\begin{figure}[htbp]
\scriptsize
\centering
\begin{verbatim}
for (int i=0; i < 2 * BLK_SIZE; i++) 
    char *p1 = new (ANNOTATION) 
                   char[[ (i % BLOCK_SIZE) + 1];
    int *p2 = new (ANNOTATION) int;
    char *p3 = new (ANNOTATION) char[300];

    delete[] p1;
    delete[] p2;
    delete[] p3;
\end{verbatim}
  \normalsize
  \caption{\textit{new} and \textit{delete} evaluation algorithm}
  \label{fig_spm_code_alloc_test}
\end{figure}

Figure \ref{fig_spm_results_alloc2} shows the average time to complete a \textit{new} and a \textit{delete} operation. The results show that our new allocation approach added a negligible overhead to the original one. The higher allocation time when the \textit{ALLOC\_NORMAL} annotation is used is expected since extra logic is required to define the heap to be used.

\fig{.6}{fig_spm_results_alloc2}{Performance of the original \textit{new} and \textit{delete} compared with the new parameterizable memory operations for different annotations}

We also measured the latency of read and write operations on the tree memory components available. Figure \ref{fig_spm_results_mem_lat} shows the measured latency, which is the average time to read/write several blocks of 4096 words of 4 bytes. Surprisingly, the read/write times were very close for all memories. 

Since the caches were disabled in this experiment, one explanation for the PLB based SPM is that it is connected to a bus that is shared with IO peripherals, which may have affected its performance. However, the other OCM based SPM is connected to a bus which is dedicated for on-chip memories and should have shown better performance. Another explanation is that the slow system clock frequency hides the higher latency of accessing an external DRAM memory. Nevertheless, it was not possible to achieve timing closure when synthesizing the system using higher clock frequencies. 

\fig{.6}{fig_spm_results_mem_lat}{Average time to read/write a block of 4096 32-bit words in different memory devices}


\section{Conclusions and future work}

We have proposed a runtime operating system management approach for SPMs that do not require compile support, profiling or hardware support. On the proposed approach, the OS will use annotations, inserted into the code by the programmer, as hints to choose the most appropriate level in the memory hierarchy to allocate the data. The results showed that we were able to implement a run-time SPM allocation technique without adding any significant overhead to the system compared with the standard allocation. However, real benchmarks must be used to determine the efficiency of the proposed approach in relation to a cache-based system and other approaches. An FPGA-based evaluation platform proved impractical. The results have shown the difficulties in achieving clock frequencies higher then the external memory devices. Also, FPGA-based platforms do not provide realistic energy consumption results, so a different platform or simulations based on energy consumption models are necessary.

In our approach we handle only user declared heap variables. Global variables allocated at compile-time can be easily converted to heap variables by declaring them in this way and allocating them manually during the application initialization. The automatic allocation of code and stack variables to the SPM at run-time without the help of a compiler or special hardware will be covered in future works. 


\bibliographystyle{abbrv}
\bibliography{references_spm.bib}

\end{document}
