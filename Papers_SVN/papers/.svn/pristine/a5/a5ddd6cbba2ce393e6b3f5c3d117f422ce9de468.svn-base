\documentclass[letterpaper]{acm_proc_article-sp}

\usepackage{afterpage}
\usepackage{cite}

\makeatletter
\newif\if@restonecol
\makeatother
\let\algorithm\relax
\let\endalgorithm\relax
\usepackage[figure,linesnumbered]{algorithm2e}

\pdfpagewidth=8.5in
\pdfpageheight=11in

\usepackage{listings}
\lstset{keywordstyle=\bfseries, flexiblecolumns=true}    
\lstloadlanguages{[ANSI]C++,HTML}
\lstdefinestyle{prg} {basicstyle=\small\sffamily, lineskip=-0.2ex, showspaces=false}

\newcommand{\prg}[3][tbp]{
  \begin{figure}[#1]
      \lstinputlisting[language=C++,style=prg]{fig/#2.cc}
    \caption{#3\label{prg:#2}}
  \end{figure}
}

\newcommand{\fig}[4][tb]{
  \begin{figure}[#1] {\centering{\includegraphics[#4]{fig/#2}}\par}
    \caption{#3\label{fig:#2}}
  \end{figure}
}

\newcommand{\figspan}[4][tb]{
  \begin{figure*}[#1] {\centering{\includegraphics[#4]{fig/#2}}\par}
    \caption{#3\label{fig:#2}}
  \end{figure*}
}

\newcommand{\tab}[3][th]{
  \begin{table}[#1]
    {\centering\small\textsf{\input{fig/#2.tab}}\par}
    \caption{#3\label{tab:#2}}
  \end{table}
}


\newcommand{\class}[1]{{\sffamily\bfseries{#1}}}
\newcommand{\method}[1]{\class{#1}}
\newcommand{\epos}{\textsc{Epos}}

\begin{document}

\title{Power Management in the EPOS System}

\numberofauthors{1} 

\author{
\alignauthor
Geovani Ricardo Wiedenhoft, Lucas Francisco Wanner,\\
Giovani Gracioli and Antônio Augusto Fröhlich\\
       \affaddr{Laboratory for Software and Hardware Integration}\\
       \affaddr{Federal University of Santa Catarina}\\
       \affaddr{P.O.Box 476, 88040900 -- Florian\'opolis -- Brazil}\\
       \email{\{grw,lucas,giovani,guto\}@lisha.ufsc.br}
}

\maketitle

\begin{abstract}

Power management strategies for embedded systems typically rely on
static, application driven deactivation of components (e.g. sleep,
suspend), or on dynamic voltage and frequency scaling. However, the
design and implementation of these strategies in embedded operating
system often fail to deal with real-time and quality-of-service (QoS)
requirements.

The EPOS system implements an infra-structure that supports both
static (application-driven) and dynamic (system-driven) power
management. In this work, this infrastructure is used to explore
energy as a parameter for QoS in embedded systems, with the goal of
guaranteeing energy consumption metrics, while preserving the
deadlines of essential (hard real-time) tasks.  Given a set of
real-time tasks and their associated energy consumption, we provide
equations to check schedulability in project-time.  At runtime, a
preemptive scheduler for imprecise tasks prevents the execution of
optional subtasks whenever there is the possibility of deadline loss
or depletion of the energy source.  We show that this mechanism is
effective in controlling energy consumption and ensuring
``best-effort'' computation without deadline loss.



\end{abstract}

\category{B.10.1}{Power Management}{Energy-aware systems}
\category{D.4.1}{Process Management}{Scheduling}
\category{D.4.7}{Or\-gan\-i\-za\-tion and Design}{Real-time systems and embedded systems}

\terms{Algorithms, Design, Measurement}

\keywords{Power Management, Embedded Systems, Imprecise Computation} 

\section{Introduction}



Power management techniques rely on the ability of certain components
in a system to be turned on and off dynamically, enabling the system
as a whole to save energy when those components are not being
used. Additionally, techniques such as \emph{Dynamic
  Voltage Scaling}~(DVS) have been introduced to enable some
components to operate at different energy levels along the
time~\cite{Benini:1998}.

While these techniques are essential to the design of a power-aware
embedded system, their use often incurs in overhead (e.g. through a
dynamic power manager or monitor) or latency (e.g. the time required
for a component to enter or exit an energy-saving mode). These
factors cannot be ignored if the system is to respect real-time
metrics. On the other hand, it is not enough to guarantee real-time
metrics if, while doing so, the system exhausts its energy budget
(e.g. discharges its batteries) and is unable to complete its
tasks.

In this work, we use an application's energy budget, that is, its expected
battery lifetime, as a QoS parameter. Our goal is not only to save
energy, but to ensure that the application's energy budget
and the deadlines of hard real-time tasks are met.  In our system, QoS
control of applications was inspired by imprecise
computation~\cite{Liu:1994}, and divides each task into two sub-tasks,
 one mandatory, and one optional.  By monitoring
energy consumption, our scheduler is able to decrease QoS level by
preventing the execution of optional subtasks in order to reduce energy
consumption when the system is overusing its budget.

We provide equations to analyse the schedulability of a set of tasks
in terms of deadlines and energy budget at project time. At runtime,
our scheduler periodically checks energy levels to ensure that
optional sub-tasks only execute when there is enough energy to meet
the budget specified by the application. This control creates more
idle periods in the system, in which the scheduler can use power
management techniques to reduce the energy consumption of components.

The remainder of this text discusses power management strategies,
their use in embedded real-time systems, their design and
implementation in the EPOS~\cite{Froehlich:2001,Marcondes:ETFA:2006}
system, and the combination of power management techniques, real-time
scheduling and imprecise computation mechanisms to provide QoS in
terms of energy.

\section{Related Work}

%%% API, Infra-Structure

Few systems targeting embedded computing can claim to deliver a real
Power Management API. Nevertheless, most systems do deliver mechanisms
that enable programmers to directly access the interface of some
hardware components. This is the case of popular embedded operating systems
like \textsc{$\mu$Clinux} and \textsc{TinyOS}.
These mechanisms, though not specifically designed
for power management, can be used for that purpose at the price of
binding the application to hardware details.

\textsc{$\mu$Clinux}, like many other
\textsc{Unix}-like systems, does not feature a proper power management
API~\cite{uclinux}. Some device driv\-ers provide power management functions inspired
on ACPI~\cite{ACPI:2006}. Usually these mechanisms are intended to be used by the
kernel itself, though a few device drivers export them via the
\class{/sys} or \class{/proc} file systems, enabling
applications to directly control the operating modes of associated
devices.

\textsc{TinyOS}, a popular operating system in the wireless
sensor network scene, allows programmers to control the operation of
hardware components through a low-level, ar\-chi\-tec\-ture-dependent
API~\cite{Hill:2000}. This API ensures direct access to the hardware and thus can be
used for power management.  OS-driven power management is
implemented by the task scheduler, which makes use of the
\class{StdControl} interface to start and stop components. When the
scheduler queue is empty, the main processor is put in \emph{sleep}
mode.  This way, new tasks will only be enqueued during the execution of an
interrupt handler.  This method yields good results for the main
microcontroller, but leaves more aggressive methods, including
starting and stopping peripheral components up to the application.  When
compared to \textsc{$\mu$Clinux}, \textsc{TinyOS} delivers a lighter
mechanism, more adequate for most embedded systems, yet suffers from
the same limitations with regards to usability and portability.

%%% Real-time vs. Power Management

There is an important connection between real-time requirements and
power management strategies. On the one hand, a power management
strategy may introduce overhead (e.g. through a dynamic power manager
or monitor) or latency (e.g. the time required for a component to
enter or exit a energy-saving mode) into a real-time system. On the
other hand, information contained in scheduling algorithms may be used
to guide the power management strategy dictating, for example, when to
reduce processor frequency or when to turn off a given peripheral
component. Recent projects by Yuan, %~\cite{Yuan:2004},
Scordino, %~\cite{Scordino:2004}, 
and Niu %~\cite{Niu:2005} 
have explored this connection~\cite{Yuan:2004,Scordino:2004,Niu:2005}.

\textsc{Grace-OS} is an energy-efficient operating
system for mobile multimedia applications~\cite{Yuan:2004}. This system uses a
cross-layer adaptation technique to guarantee quality-of-service on
systems with adaptive software and hardware.  It combines real-time
scheduling with DVS mechanisms to allow dynamically managing energy
consumption. The \textsc{Grace-OS} scheduler decides each task's
execution speed and time, based on a probabilistic estimation of how
many cycles each task will need to complete its computation.
\textsc{Grace-OS} was implemented over the \textsc{Linux} operating
system and supports soft real-time tasks.
\textsc{GRUB-PA} shares the same objectives of 
\textsc{Grace-OS}, but supports both soft and hard real-time
tasks~\cite{Scordino:2004}. In \textsc{GRUB-PA}, the scheduler also reduces processor
frequency to save energy, but without compromising the deadlines of
real-time tasks.


Niu proposed to minimize energy consumed by soft
real-time systems while guaranteeing quality-of-service
requirements~\cite{Niu:2005}. This goal is achieved through the use of a hybrid
static/dynamic scheduling algorithm that uses DVS mechanisms and 
partitions the set of tasks in mandatory and optional tasks. In this
work, the quality-of-service requirements are qualified by
\textit{(m,k)} constraints which specify that tasks must meet at
least \textit{m} deadlines in any \textit{k} consecutive task
releases.

Other projects explore the trade-off between application's
quality-of-service and energy consumption through 
adaptative scheduling.
The \textsc{Odyssey} system periodically monitors an application's energy
budget, and selects different power consumption and performance levels 
according to the application's needs~\cite{Flinn:1999}.
Whenever energy consumption is too high, the system decreases QoS
by selecting lower performance and power consumption levels.
This allows the system to meet a specified lifetime by dinamically
adapting performance to save energy.




\textsc{ECOSystem}~\cite{Zeng:2002} is another operating system that
supports dynamic QoS adaptation. This system is based in a
``currency'' that applications use to allocate (``to pay for'') system
resources (e.g., access to memory, network or disks), called
\textit{currentcy}. The system distributes \textit{currentcies}
periodically to tasks accordingly to an equation that defines the
discharge rate that the system battery can assume to force the system
to last for a defined period of time. This allows applications to
adapt their execution based on their \textit{currentcy} balance. This
model unifies the calculation of energy on the various hardware
devices, but requires applications to manage and act upon a specific
energy budget.

%%% Imprecise computation

Harada explores the 
trade-off between QoS maximization and energy consumption
minimization, by allocating processor cycles and frequency with
quality-of-service guarantees, and dividing tasks into
mandatory and optional parts~\cite{Harada:2006}. 

The division of mandatory
and optional subtasks allows a system to satisfy timing requirements of real-time tasks
preventing the execution of optional subtasks, and thus decreasing
levels of quality-of-service that is the basic premise of imprecise computation~\cite{Liu:1994}. 
Imprecise computation unites real-time
computing and \emph{best effort} techniques for, respectively, the
mandatory and optional subtasks. The mandatory subtask of imprecise
tasks generates imprecise results which reflect the minimum of
quality-of-service to guarantee that these results are useful. These
imprecise results have their quality enhanced when the optional
subtask executes, generating the precise results.

While originally proposed to ensure hard real-time tasks deadlines,
imprecise computation may be used to save energy, by preventing the
execution of a given optional subtask according to a power management
criterion. In this work, we introduce the concept of
subtasks into the EPOS system to guarantee that all hard
real-time deadlines are met, and that optional sub-tasks only execute
when there is enough energy to meet the budget specified by the
application.


\section{EPOS}



EPOS (Embedded Parallel Operating system)~\cite{Froehlich:2001,
  Marcondes:ETFA:2006} is a component-based framework for the
generation of dedicated runtime support environments.  The EPOS system
framework allows programmers to develop platform-independent
applications. Analysis tools allow components to be automatically
selected to fulfill the requirements of these particular applications.
By definition, one instance of the system aggregates all the necessary
support for its dedicated application, and nothing else.


{

\sloppy

EPOS provides a wide set of operating system services through
platform-independent interfaces, and supports a wide range of
architectures, such as IA32, PowerPC, Sparc, MIPS, H8 and
AVR~\cite{Marcondes:ETFA:2006}.  EPOS provides an API for
application-driven power management services that supports \emph{power
  aware} operation of deeply embedded systems, without compromising
application portability and without incurring excessive overhead.
Furthermore, the system provides an active, oportunistic \emph{power
  manager}, a system resource monitor, and a real-time scheduler. This
section introduces the power management and real-time infrastructure
in EPOS, which was used to support the contributions in this work.

}

\subsection{Power-Management Infra-Structure}

%\subsubsection{Power Management API}

EPOS provides application-driven power management services, 
that allow \emph{power aware} operation of deeply embedded systems, without
compromising application portability and without incurring excessive
overhead. The goal of this power management system is to allow
applications to express when certain software components are not being
used, permitting the system to migrate hardware resources associated
with them to lower power levels. 


The Power Management API featured in EPOS~\cite{Hoeller:DIPES:2006}
supports direct application control of energy-related issues,
without excluding cooperation with an automatic power manager.
Furthermore, it is not restricted to the interface of hardware
components, but also acts at the level of user visible components,
thus promoting portability and usability. Finally, the API includes,
but is not restricted to, semantic modes, enabling programmers to
 express power management operations easily, but avoiding the
limitations of a small, fixed number of operating modes (as is the
case of ACPI).

The EPOS power management API features two methods:
\class{Power\_Mode power()}, and \class{power(Power\_Mode)}.  The
first method returns the current power mode of the associated object
(i.e., component), while the second allows for mode changes.  Aiming
at enhancing usability, four power modes have been defined with
semantics that must be respected for all components in the system:
\emph{off}, \emph{stand-by}, \emph{light} and \emph{full}. Each
component is still free to define additional power modes with other
semantics, as long as the four basic modes are preserved. Enforcing
universal semantics for these power modes enables application
programmers to control energy consumption without having to understand
the implementation details of underlying components (e.g., hardware
devices). Allowing for additional modes, on the other hand, enables
programmers to  control the operation of special component precisely,
whose operation transcend the pre-defined modes.

Table~\ref{tab:api-modes} summarizes the semantics defined for the
four universal operating modes. A component operating in mode
\emph{full} provides all its services with maximum performance,
possibly consuming more energy than in any other mode. Contrarily, a
component in mode \emph{off} does not provide any service and also
does not consume any energy. Switching a component from \emph{off} to
any other power mode is usually an expensive operation, specially for
components with high initialization and/or stabilization times. The
mode \emph{stand-by} is an alternative to \emph{off}: a component in
\emph{stand-by} is also not able to perform any task, yet, bringing it
back to \emph{full} or \emph{light} is expected to be quicker than
from mode \emph{off}. This is usually accomplished by maintaining the
state of the component ``alive'' and thus implies in some energy
consumption.  A component that does not support this mode natively
must opt between remaining active or saving its state, perhaps with
aid from the operating system, and going off.

\tab[t]{api-modes}{Semantic power modes of the proposed PM API.}


The hierarquical organization of components in EPOS allows
applications to act on different levels of components. 
The power management API features the concept of a \class{System}
pseudo-component, which can be seen as a kind of aggregator for the
actual components selected for a given system instance. The goal of
the \class{System} component is to aid programmers to express global
power management actions, such as putting the whole system in a given
operating mode, perhaps after having defined specific modes for
particular components.
Thus, the application may use the \class{System} component to
trigger a system-wide power mode
change. Another way the application may use this interface is through
subsystems (e.g., \textit{Inter-Process Communication} (\class{IPC}),
\class{Processing}, \class{Sensing}). In this way, messages are
propagated only to the components used in the implementation of each
subsystem. The application may also access the hardware directly,
using the API available in the device drivers, such as \textit{Network
  Interface Card} (\class{NIC}), \class{CPU}, or \class{Thermistor}.

%\subsubsection{Opportunistic Power Management}




A simple strategy for opportunistic power management is to make use of
the scheduler in an operating system. Whenever the scheduler has no
tasks to schedule, the system's main processor is put in standby
mode. However, this technique is very limited, as it does not regard
peripheral components, which in deeply embedded systems potentially
consume more energy than the main microcontroller.  In order to
contemplate these devices, an active power manager is required. This
manager checks component usage, and if a certain component is inactive
for a given period of time, it changes the components power state to a
lower level. One technique for detecting component usage makes use of
hardware activity counters for each component~\cite{Bellosa:2000}.
However, embedded systems hardware typically does not feature such
counters, and a software-based infra-structure for energy accounting
must be used.

EPOS features energy accounting in two levels: a system-wide
\emph{energy monitor}, and individual component \emph{access
  counters}. The energy monitor uses pre-determined information about
the system's hardware and power source to build an expected energy
consumption curve, and periodically samples the power source
(e.g. battery) through a charge sensor channel to calibrate its expected
discharge rate. This allows low-overhead energy accounting with
reasonable accuracy~\cite{Wiedenhoft:DIPES:2008}.

Access counters are implemented through an aspect program~\cite{Kiczales:1997}
that updates a timestamp each time the component is 
accessed~\cite{Wiedenhoft:ETFA:2007}.
EPOS supports aspects through a technique called 
\emph{Scenario Adapters}~\cite{Froehlich:2001}. Through this technique, an aspect \class{Scenario}
implements code that may be inserted before
and/or after the targeted operations. This mechanism also permits the extension of
the targeted component's interface and data structures.
Through this system, event counters were added to the accounting \class{Scenario}, 
and code to use these counters was added to each component. 






An opportunistic power manager, which is executed either
periodically or when there are no tasks to schedule,
checks the  utilization timestamps of each 	component
against the current timestamp of the system. A configurable
power management heuristic then decides  if and when to change
a component's power mode. In its simplest form, the power manager
puts all \emph{idle} components (components that have not been 
accessed for a pre-set period of time) to sleep mode.


Since both access counters and the power manager are implemented
through aspect programs, they may be extended, configured, or disabled
without incurring in significant interference in the application. The
power manager may be statically and dynamically configured through 
modification of the power management algorithm. This modification is
made available because the management algorithm is one of the main
factors in the balance between power economy and application overhead.
This way, reconfigurability allows the application programmer to
decide what power management algorithm his system will
support~\cite{Wiedenhoft:ETFA:2007}.


\subsection{Real-Time Scheduling}

%O diferencial da modelagem de escalonamento de tempo real no EPOS para as abordagens de outros sistemas operacionais está relacionado às filas de threads do escalonador.  As filas são ordenadas por um critério de escalonamento. Dessa forma, a substituição do critério de ordenação das filas substitui a política de escalonamento sem necessitar a alteração do escalonador propriamente dito. Nos casos em que a política necessite formas mais específicas de tratamento, um novo escalonador pode ser implementado herdando escalonadores pré-existentes.


The real-time scheduling infrastructure in EPOS is comprised of
three central components: \class{Thread}, \class{Criterion},
and \class{Scheduler}. The main difference between the EPOS real-time
modelling
and other real-time operating systems is related to the scheduler queues.
These are ordered according to a Criterion object, which may be replaced
according to the needs of specific applications.

Figure~\ref{fig:criterion} presents the class hierarchy of 
EPOS Criterion components. Real-time support is provided by
the \class{Real-Time} class, which inherits the priority
and scheduling information from the task. Periodic task
scheduling algorithms such as \class{RM} (Rate Monotonic)
and \class{EDF} (Earliest Deadline First), inherit period
information from the \class{Periodic} components. 

\fig[t]{criterion}{Class diagram of EPOS Criterion components}{width=\columnwidth}


The separation of scheduling policy and scheduler allows the
same scheduler to be used with different policies. In cases
where the policy requires specific scheduling treatment, a
new scheduler may be created by extending the existing schedulers.

\fig[t]{energy_time}{Intersection between energy and time}{width=3.7cm}


\section{Energy-aware Real-Time \\Scheduling}



In this work, we extend the real-time infra-structure in EPOS
to be able to use an application's energy budget (e.g. its expected
battery lifetime) as a QoS parameter. As in imprecise computation,
we divide each task into two parts: one mandatory and optional. 
In order for an optional subtask to execute it must meet two criteria: 
time and energy. It cannot interfere with the deadlines of mandatory
subtasks, and it may only execute when there is enough energy to
complete the set of mandatory tasks.

Our scheduler, which is based on the \textsc{EDF} policy (\emph{Earliest-Deadline First})~\cite{Liu:1973}, guarantees the
execution and meeting the deadlines of mandatory subtasks,
independently of the system energy level. However, the execution of optional
subtasks is not guaranteed. The optional subtasks are
executed only if the mandatory subtasks deadlines and the system
energy budget defined by application are met.
Figure~\ref{fig:energy_time} represents the tasks that comply with
both the energy (system lifetime) and time (mandatory subtasks deadlines)
criteria. Tasks outside the intersection of the two criteria fail scheduling tests for this algorithm.




\begin{algorithm}[tp]  
  \For{each task in the \textit{READY} state}{
    Determine the new absolute deadline \;
    Calculate priority according to deadline\;
    Insert into the queue according to calculated priority\;
  }
  \For{each rescheduling}{
    Select the highest priority task in the \textit{READY} state\;
    \For(\tcc*[f]{$\pi$ is configurable}){each $\pi$ time units}{
     Read the energy monitor\;
     Check if there is enough energy to meet the time specified by the application\;
    }
    \eIf{task is hard real-time}{
      Execute the selected task\;
    }(\tcc*[f]{task is \emph{best effort}}){
      \eIf{there is enough energy to meet the required system lifetime}{
         Execute the selected task\;
      }(\tcc*[f]{energy is not sufficient}){
         Execute the opportunistic power manager\;
      }
    }
  }
\caption{Scheduling Algorithm\label{fig:algoritmo}}
\end{algorithm}


The objective of this scheduler is not only to save energy --- otherwise, the technique would simply avoid executing the optional subtasks --- but to meet the energy budget (e.g. battery lifetime) 
specified
by the application and to meet the deadlines of mandatory subtasks with
the execution of the maximum possible of the optional subtasks, thus
improving the application \emph{utility}.









Figure~\ref{fig:algoritmo} presents our scheduling algorithm, in 
the subtasks are treated as tasks in terms of scheduling.  $\pi$ is
the interval between energy measurements, that can be specified
by the application programmer and must take into consideration that
each measurement consumes energy. This interval
depends on the energy state found in the last measurement.








\subsection{Schedulability Tests at Project-Time}
\label{sc:proposta:proposta:projeto}


Since our scheduler is based on the EDF algorithm, it is possible to
adapt the classic EDF schedulability tests to take both
energy and the division of tasks into mandatory and optional parts  into acount.
We assume the system has a set of $n$ periodic and independent tasks, 
${\displaystyle \tau} = \{\tau_0,\tau_1,...,\tau_{n-1}\}$. 
$P_i, D_i,$ and $C_i$ are parameters of each $\tau_i$, where $P_i$ is the period
in which task $i$ is scheduled, $D_i$ is the maximum relative deadline of the task $i$, and $C_i$ is the 
worst case execution time of task $i$.
In our tests, we assume  that $\forall\tau_i$, $D_i \le P_i$ . The utilization $U_i$
of task $i$ in terms of processing  is represented by  
$U_i = \frac{C_i}{D_i}$ .

In the imprecise computation model, each $\tau_i$ is divided
into mandatory and optional subtasks with worst case execution times
of $\mu_i$ and $\theta_i$, respectively. Therefore, the worst case
total execution time of $\tau_i$ is $C_i = \mu_i + \theta_i$.  In
order to guarantee that no mandatory subtask deadlines will be lost,
equation (\ref{eq:escalonador:m}) must be respected.

\begin{equation}
\sum_{i=1}^n \left (\frac{\mu_i}{D_i} \right) + \sigma \le \omega
\label{eq:escalonador:m}
\end{equation}


%\noindent 
Where $\omega = 1$ for a system with a single-processor and $\sigma$
represents the run-time overhead in the worst case, which includes: time spent in
the operating system, context switch, scheduler algorithm.
Equation (\ref{eq:escalonador:m}) must be met in order for the tasks to be
schedulable in relation to mandatory subtasks deadlines, otherwise, 
the processor is overloaded.



With the inclusion of the optional subtask execution time in equation
(\ref{eq:escalonador:m}), we can determine if the tasks as a whole
(both mandatory and optional subtasks) will be
executed. However, it is important to note that
equation (\ref{eq:escalonador:mo}) is not an obligatory requirement in our 
algorithm and only will be relevant when
equation (\ref{eq:escalonador:m}) is true, otherwise, the tasks are not
schedulable.


\begin{equation}
\sum_{i=1}^n \left (\frac{\mu_i + \theta_i}{D_i} \right) + \sigma \le \omega
\label{eq:escalonador:mo}
\end{equation}


Mandatory and optional subtasks are schedulable in relation to
their deadlines when equation (\ref{eq:escalonador:mo}) is respected.
Otherwise, a certain fraction $\chi$ of optional subtasks is discarded,
as shown in equation (\ref{eq:escalonador:x}).


\begin{equation}
\chi = \frac{\displaystyle \sum_{i=1}^n \left (\frac{\mu_i + \theta_i}{D_i} \right)
+ \sigma - \omega}{\displaystyle \sum_{i=1}^n \left (\frac{\theta_i}{D_i}
\right)}
\label{eq:escalonador:x}
\end{equation}

In order to deal with energy requirements, it is necessary to
take into account the energy consumption rate of each task. 
The $E_i$ worst case energy consumption of a task $\tau_i$, is
given by the sum of the worst case energy consumption of the mandatory and optional
subtasks $E_{\mu i}$ and $E_{\theta i}$, respectively (i.e., $E_i =
E_{\mu i} + E_{\theta i}$).
As it is the case with the worst case execution times, it is necessary
to assess the worst case energy consumption rate beforehand.
These values can be obtained by energy profiling or another techniques. 
The maximum number of possible executions $\eta_i$ of $\tau_i$ in the time $T_t$
required by the application is given by the division between the time required and
the execution interval of $\tau_i$, i.e., $\eta_i = \frac{T_t}{P_i}$. $T_t$ is
determined by the application developer based on energy capacity.
In order to guarantee the execution of at least the mandatory subtasks, 
equation (\ref{eq:escalonador:en}), which indicates if the set of tasks will be
schedulable with respect to energy, must be respected.


\begin{equation}
\sum_{i=1}^n \left (\frac{E_{\mu i} \times \eta_i}{E_t} \right) + \epsilon \le 1
\label{eq:escalonador:en}
\end{equation}


%\[ \sum_{i=1}^n \left (\frac{E_{\mu i} \times \eta_i}{E_t} \right) + \epsilon \le
%1 \]


%\noindent 
Where $E_t$ is the total energy available to the system (e.g. battery capacity), 
$\epsilon$ represents the worst case energy consumption of operating system services
such as alarms, context switches and the scheduler itself. In this equation, the
total energy is set to 1 (e.g. battery capacity is 100\%). By
substituting the maximum number of possible executions $\eta_i$ 
in equation (\ref{eq:escalonador:en}) we obtain equation (\ref{eq:escalonador:e}).

\begin{equation}
\sum_{i=1}^n \left (\frac{E_{\mu i} \times T_t}{P_i \times E_t} \right) + \epsilon \le 1
\label{eq:escalonador:e}
\end{equation}


The tasks are schedulable in relation to energy if equation
(\ref{eq:escalonador:e}) is respected. Otherwise, the
system will not meet energy budget required by application for this set
of tasks. The inclusion of the energy consumed by optional subtasks in
equation (\ref{eq:escalonador:e}) allows us to check if the tasks as a whole
will be executed. As discussed previously, this
is not an obligatory requirement and equation (\ref{eq:escalonador:eo}) only
should be calculated if equation (\ref{eq:escalonador:e}) is respected,
i.e., the mandatory subtasks have met their energy budget.


\begin{equation}
\sum_{i=1}^n \left (\frac{\left (E_{\mu i} + E_{\theta i} \right ) \times T_t}{P_i
\times E_t} \right) + \epsilon \le 1
\label{eq:escalonador:eo}
\end{equation}


All mandatory and optional parts of the tasks are executed in relation to system
energy if equation (\ref{eq:escalonador:eo}) is respected. Otherwise, a
certain fraction $\gamma$ of optional subtasks will not be executed because the
system would not meet the energy budget specified by the application. Equation
(\ref{eq:escalonador:y}) provides a fraction $\gamma$ of optional subtasks
discarded in relation to energy.

\begin{equation}
\gamma = \frac{\displaystyle \sum_{i=1}^n \left (\frac{ \left (E_{\mu i} + E_{\theta i} \right ) \times T_t}{P_i \times E_t} \right) + \epsilon - 1 }{\displaystyle \sum_{i=1}^n \left (\frac{E_{\theta i} \times T_t}{P_i \times E_t} \right)}
\label{eq:escalonador:y}
\end{equation}

In order to provide real-time and energy-aware scheduling, it
is necessary to respect all the mandatory substasks deadlines and
to have enough energy to execute all the mandatory substasks.
Equation (\ref{eq:escalonador:te}) is used to determine if
a given set of tasks is schedulable in our system.
 


\begin{equation}
\left [ \sum_{i=1}^n \left (\frac{\mu_i}{D_i} \right) + \sigma \le \omega
\right ]  \wedge  \left [ \sum_{i=1}^n \left (\frac{E_{\mu i} \times T_t}{P_i \times E_t}
\right) + \epsilon \le 1 \right ]
\label{eq:escalonador:te}
\end{equation}



The mandatory subtasks have their executions guaranteed in our scheduler in
relation to time and energy if equation (\ref{eq:escalonador:te}) is
respected. The maximum fraction $\lambda$ of possible optional subtasks lost in
relation to time and energy can be obtained by equation
(\ref{eq:escalonador:l}).


\begin{equation}
\lambda = \max \left ( \chi , \gamma  \right)
\label{eq:escalonador:l}
\end{equation}


\subsection{Schedulability at Execution-Time}
\label{sc:proposta:proposta:execucao}


In order to provide quality of service in terms of energy and make better use of resources
through the execution of optional subtasks, it is necessary to periodically check if the system lifetime 
%$T_{t}$ in the instant $\kappa$ 
can be achieved at execution-time. 
Therefore, the system lifetime, $T_{t \kappa}$, and the system energy (e.g. battery charge), 
$E_{t \kappa}$, at instant $\kappa$ are recalculated.
%according to the elapsed time, the system lifetime at instant $\kappa$, $T_{t \kappa}$, 
%is recalculated.
% in the instant $\kappa$ according to the elapsed time. 
%The system energy at instant $\kappa$ (e.g. battery charge), $E_{t \kappa}$, also must be recalculated. 
Equation (\ref{eq:escalonador:ek}) can
be calculated with the new values in order to check if $T_{t \kappa}$ can be
met at instant $\kappa$. This equation uses the discharge rate in the last
period to check wether the $T_{t \kappa}$ can be attained at the current power
levels.


\begin{equation}
\left[ \left (\frac{E_{t \kappa}}{E_{t \kappa-1} - E_{t \kappa}} \right) \times \left (T_{t \kappa-1} - T_{t \kappa} \right) \right] \ge T_{t \kappa}
\label{eq:escalonador:ek}
\end{equation}


If equation (\ref{eq:escalonador:ek}) is respected, there is enough energy to meet $T_{t \kappa}$.
Thus, 
all mandatory subtasks are executed and optional subtasks are scheduled.
%All mandatory subtasks are executed and optional subtasks will be scheduled 
%if equation (\ref{eq:escalonador:ek}) is respected because this equation
%indicates there is sufficient energy to meet $T_{t \kappa}$. 
Otherwise, some optional subtasks will be discarded, decreasing quality-of-service, and the 
scheduler invokes the oportunistic
power manager using 
%in the time that the optional subtasks would execute. 
%Thus, it uses 
%the idle time of the system
the time that the optional subtasks would execute 
in order to save energy. 
In a future instant $\kappa+1$, if $T_{t {\kappa+1}}$ 
%equation (\ref{eq:escalonador:ek}) 
is satisfied, the optional subtasks will resume execution, increasing quality-of-service.








\section{Case Study}

Sensor data acquisition is an example of an application that may benefit
from imprecise computing. Multiple averaged readings from an unreliable
data source may improve accuracy when compared to a single reading
from the same source. Multiple readings, however, may also incur
in excessive computation time and energy consumption. An imprecise 
scheduler may choose when to perform multiple readings to improve accuracy,
and when to perform a single reading to save system resources.


\fig[tp]{sense_app}{Sequence Diagram of the Data Acquisition Application}{width=6cm}


\prg{sense_app}{System APIs used by the Data Acquisition Application}



%\afterpage{\clearpage}



In this case study, we used Mica2 sensor nodes~\cite{Hill:2004} to design a 
data acquisition application that periodically samples data from a 
temperature sensor and sends sensor data to the network. 
Figure~\ref{fig:sense_app} features a sequence diagram that
 illustrates the behaviour of this application.
Following
our imprecise computation model, the mandatory part of our sensing
task performs a single reading. If there is enough time and energy
available in the system, an optional part performs multiple averaged
readings. Finally, a communication task sends the sensor data,
either from the single mandatory reading or from the multiple averaged readings.





We implemented this application for the EPOS system, using our
imprecise computation model. Figure~\ref{prg:sense_app}
illustrates the system APIs used by the application. The \class{main}
function first creates a temperature sensor and a communication link~\cite{Wanner:ETFA:2006,Wanner:IESS:2007},
and proceeds to create an imprecise and a periodic thread, wich represent
our sensing and communication tasks.
%
The mandatory part of the data acquisition task performs a single
reading of the sensor, and waits for its next execution period.
When executed, the optional part performs multiple readings (in this case 10 readings if possible), averaging all the 
previous readings. When finished, the optional part also
releases the processor and waits for its next sheduling.
Finally, the communication task sends the collected data,
which was last updated by the mandatory or by the optional part.

\figspan[tp]{sched}{Scheduling Diagram}{}


%Values are presented in table~\ref{tab:crit}.









The imprecise thread receives its mandatory and optional functions as a parameter,
while the periodic thread receives a single function. Both threads
receive a criterion as a parameter, which
specifies deadline, period, number of execution times, and phase for each thread. 
The deadline of each thread is set so that the order of
mandatory sensing, optional sensing and communication is preserved.
All threads run for an infinite number of times. 
Table~\ref{tab:criterion} presents the scheduling criteria for
both threads.
% The imprecise
% sensing thread is configured with 0~ms phase, 150~ms deadline,
% and 170~ms period. The periodic communication thread is configured
% with 150~ms phase, 20~ms deadline, and 170~ms period (Table~\ref{tab:criterion}). 
Figure~\ref{fig:sched} presents the scheduling diagram for the
application. 

\tab[t]{criterion}{Scheduling Criteria}



In order to check schedulability at project time, we profiled our
application for time and energy with a digital osciloscope.
Table~\ref{tab:worst} presents the worst case execution time and energy consumption for one
execution of our tasks and total system overhead for one period. These values represent the average from 9100 samples.

\tab[t]{worst}{Worst-case execution time and energy consumption.}




In this example, our energy budget was the charge provided by two regular AA batteries with 
a total capacity of  58320~J (5400~mAh at 3~V). We configured the system
with an expected lifetime of 11~days, or 950400000~ms. It should be noted that,
in order to better illustrate energy budget exaustion,
our application purposedly set the system to a full load. Most applications
would tipically run at a considerably lower duty-cycle, and thus for a longer period of
time. In order to check schedulability of the application with relation to time,
we applied the application values to equation~(\ref{eq:escalonador:m}):

\begin{eqnarray}
\label{eq:escalonador:m:ap}
\sum_{i=1}^n \left (\frac{\mu_i}{D_i} \right) + \sigma & \le \omega  \nonumber\\
\left ( \frac{11.683~\mathrm{ms}}{150~\mathrm{ms}}\right) + \frac{0.138~\mathrm{ms}}{150~\mathrm{ms}}    & \le 1 \nonumber\\
0.078 & \le 1
\end{eqnarray}

Since~(\ref{eq:escalonador:m:ap}) is true, the mandatory parts are schedulable
with relation to time.  The application of equation~(\ref{eq:escalonador:mo}), presented in  (\ref{eq:escalonador:m:ap:opt})
 shows that, both mandatory and optional parts are schedulable with relation to time. 

\begin{eqnarray}
\label{eq:escalonador:m:ap:opt}
\sum_{i=1}^n \left (\frac{\mu_i + \theta_i}{D_i} \right) + \sigma & \le \omega \nonumber\\
\left ( \frac{(11.683 + 0.138 + 116.831 + 0.138)~\mathrm{ms}}{150~\mathrm{ms}} \right) & \le 1 \nonumber\\
0.8586 & \le 1
\end{eqnarray}




In order to check schedulability of the application with relation to energy,
we applied the application values to equation~(\ref{eq:escalonador:e}):


\begin{eqnarray}
\label{eq:escalonador:e:ap}
\sum_{i=1}^n \left (\frac{E_{\mu i} \times T_t}{P_i \times E_t} \right)  +   \epsilon & \le 1\nonumber\\
{ \left (\frac{425.4 \times 10^{-6} \mathrm{J}   \times 950.4 \times 10^6 \mathrm{ms}}{170~\mathrm{ms} \times 58320~\mathrm{J}} \right )} + & \nonumber\\
\left (\frac{9828.9 \times 10^{-6} \mathrm{J} \times 950.4 \times 10^6 \mathrm{ms}}{170~\mathrm{ms} \times 58320~\mathrm{J}} \right )  & \le 1  \nonumber\\
%
{ \left (\frac{425.4 \times 950.4}{170 \times 58320} \right )} +
\left (\frac{9828.9 \times 950.4}{170 \times 58320} \right )  & \le 1  \nonumber\\
%
% & \le 1 
0.0407791 + 0.9422039  &  \le 1 \nonumber\\
0.9829830 & \le 1 
\end{eqnarray}

Since~(\ref{eq:escalonador:e:ap}) is true, the tasks are schedulable with relation to energy.
However,
the application of equation~(\ref{eq:escalonador:eo}) shows that some optional subtasks will
be lost due to energy constraints, as seen in (\ref{eq:escalonador:e:ap:opt}):

\begin{eqnarray}
\sum_{i=1}^n \left (\frac{\left (E_{\mu i} + E_{\theta i} \right ) \times T_t}{P_i
\times E_t} \right) + \epsilon & \le 1 \nonumber\\
\left (\frac{\left ( 425.4  + 4254.3   \right )\times 10^{-6} \mathrm{J} \times 950.4 \times 10^6 \mathrm{ms}}{170~\mathrm{ms} \times 58320 ~\mathrm{J}} \right ) + & \nonumber\\
\left (\frac{9828.9 \times 10^{-6} ~\mathrm{J} \times 950.4 \times 10^6 \mathrm{ms}}{170~\mathrm{ms} \times 58320 ~\mathrm{J}} \right )  & \nonumber\\
%
\left (\frac{4679.7 \times 950.4}{170 \times 58320} \right ) +
\left (\frac{9828.9 \times 950.4}{170 \times 58320} \right )  & \nonumber\\
%
0.4485987 + 0.9422039  & \nonumber\\
1.3908026 & \nleq 1 
\label{eq:escalonador:e:ap:opt}
\end{eqnarray}



Since the application of equation~(\ref{eq:escalonador:eo}) 
fails for this test, the system will decide at run-time when
to execute the optional subtasks.
The system is configured with a master timer of 72Hz, and
each thread has a quantum of 15ms. In each rescheduling,
the scheduler checks if the next task is a real-time or
mandatory task by cheking its priority. If this test is true,
then the task receives the processor. Otherwise, the
task is optional, and receives the processor only if 
there is enough energy to meet the desired system lifetime.
If the task is optional, and energy is not enough,
the processor and peripheral components are put in low
power mode through the power manager~\cite{Wiedenhoft:ETFA:2007}.

\figspan[p]{power_time}{Power rate along time}{width=15cm}

\figspan[p]{qos_time}{QoS levels along time}{angle=270,width=15cm}



Figure~\ref{fig:power_time} presents the power rate of
our test application along the time. In the curve with
the highest power rate, the system is configured so
that it executes every task, optional and mandatory.
In the curve with the lowest power rate, the system
is configured so that it only executes the mandatory parts.
The midddoes notle curve represents the use of our imprecise
computing model, where optional tasks only execute
if the system is within its energy budget.

Figure~\ref{fig:qos_time} presents different QoS levels along time for the imprecise computing model. 
In this graphic, QoS level is defined as the number of sensor readings
performed in a given period. When there is enough energy in the system, optional
subtasks are scheduled, increasing quality of service. When energy levels
are lower than expected, the optional parts are discarded. The battery monitor
periodically checks the battery level. If it detects a lower than expected energy level, it may
preempt the execution of optional subtasks, resulting in intermediate levels of quality of service (e.g. 
when only two iterations of the optional subtask were executed). 


% This figure shows the optional task behavior when a preemption occurs. There are two kinds of preemption, one related to task deadline and other regarding system energy. 
% The task deadline is not met when the new mandatory activation begins and the optional task has not finished yet. This scenario is presented in the first dot in means the graph. The energy preemption occurs when equation (\ref{eq:escalonador:ek}) is not respected which is presented in the second dot in means the graph.

% Considering that the
% power source (battery) is the same for each test, 
% the smaller the $T_t$, the more energy is left in the
% system to execute optional subtasks, increasing QoS levels.
% As $T_t$ aproaches the total possible lifetime of the
% system, no mandatory parts are executed.






\section{Conclusion}

In this work, we extended the real-time scheduling and the power
management infrastructure in the EPOS operating system to use
an application's energy budget as a QoS parameter. Through our
imprecise computation model, application programmers define mandatory
and optional parts of the application's tasks, an expected system lifetime,
and an energy budget. Whenever there 
is enough energy in the system to meet the application's budget,
the optional parts are executed, increasing QoS. Otherwise, only the mandatory parts
run, allowing the system to save energy. 
%As demonstrated by our case study,
%this automatic, adaptative quality control allows applications to achieve their
%compromise between quality-of-service
%and energy consumption.


In addition to our case study of single point data acquisition, this system could also be used to manage QoS in a network of sensors. For example, in an application that uses freshness of information as the main parameter of QoS, our system could be used to dynamically update sensor information according to energy availability. Thus each node would decide, based on its available time and energy, whether to update its sensor readings or to keep an older reading. In this example, the quality of service of the sensor network application would be automatically adapted to suit the available resources. As demonstrated by our case study, this automatic, adaptative quality control allows applications to achieve their compromise between quality-of-service and energy consumption.


%In this context, applications that use liveness of information is an important sensoring example for our work. 
%%Therefore, there are many possible applications for this work in particular sensoring applications. For example, applications that use liveness of information. 
%In these applications, the information could expire its lifetime,  
%%altough old, 
%remaining alive %valid 
%for a period of time and can be reused if a new reading is not available. In the context of this work, if there is enough time and energy available in the system, the optional subtasks perform new data readings. Otherwise, only the mandatory subtasks 
%run, using the previously data and periodically would perform new readings in order to uptade the data. 
%As demonstrated by our case study,
%this automatic, adaptative quality control allows applications to achieve their
%compromise between quality-of-service
%and energy consumption.



%An important example are those that 
%%within these applications 
%can use the old data. In this kind of applications, if there is enough time and energy available in the system, the optional subtasks perform new data readings. Otherwise, the mandatory subtasks use the old data and periodically perform new readings. 




\bibliographystyle{abbrv}
\bibliography{pm_epos}

%\balancecolumns

\end{document}


