\documentclass[9pt,conference]{IEEEtran}

\usepackage[latin1]{inputenc}	% for Latin languages
\usepackage[T1]{fontenc}	% for ISO and UTF characters
\usepackage[english]{babel}	% for multilingual support
%\usepackage{hyperref}
%\hypersetup{
    %colorlinks=false,
%    pdfborder={0 0 0},
%}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subfig}%switch to subcaption if problems with hyperref arrizes
\usepackage{booktabs}
%\usepackage[caption=false]{caption}
%\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\usepackage{color}
%\definecolor{Red}{rgb}{.9,0,0}

%\newcommand{\codefont}{\footnotesize\sffamily}
\newcommand{\codefont}{\scriptsize\sffamily}



\usepackage{listings}
%\lstset{keywordstyle=\bfseries, flexiblecolumns=true, breaklines = true, numbers = left,
%        xleftmargin=1.5em,numbersep=5pt}
\lstset{keywordstyle=\bfseries, flexiblecolumns=true, numbers = none}
%\lstset{frame=single,framexleftmargin=2em}
\lstloadlanguages{[ANSI]C++,HTML}
\lstdefinestyle{prg} {basicstyle=\codefont, lineskip=-0.2ex, showspaces=false}

\usepackage{microtype}

\usepackage{hyperref}
\hypersetup{
    colorlinks=false,
    pdfborder={0 0 0},
}

\include{utils} %new commands 

%\setlength{\intextsep}{8pt}
%\setlength{\floatsep}{-1ex}
%\setlength{\dblfloatsep}{-1ex}
%\setlength{\abovecaptionskip}{1pt}
%\setlength{\belowcaptionskip}{1pt}
% use '-1ex' to eliminate space
%Options    
%\floatsep - Space between floats. \dblfloatsep for 2 column format
%\intextsep - Space above and below in-line text floats
%\abovecaptionskip - Space above float caption
%\belowcaptionskip - Space below float caption

\hyphenation{Meta-pro-grams}

\renewcommand{\subsubsection}[1]{\vspace{0.3cm} \noindent \textit{#1} \vspace{0.2cm}}

\newcommand*\tlmch{\scalebox{0.65}{\includegraphics{fig/fig_virtual_platform_tlm_symbol}}}

\newcommand*\figsize{0.55}

\begin{document}
   
\title{Seamless integration of HW/SW components in a HLS-based SoC design environment}

\author{Tiago Rogério Mück and Antônio Augusto Fröhlich\\
\IEEEauthorblockA{Software/Hardware Integration Lab\\
Federal University of Santa Catarina\\
Florianópolis, Brazil\\ 
Email: \{tiago,guto\}@lisha.ufsc.br}
}

\maketitle

\begin{abstract}
With \textit{system-on-chip}~(SoC) designs growing in complexity, system-level
approaches that leverage on \textit{high-level synthesis}~(HLS) techniques are becoming the
workhorse of current SoC design flows. In this scenario, we propose a component communication
framework that allows for the seamless integration of hardware and software components  in
a HLS-capable environment. The proposed infrastructure relies on C++ static
metaprogramming techniques to efficiently abstract communication details in high-level C++
implementations of components. We show how these mechanisms can be integrated with virtual platforms
at different levels of abstraction, resulting in a design flow that enables the rapid design space
exploration of SoC designs.
\end{abstract}

\begin{IEEEkeywords}
System-on-chip; High-level synthesis; HW/SW co-design; Virtual platforms
\end{IEEEkeywords}

\section{Introduction}
\label{sec:introduction}

\textit{System-on-chip}~(SoC) designs are becoming more sophisticated as the advances of
the semiconductor industry allows the use of an increasingly amount of computation resources in a
wide range of applications. Low-power and small \textit{field-programmable gate arrays}~(FPGAs),
for instance, are now enabling the rapid deployment of complex and fully customized SoC designs even
for small-scale applications. In this scenario, the
strict time-to-market requirements of most applications demands a better productivity than what is
possible with current \textit{register transfer level}~(RTL) methodologies, thus leading to a
growing demand for \textit{high-level synthesis}~(HLS) solutions. HLS is a (semi-)automatic process
that creates cycle-accurate RTL specifications from untimed or partially timed behavioral
specifications. Current tools (e.g \cite{Calypto:Catapult,Xilinx:Vivado}) already support hardware
synthesis from high-level C++ and SystemC descriptions, allowing the use of higher-level
implementation techniques, such as \textit{object-oriented programming}~(OOP). 

These tools can be employed to create design flows in which hardware and software can be
implemented in the same level of abstraction~\cite{Mueck:ICECS:2012}, facilitating the creation of
component instances in both hardware and software domains. In such scenario, SoC components must be
able to communicate seamlessly whether they are implemented as software running in a processor or as
dedicated hardware IPs. Most design techniques do not provide such flexibility in the sense that
the software views hardware circuits mostly as passive co-processors\cite{So:2008,Cong:2011,Xilinx:Vivado}. 
This may potentially lead to major system redesigns when changes in the hardware/software
partitioning are performed in the final phases of the design process.

In order to contribute to this scenario, in this paper we show how hardware and software components
implemented in C++ following OOP principles can be seamlessly integrated in a HLS-capable
environment. This
integration is performed through a \textit{remote method invocation}~(RMI) mechanism that allows
cross-domain communication between hardware and software components. Our communication
infrastructure is also fully implemented using C++ and \emph{static metaprogramming}
techniques~\cite{Czarnecki:2000}. This results in mechanisms that can be directly parsed by
C++-based HLS tools and software compilers, thus reducing the need of non-standardized language
support.

We also describe a \textit{network-on-chip}~(NoC)-based SoC platform and show how components can be
deployed either as
independent hardware IPs or as software running within a NoC CPU node. Furthermore, apart from a
physical platform, high-level
hardware simulation models of the input components and IPs may be generated and assembled to build a
\emph{virtual platform}. Virtual platforms are present in many SoC design
flows~\cite{Gruttner:2010,Keinert:2009,Domer:2008} as a faster alternative to full-fledged RTL
simulations. Our proposed virtual platform supports rapid functional validation
and performance evaluation of the system by employing  both high-level \emph{transaction-level
models}~(TLM)~\cite{Cai:2003} extracted directly from the original C++ implementation, and
cycle-accurate models generated during the high-level synthesis process. 

%may be removed
The remaining of this paper is organized as follows: 
Section \ref{sec:comp_cmm} presents the programming and RMI communication models; in
Section \ref{sec:platform} we describe the proposed SoC platform; Section \ref{sec:design_flow}
presents the integration of the RMI mechanisms in our design flow; Section
\ref{sec:case_study} describes the implementation and design space exploration of a phone call
processing pipeline extracted from a PABX/VoIP application; Section \ref{sec:related_work} discuss
related work and Section \ref{sec:conclusion} closes the paper with our conclusions.

\section{Programming and communication model}
\label{sec:comp_cmm}

Communication modeling is an important aspect in the design of complex embedded systems.
In the software domain, components may be objects which communicate using method invocation
(considering an object-oriented approach), while in the hardware domain, components may
communicate using
input/output signals and specific handshaking protocols. For communication through different
domains, the software must provide appropriate \textit{hardware abstraction layers}~(HAL) and
\textit{interrupt service routines}~(ISR), while the hardware must be aware that it is requesting a
software operation.  

In this work, we have chosen to rely on a pure object-oriented programming model. An OOP model
has the necessary expressiveness to describe component interactions at the application level and is
becoming an established standard for both hardware and software due to the introduction of C++-based
synthesis. ANSI C++ and its OOP features are extensively supported by both hardware HLS tools and
software compilers, thus increasing the applicability of our approach over different design flows
and tools.

When focusing on an OOP-based methodology, one must provide ways to abstract the possible
hardware/software partitionings from the high-level model.
To illustrate this issue,
Figure~\ref{fig_oop_to_phy} shows a simple system represented in an OOP model. A
component can be implemented as a part of another object (e.g. \emph{C2}) creating a hierarchical object
composition. Such characteristics may hinder the direct mapping between an OOP model and a physical
implementation. As show in Figure \ref{fig_oop_to_phy}, the original structure may be
``disassembled'' in the final physical implementation if different objects in the same class
hierarchy represent components that are to be implemented in different domains. For example,
\emph{C2} is ``inside'' \emph{C1} in the OO model in Figure
\ref{fig_oop_to_phy}, but, in a possible final implementation, \emph{C2} could be implemented as a
hardware component while \emph{C1} could run as software in a processor (first mapping in Figure
\ref{fig_oop_to_phy}).  Furthermore, the different communication patterns between hardware and
software must also be properly abstracted. For instance, in the second mapping shown in Figure
\ref{fig_oop_to_phy}, \emph{C1} can call \emph{C2}'s methods directly, while in the first mapping
a hardware/software communication mechanism must be defined.

\figSC{\figsize}{fig_oop_to_phy}{Possible mappings of an object-oriented model to physical
implementations}

To overcome this issue, we employ an approach based on RMI concepts from distributed object 
platforms~\cite{Ostrowski:2008}. Figure \ref{fig_remote_invocation} illustrates the
\mbox{\emph{SW-->HW-->SW}} interactions that results from the first mapping shown in Figure
\ref{fig_remote_invocation}. Callee components are represented in the domain of callers by
\emph{proxies}. When an operation is invoked on the components' proxy, the arguments supplied are
marshaled in a request message and sent through a \emph{communication channel} to the actual
component. An \emph{agent} receives requests, unpacks the arguments and performs local method
invocations. The whole process is then repeated in the opposite direction, producing reply messages
that carry eventual return arguments back to the caller.

\figSC{\figsize}{fig_remote_invocation}
{Cross-domain communication using proxies and agents}

\section{System-on-Chip platform}
\label{sec:platform}

The implementation of \emph{channels}, \emph{proxies} and
\emph{agents} can be realized in several different ways (e.g. specific buses, DMA, NoCs). Figure
\ref{fig_platform} shows the chosen hardware/software architecture to implement these mechanisms. We
rely on a NoC as the main communication link between hardware and software components. While a
bus-based MPSoC can provide a good trade-off for software-centric designs that rely on hardware
mostly as passive accelerators, it is not the most suitable choice for more heterogeneous designs in
which hardware components have active roles~\cite{DeMicheli:2010}, therefore in our work we have
favored a NoC based architecture. The \textit{Real-time Star NoC}~(RTSNoC)~\cite{Berejuck:2011} is
the basic infrastructure of our SoC platform. RTSNoC
consists of a set of \emph{routers} with a star topology that can be arranged forming a 2-D mesh.
Each router has eight bidirectional channels that can be connected to cores or to channels of other
routers. Each application-specific hardware IP is deployed as a node connected to the router.
Software components are compiled with a \textit{real-time operating system}~(RTOS) and run in a \emph{CPU node} that consists of a
softcore CPU and memories. 

\figSC{\figsize}{fig_platform}{System-on-Chip platform}

The internal structure of a CPU node is based on the AXI4 family of protocols, which is becoming the
industry's standard for bus-based interconnection. In our current implementation we focused on
reusability and in avoiding vendor-specific IPs, thus we have relied on IPs available at
Opencores\footnote{http://opencores.org/}. Our current CPU node, for instance, is based on the
\emph{Plasma} softcore, an implementation of the MIPS32 ISA.

The software components runs on an RTOS which provides the necessary run-time support to implement
the proxies and agents described previously. For our current implementation we have chosen the
\textit{Embedded Parallel Operating System}~(EPOS). EPOS is an open-source\footnote{EPOS
source code along with the sources of all components and artifacts described in this paper are
available in the \emph{EPOS project} web-page: http://epos.lisha.ufsc.br/}, multi-platform,
object-oriented,
component-based, operating system for embedded applications~\cite{Froehlich:2001,EPOS:2013}.
Platform-independent system components implement
traditional OS services, such as threads and semaphores. Hardware Mediators implement
platform-specific support and are functionally equivalent to device drivers in Unix, but do not
build a traditional HAL~\cite{Polpeta:2005}. Instead, Hardware mediators are incorporated by high
level components through static metaprogramming and inlining techniques. Figure~\ref{fig_platform}
summarizes the main families of abstractions provided by EPOS to applications.


\section{Design flow}
\label{sec:design_flow}

Our design flow consists in a set of basic steps shown in Figure~\ref{fig_hw_flow}.  The
developer provides high-level implementations in C++ of the software and hardware components that
build up the application.  An automated process then generates the respective proxies and agents
which
are part of the communication framework. In the software side of the flow, the components and their
proxies/agents are compiled with EPOS. The hardware implementation flow encompass a process which
includes: 1) C++-to-RTL synthesis using a HLS tool; 2) binding of the generated RTL descriptions and
models with the pre-existing IPs to build the hardware platform; and 3) system validation using the
virtual platform and its subsequent synthesis to the target FPGA device. Each of these steps is
described in more details below.

\figSC{\figsize}{fig_hw_flow}{Design flow overview}

\subsection{Proxies and agents}
The proxies and agent are automatically generated by EPOS analyzer~\cite{Schulter:2007}. EPOS
analyzer is a syntactical analysis tool that obtains the signatures of all methods in the
component's interface. With this information, a proxy or agent can be generated automatically. The
example below shows the generated proxy for a software implementation of the component \emph{C2}
shown in Figure \ref{fig_oop_to_phy}.
%
\progcppinline{code_proxy_example}
%
The proxy only replicates the signatures of all methods in the component's public interface and
implements their behavior using RMI primitives defined by the class \emph{SW\_Proxy\_Base}.

The agent implementation follows a similar approach. For instance, the following is code generated
for \emph{C2}'s hardware agent:
%
\progcppinline{code_agent_example}
%
The mechanisms that parse the RMI messages are inherited from \emph{HW\_Agent\_Base}. The
component implementation is also incorporated through inheritance. Therefore, each specific
generated agent must only implement a \emph{dispatch} method which defines a switch statement that
selects the correct component method using information parsed by \emph{HW\_Agent\_Base}. Proxies
in hardware and agents in software are also generated following the same structure.

\subsubsection{Proxies and agents implementation}

As shown above, the actual implementation of the RMI mechanisms is encapsulated in the
\emph{SW/HW\_Proxy\_Base} and \emph{SW/HW\_Agent\_Base} classes. This allows us to separate the
component-specific implementation that is part from the behavioral model from the implementation
related to artifacts of the underlying platform. Extending the previous examples, the code
snippet below shows part of the \emph{SW\_Proxy\_Base} class, which implements an RMI request using
the mechanisms provided by EPOS:
%
\progcppinline{code_proxy_imp}
%
Several template-based implementations of \emph{call\_r} are provided in order to support methods
with a different number of arguments and different argument types. Each one implements
the arguments serialization and requests a remote call using EPOS's \emph{Component\_Manager}. The
\emph{Component\_Manager} was added to EPOS as the main software infrastructure to handle the
communication between software and hardware components. It keeps lists of all existing proxies to
hardware and agents to software. Each component is associated to a unique ID that is mapped by a
static resource table to a physical address in the NoC. Upon a call request, this address is used
to build and send packets containing the target method ID and its arguments. If the method has
return values, the component manager blocks until it receives packets containing the return values.

On the hardware side, the messages are parsed by the hardware components. This parsing is
implemented by the \emph{HW\_Agent\_Base} class show below:
%
\progcppinline{code_agent_imp}
%
The main responsibility of the hardware agent is to define the entry-point of the final hardware IP
that is generated by the HLS tool. For the tool we have used (Calypto's
CatapultC~\cite{Calypto:Catapult}), the top-level interface of the resulting hardware block (port
directions and sizes) is inferred from a \emph{single function signature}. This function is the
\emph{top\_level} method and it receives an \emph{ac\_channel} object as argument.
\emph{ac\_channels} are abstractions provided by CatapultC that define blocking read/write methods
that can be easily coupled with the IO interface provided by RTSNoC. The behavior of the agent is
to block until a packet containing a method ID is received, followed by packets containing the
arguments. It parses the packets and performs the local method invocation though the
\emph{dispatch} method implemented by the component-specific implementation. Static polymorphism is
employed so that the component-specific dispatching defined at, for instance, \emph{HW\_Agent\_C2},
can be called from within \emph{HW\_Agent\_Base}. \emph{HW\_Agent\_*} classes derive from template
instantiations of \emph{HW\_Agent\_Base} using themselves as template. This allows the static
resolution of calls to virtual methods in the base class and, therefore, yields synthesizable code.

%ABOUT HW PROXIES AND SW AGENTS
%
%Proxies in hardware are very similar to proxies in software, except by the fact that there is not a
%global component manager. All the required mechanisms are implemented locally in each proxy. Since
%C3's proxy is in the same node of C2 and its agent, they both share the same \emph{ac\_channel}.
%
%Packets sent to the CPU node trigger interrupts that are handled by an ISR defined in the component
%manager. The ISR reads all pending packets and performs the necessary operations. When the
%manager receives a packet containing return values, it searches a list of blocked proxies and
%forwards the packet to the correct one (in Figure \ref{fig_sw_hw_sw_cmm} the \emph{call} method
%issued by \emph{C2\_SW\_Proxy} returns with the return value). When a packet contains data from a
%method call request (e.g. packets 2 and 3 in Figure \ref{fig_sw_hw_sw_cmm}), the information is
%forwarded to the dispatcher of the respective agent. The \emph{dispatch} method of a software agent
%is very similar to the hardware implementation, but it receives data through successive explicit
%calls. Once all the data is received, the local call is performed in the software component.

\subsection{Metaprogrammed framework}

Another issue is how to abstract the communication mechanisms and make them transparent during
component instantiation. For instance, considering the OOP example shown in Figure
\ref{fig_oop_to_phy}, the type \texttt{'C2'} in the \texttt{'C2 c2;'} declaration inside \emph{C1}
should be replaced by the following types according to the final hardware/software partitioning of
the system:
\begin{itemize}
    \item \texttt{HW\_Proxy\_C2}, if \emph{C1} is synthesized as a hardware IP and C2 is in
software;
    \item \texttt{SW\_Proxy\_C2}, if \emph{C1} is in software and \emph{C2} is a hardware IP;
    \item \texttt{C2}, if \emph{C1} and \emph{C2} are in the same domain. In this case, \emph{C2} is
``dissolved'' inside \emph{C1}, eliminating any communication overhead.
\end{itemize}

An efficient solution to realize these different mapping is to use \emph{static metaprogramming}
techniques~\cite{Czarnecki:2000}. Metaprograms are constructs implemented using \emph{C++ templates}
to perform operations at compile-time. An example of a metaprogram is shown below:
%
\progcppinline{code_meta_if}
This \emph{IF} metaprogram return one of two possible types depending on the value of a boolean
condition. It is implemented using C++ partial template specialization. If \emph{condition} is
\emph{true}, it defines \emph{Result} as the type \emph{Then}. This is encoded in the base
definition of the template. The template is partially specialized for the \emph{false} condition,
defining \emph{Result} as the type \emph{Else}.

The result of a metaprogram usually depends on static configurations defined in special template
classes called \emph{Traits}. The code sample below shows two possible \emph{Trait} classes for
components \emph{C1} and \emph{C2}:
%
\progcppinline{code_traits_example}
%
They define the \emph{imp\_domain} characteristic that is used to describe in which domain the
component is implemented (hardware or software).

Using the components' traits, the mapping mentioned previously for \emph{C2} can be described using
a metaprogram that replace the definition of a component by its proxy only when necessary: 
%
\progcppinline{code_c2_map}
%
In the final implementation domain, \emph{C2} can be redefined as an empty class that inherits from
its actual implementation depending on the configuration defined by \emph{C2}'s traits. In the
example above, the \emph{MAP} metaprogram selects between \emph{C2},
\emph{HW\_Proxy\_C2}, and \emph{SW\_Proxy\_C2}. \emph{MAP} uses the value of
\emph{Traits<Sys>::curr\_imp\_domain} to determine if the code is being submitted to a HLS
tool or to a software compiler. If \emph{Traits<Sys>::curr\_imp\_domain} is equal to
\emph{comp\_imp\_domain}, which receives the value of \emph{Traits<C2>::imp\_domain} in the example
above, then it must map to the actual implementation; therefore, \emph{Result} is equal to
\emph{C2}. Otherwise, it maps to one of the proxies according to the current implementation domain.

There exist other mechanisms to implement such mapping between implementations. Polymorphism and
other dynamic language features could be used; however, such constructs are not widely supported by
C++ synthesis tools. This mapping can also be implemented as part of an external tool,
nevertheless the authors of this paper believe that keeping tool's dependency to a minimum and
leveraging mostly on language features facilitates the migration between different C++/C-based HLS
solutions.

\subsection{Compilation/HLS}

In the software flow, components and its respective proxies and agents are compiled along with the
run-time support implemented in EPOS using the GCC C++ compiler. In the hardware flow, a HLS tool is
used to generate an RTL IP for each component. The \emph{traits} and the metaprograms that choose
between the instantiation of an actual component or its proxy and are also part of the C++ input
source code and are automatically parsed by the compiler and the synthesis tools. 

In this work we have used Calypto's CatapultC~\cite{Calypto:Catapult} as the HLS tool. Additionally
to the C++ source code, the inputs for the HLS process also include \emph{synthesis directives}.
Synthesis directives are used to aid the synthesis tool in associating C++ constructs to RTL
microarchitectures. For instance, \emph{loops} can have each iteration executed in a clock cycle, or
can be fully unrolled in order to increase throughput at the cost of additional silicon area. The
definition and fine tuning of these directives is part of the design space exploration process and
is not in the scope of this paper.

\subsection{Integration with the virtual and physical platforms}

In order to provide a rapid prototyping environment using the mechanisms proposed in this work, we
have developed a SystemC-based virtual platform that allows us to quickly evaluate components
deployed on the hardware/software architecture described in section \ref{sec:platform}. An overview
of the virtual platform is shown in Figure \ref{fig_virtual_platform_full}. The virtual platform
relies on the concept of TLM channels~\cite{Cai:2003} for communication (the \tlmch~symbol in Figure
\ref{fig_virtual_platform_full}). Channels are used to abstract communication details and allow
components to exchange data using method calls. 

%\figSC{\figsize}{fig_virtual_platform}{Virtual platform}
%\multfigtwoh{\figsize}
%{fig_virtual_platform_tlm_to_functional}{High-level C++ components}
%{fig_virtual_platform_tlm_to_rtl}{Cycle-accurate models}
%{fig_virtual_platform_tlm}{Integration of hardware components in the virtual platform}
\figSC{\figsize}{fig_virtual_platform_full}
{Virtual platform. Integration with high-level C++ components (a) and cycle-accurate models (b)}

In order to enable both fast functional validation and accurate performance evaluation, the
virtual platform support both untimed and timed TLM models. On untimed simulation, software
components are evaluated using a full MIPS32 \textit{instruction set simulator}~(ISS) that runs ELF
binaries generated during the compilation process. On the hardware side, a simple TLM wrapper was
developed to couple the C++ top\_level defined in the Proxy/Agent framework with the TLM
interface of the RTSNoC model.

On timed simulation, the untimed models are annotated with SystemC \emph{sc::wait} statements to
emulate the delays of the RTL models. For the hardware generated from C++ code, we have leveraged on
the cycle-accurate models generated by CatapulC. These models are integrated with the rest of the
platform through a wrapper that only drives the cycle-accurate signals between TLM transactions.
This eliminates any simulation overhead from idle components. By using the annotated models and
the models generated by CatapultC, the simulation time is significantly increased, however it is
possible to obtain accurate performance data without the need of costly RTL simulations.

Once the SystemC has been verified using the virtual platform, the RTL descriptions generated by
CatapultC are bound with the rest of the hardware platform library and fed to the RTL synthesis tool
which generates the final hardware for the target FPGA device. 

\section{Case study}
\label{sec:case_study}


In order to evaluate our approach, we have also implemented part a digital PABX/VoIP system
using the proposed mechanisms. This kind of system usually consists of a commutation matrix that
switches connections amongst different input/output data channels. These channels are connected to
phone lines (through an AD/DA converter), tone generators, and tone detectors. The system must also
support the transmission of phone call data through an Ethernet network. As a case study, we have
implemented a phone data processing pipeline that includes operations typical from this kind of
system. Figure \ref{fig_pabx_case} shows the evaluated components. 4-bit ADPCM phone line samples
encapsulated in encrypted packets are received from the network. An AES component first decrypts the
packets using a 128-bit AES algorithm. The resulting data is then decoded to 16-bit PCM samples and
send to a \textit{dual-tone multi-frequency}~(DTMF) detector. The DTMF detector uses the
\emph{goertzel algorithm} to check if a sample frame contains specific frequency components. Once a
tone is detected, the system controller is notified. For this particular pipeline, the Ethernet MAC
has a fixed hardware implementations while the controller is implemented only in software. For the
DTMF detector, the ADPCM codec and the AES decipher we have provided both hardware and software C++
implementations.  As shown in Figure \ref{fig_pabx_case}, the components are implemented using
composition as described in the previous sections. 

\figSC{\figsize}{fig_pabx_case}
{UML class diagram of the evaluated system. Component interactions are also indicated.}

%\figSC{\figsize}{fig_pabx_mappings}
%{Different HW/SW mappings of the case study}

\subsection{Results}
\label{sec:case_study:results}

\newcommand*\vplatuntimed{Virtual plat. -- Untimed}
\newcommand*\vplattimed{Virtual platform -- Timed}
\newcommand*\phyplat{Physical platform}

The goal of this experimental evaluation is to show how we can explore the different partitionings
for the implemented components. By only changing the system's \emph{traits}, the metaprogrammed
framework automatically replaces the component definition by a proxy or agent when necessary.
Table~\ref{tab_result_dse} shows this design space exploration. 

\tabTC{tab_result_dse}
{Design space exploration results. Software footprint is given in bytes. All simulation and execution times are in milliseconds.}

For each partitioning, columns \emph{\vplatuntimed} were obtained by simply changing the system
traits and recompiling the software and the untimed virtual platform with the high-level C++
components. As mentioned before, this does not give us any accurate performance or area figures, but
enable us to quickly verify the functional correctness of different partitionings. Since the
software is compiled to the target binaries at this stage, the total software footprint is already
known.
Columns \emph{\vplattimed} were obtained by compiling the timed virtual platform with the
cycle-accurate models generated after C++ hardware components are synthesized to RTL. At this stage
we already have an initial estimation of the application execution time.The \emph{Area rating}
column also gives an initial estimation of the circuit size. Its value has no direct relation to
physical units, but it is useful to compare different designs.
Columns \emph{\phyplat} shows the performance and area of the system running in the physical platform and
also the simulation time of the physical platform being simulated in a full RTL simulator. The
\emph{Avg. FPGA area}  is the arithmetic mean of the amount of each specific resource (e.g LUTs,
flip-flops, BRAMs, MAC slices) weighted by its total amount available. This resulting value
estimates the total amount of FPGA area (in \%) required and is used in this paper as a unified area
comparison metric.

In our experimental setup, the virtual platforms were compiled with \emph{gcc 4.3.3} and SystemC
library version 2.2. The RTL simulation was performed using \emph{ModelSim 6.5c}. All simulations
were executed in an i686 system (Intel Core2 Quad CPU Q9550 @ 2.83GHz) running Linux kernel 2.6.28
with maximum priority. Both the physical and simulated platforms were clocked at 100MHz. The
software running on the MIPS32 ISS was compiled with \emph{gcc 4.0.2} using \emph{level 2}
optimizations. For the hardware flow, \emph{Calypto's CatapultC UV 2011a} was used 
to obtain RTL descriptions of the components. The descriptions were then synthesized using
\emph{Xilinx's ISE 13.4} targeting a \emph{Virtex6 XC6VLX240T} FPGA. CatapultC and ISE were
configured to minimize circuit area considering a target operating frequency of 100 MHz.

As we can see in the results, the simulation time increases by 2-3 orders of magnitude when we
move to a lower level of abstraction. On the other hand, the average difference between the
execution times on the real and timed virtual platform is only $13\%$, confirming the feasibility of
our virtual platform for early and fast performance estimation. Applications with tight real-time
constraint may not harness simulations that lack timing accuracy, however. We are currently aiming
at improving this accuracy for future works. The difference between the execution times of the
virtual and real platforms comes mostly from the MIPS32 ISS which can still be significantly
improved in order to closely match the timing behavior of the Plasma softcore used in the RTL
implementation. Additionally, as future work, we aim at implementing a full functional model of
EPOS in order to replace the untimed ISS in the highest-level of simulation. This would allow a more
significant speed-up since both hardware and software could run as host-compiled models.

The results on Table \ref{tab_result_dse} also show that the execution time dominates DSE
decisions for our particular case study. The fastest partitioning is about $770X$ faster than the slower, while the most
efficient is terms of area is only $64X$ smaller than the least efficient. \emph{HW/HW/HW} would be
the best choice. The worst partitioning would be \emph{SW/HW/SW} which is also the slower. AES is
most demanding algorithm in the pipeline, and in this partitioning it runs in software.
Additionally, all communication is performed through cross-domain RMI, which imposes a significant
overhead. The \emph{HW/HW/HW} partitioning, on the other hand, uses RMI only for the
\emph{tone\_detected} method call. The rest of the pipeline is fully mapped to hardware in the same
NoC node, therefore, as described in the previous sections, all communication happens through
direct method calls.

%- untimed from 2 to 3 orders of magnitute faster than timed
%- timed simulation runs 2 to 3 orders of magnitute faster than RTL simulation
%- as expected, simulation is faster in the untimed TLM when more components are in HW, since they run as host code, while software is still compiled to target binary and run on ISS, threfors slower
%- diff of accurracy = 13\%
%     -accuracy increases when more components are moved to HW, since the models generated by catapult
%      match the timing behavior of the generated RTL, while our ISS is not so precise which influences SW more
%      - may be harmfull for hard-real time, but for our case, its is sufficient to take make design choices afte this simulation, since 
%        the difference in perforance between partitioning varies from XXX to XXX
%      
%- it is much faster to evaluate the different partitionings
%
%- only modifications on the traits are necessary
%- Best partitioning:
%   - Execution time dominates decision: fastest design is 770x faster than the slower, while the smallest is only 64x smaller than the largest.
%   - HW/HW/HW would be the best choice. The worst partitioning would be SW/HW/SW which is also the slower. AES is most demanding algorithm in 
%    the pipeline, and in this partitioning it is run in SW. Additionally, all commication is performed through cross-domain RMI, which imposes a significant overhead.
%    The HW/HW/HW par., on the other hand, uses RMI only for the the tone_detected method call. The rest of the pipeline is fully mapped to hw in the same
%    noc node, threfore all communication happens through direct method calls.


\section{Related work}
\label{sec:related_work}

Several previous works have proposed mechanism for providing a uniform interface between hardware
and software. The ReconOS~\cite{Lubbers:2008} and the BORPH operating
system~\cite{So:2008} use a similar approach. In these works a task performed in hardware is seen
with the same semantics as a software thread, and a
system call interface is provided to hardware components. However, these works still focus on RTL
as the base methodology of hardware designs. A similar approach aiming at system-level can be seen
in the scope of the FOSFOR project~\cite{Gantel:2011}, in which an infrastructure for
hardware/software task has been implemented to support a future design flow based on synchronous
data-flow models.

The work of \textit{Rincón et al}~\cite{Rincon:2007} and \textit{Paulin et al}~\cite{Paulin:2006}
are based on the same concepts we have used in our approach. The authors, however, focus on
RTL designs for hardware and do not provide support for designing all components at the same level
of abstraction.  High-level UML models of the system are only used in the former to automatically
generate the communication glue necessary so that hardware and software components can communicate. 

In the scope of HLS-based flows, the OSSS+R methodology uses timed SystemC descriptions for both
hardware and software and defines the concept of \emph{shared objects}~\cite{Gruttner:2010} for
high-level communication. SystemCoDesigner~\cite{Keinert:2009} is
a tool which integrates HLS with design space exploration and provides a fully automated design flow
from specification to the final platform. The design entry of SystemCoDesigner is an actor-based
data flow model implemented using an extension of SystemC. The System-on-Chip
Environment~(SCE)~\cite{Domer:2008} also defines a complete design flow. It takes SpecC models as
input and provides a refinement-based methodology.  Guided by the designer, the SCE automatically
generates a set of TLM platforms that are further refined to pin- and cycle-accurate system
implementations.

In the industry side, a considerable effort has been made by FPGA suppliers to integrate 
HLS solutions to their commercial design flows. Xilinx has recently incorporated C++/SystemC
synthesis to its Vivado tool flow~\cite{Xilinx:Vivado}, providing a complete path from
C++/SystemC to their standard bus-based platform. In this sense, it is worth mentioning that most of
the aforementioned works also rely on Xilinx's tools. For instance,
\cite{Lubbers:2008,So:2008,Rincon:2007,Gruttner:2010,Keinert:2009} provide some degree of
integration with Xilinx's tools and its platform-based design flow. In our work, however, we chose
to keep our proposed mechanisms as independent as possible from specific tools and methodologies. 


\section{Conclusion}
\label{sec:conclusion}

In this paper we have proposed a flexible NoC-based platform for SoC deployment in FPGAs and
demonstrated how hardware and software components can be integrated seamlessly in a HLS-based
implementation flow. This integration is done through RMI mechanisms that provide transparent
communication across hardware/software boundaries. The main contribution of this work in on
showing how such mechanisms can be implemented as a C++ metaprogrammed framework that
integrates seamlessly with hardware/software components implemented in C++ using an object-oriented
approach. Furthermore, throughout our experimental evaluation, we have shown that the integration of
these mechanisms with both untimed and timed virtual platforms enables fast design space
exploration and system prototyping. With our current virtual platform implementation, we have
achieved a speed-up of about $260X$, with a timing accuracy of about $13\%$ when compared to a RTL
simulation. As future work, we aim at improving the virtual platforms performance and accuracy, and
further explore the integration of our approach with different HLS tools and platform architectures.



\bibliographystyle{IEEEtran}
\bibliography{paper}

\end{document}
