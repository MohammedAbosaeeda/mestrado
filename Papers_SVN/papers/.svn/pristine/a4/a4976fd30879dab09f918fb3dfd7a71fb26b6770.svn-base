\documentclass[10pt,journal,letterpaper,compsoc]{IEEEtran}
\makeatletter
\def\markboth#1#2{\def\leftmark{\@IEEEcompsoconly{\sffamily}\MakeUppercase{\protect#1}}%
\def\rightmark{\@IEEEcompsoconly{\sffamily}\MakeUppercase{\protect#2}}}
\makeatother

%\documentclass[prodmode,acmtecs]{acmsmall}
%\pdfpagewidth=8.5in
%\pdfpageheight=11in

\usepackage[latin1]{inputenc}	% for Latin languages
\usepackage[T1]{fontenc}	% for ISO and UTF characters
\usepackage[english]{babel}	% for multilingual support
\usepackage{hyperref}
\hypersetup{
    colorlinks=false,
    pdfborder={0 0 0},
}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{stfloats}
\usepackage{booktabs}
%\usepackage[caption=false]{caption}
%\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{color}
\definecolor{Red}{rgb}{.9,0,0}
\definecolor{Green}{rgb}{0,.9,0}
\definecolor{Blue}{rgb}{0,0,.9}
\usepackage{soul}

\include{utils} %new commands 


\begin{document}

%\markboth{T. R. Mück and A. A. Fröhlich}{Unified Design of Hardware and Software Components}

\title{Unified Design of Hardware and Software Components}


%\author{Tiago~Rogério~Mück,~\IEEEmembership{Student~member,~IEEE,}
%        and~Antônio~Augusto~Fröhlich,~\IEEEmembership{Member,~IEEE,}%
\author{Tiago~Rogério~Mück~and~Antônio~Augusto~Fröhlich%
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem T. R. Mück and A. A. Fröhlich are with the
Software/Hardware Integration Lab , Federal University of Santa Catarina,
Florianópolis, Brazil.\protect\\
E-mail: \{tiago,guto\}@lisha.ufsc.br}% <-this % stops a space
\thanks{}}

%\author{Authors omitted for peer review}

\markboth{IEEE Transactions on Computers,~Vol.~x, No.~x, Month~year}%
{Shell \MakeLowercase{\textit{et al.}}: Unified Design of Hardware and Software Components}

\IEEEpubid{\makebox[\columnwidth]{\hfill 0000--0000/00/\$00.00~\copyright~2007 IEEE}%
\hspace{\columnsep}\makebox[\columnwidth]{Published by the IEEE Computer Society\hfill}}


\IEEEcompsoctitleabstractindextext{%
\begin{abstract}
The increasing complexity of current embedded systems is pushing their design to higher levels of
abstraction, leading to a convergence between hardware and software design methodologies. In this
paper we aim at narrowing the gap between hardware and software design by introducing a strategy
that
handles both domains in a unified fashion. We leverage on \emph{aspect-oriented programming} and
\emph{object-oriented programming} techniques in order to provide \emph{unified} C++ descriptions of
embedded system components. Such unified descriptions can be obtained through a careful design
process focused on isolating aspects that are specific of hardware and software scenarios. Aspects
that differ significantly in each domain, such as resource allocation and communication
interface, were isolated in \emph{aspect programs} that are applied to the unified descriptions
before they are compiled to software binaries or synthesized to dedicated hardware using
\emph{high-level synthesis} tools. Our results show that our strategy leads to reusable and flexible
components at the cost of an acceptable overhead when compared to software-only C/C++ and
hardware-only C++ implementations.
\end{abstract}
\begin{keywords}
System-level design, HW/SW co-design, High-level synthesis, Aspect-oriented system design.
\end{keywords}}

\maketitle


\section{Introduction}
\label{sec:introduction}
       
Embedded systems are becoming increasingly complex as the advances of the semiconductor industry
enable the use of sophisticated computational resources in a wider range of applications. Depending
on the application's requirements (e.g. performance, energy consumption, cost, etc.), the
development of such systems may encompass an integrated hardware and software design that can be
realized by several different architectures, ranging from simple 8-bit microcontrollers to
complex \textit{multiprocessor system-on-chips}~(MPSoCs).

In order to deal with this complexity, embedded system designs are being pushed to the
\emph{system-level}. In this scenario, a convergence between hardware and software design
methodologies is desirable, since a unified modeling approach would enable one to take decisions
about hardware/software partitioning later in the design process, maybe even automatically. In the
last few years, advances in \textit{electronic design automation}~(EDA) tools
are allowing hardware synthesis from high-level, software-like descriptions. This process is known
as \textit{high-level synthesis}~(HLS) and allows designers to describe hardware components using
languages like C++, and higher-level techniques, such as \textit{Object-Oriented Programming}~(OOP).
The focus of these
tools~\cite{Calypto:Catapult,Synopsys:Synphony,Cadence:CtoSilicon,Forte:Cynthesizer,Xilinx:AutoESL},
however, is hardware synthesis, and they do not provide a clear design methodology for developing
components which could be implemented as both hardware and software.

Aiming to narrow this gap and to move towards a real unified design approach, in this paper we
describe some design guidelines and mechanisms which support the implementation of both hardware and
software components from a single C++ description. Our guidelines are built upon the
\textit{Application-driven Embedded System Design}~(ADESD) methodology~\cite{Polpeta:2005}. ADESD
leverages on OOP and \textit{aspect-oriented programming}~(AOP) concepts, defining a domain
engineering strategy which allows us to clearly separate the core behavior and the structure of a
component from aspects that must be handled differently whether a component is implemented as
hardware or software. Such specific characteristics are modeled in special constructs called
\emph{aspects} and are applied to the unified descriptions of components only after the
hardware/software partitioning is defined, yielding the final implementation in the target domain
(hardware or software). In order to generate descriptions that can be efficiently synthesized by
HLS tools or compiled to a software binary, the implementation of both the components and the
mechanisms which adapt them make extensive use of C++ \emph{generative
programming}~\cite{Czarnecki:2000} techniques such as \emph{static metaprogramming}. To evaluate the
efficiency of our approach, we present the implementation of a \textit{Private Automatic Branch
Exchange}~(PABX) SoC of which some components were implemented using our unified design strategy.

It is important to recall that it is not a goal of this work to discuss the quality of hardware
implementation generated using HLS tools, neither the intrinsic differences between software and
hardware that cannot yet be fully handled by such tools. We take in consideration the fact that
these tools impose limitations to source descriptions (such as dynamic allocation and binding). As
it will be demonstrated in the following sections, limitations of this kind can be circumvented by
our unified approach.

The remaining of this paper is organized as follows: section \ref{sec:related_work} presents a
discussion about works related to the integration of the hardware and software design flows; section
\ref{sec:adesd} presents an overview of previous contributions upon which this work is built; in
section \ref{sec:proposal} we discuss the characteristics that are part of software and hardware
scenarios and present our approach for their proper separation and implementation; section
\ref{sec:case_study} describes our case studies and shows our experimental results; and section
\ref{sec:conclusion} closes the paper with our conclusions.

\section{Related work}
\label{sec:related_work}

Several design methodologies and tools were proposed in order to provide more tightly coupled
hardware and software design flows. Most of these methodologies are based on the concept of building
a system by assembling pre-validated components. The \textit{Ptolemy extension as a Codesign
Environment}~(PeaCE)~\cite{Ha:2008}, an extension of the Ptolemy project~\cite{Eker:2003}, is a
synthesis framework for real-time multimedia applications. PeaCE takes models composed by
synchronous data-flow graphs and extended \textit{finite state machines}~(FSMs) and either generates
C code or maps the models to
pre-existing IP cores and processors. ROSES~\cite{Dziri:2004} is a design flow which automatically
generates hardware, software, and interfaces from an architectural model of the system and a library
of pre-validated components. The \emph{Metropolis}~\cite{Balarin:2003} and its successor
\emph{Metro-II}~\cite{Davare:2007} follow the \emph{Platform-based
design}~(PDB)~\cite{Vincentelli:2001} methodology. They propose the use of a metamodel with formal
semantics to capture designs. An environment to support simulation, formal analysis, and synthesis
is also provided. Despite providing integration frameworks for the entire design flow, these
methodologies do not define clear guidelines to design new reusable components. Also, mapping the
application model to pre-existing components limits hardware/software partitioning.
%Also in PDB the hardware/software partitioning must be defined in the early design stages and is
%limited by the platform specification. 

In order to overcome these limitations, one must focus on closing the \emph{design gap} of software and
hardware components. State-of-the-art EDA tools (e.g. Calypto's CatapultC~\cite{Calypto:Catapult},
Synopsys' Synphony~\cite{Synopsys:Synphony}, Cadence's C-to-Silicon~\cite{Cadence:CtoSilicon},
Forte's Cynthesizer~\cite{Forte:Cynthesizer}, Xilinx's AutoESL~\cite{Xilinx:AutoESL}) support
hardware synthesis from high-level C++/C-based constructs. Indeed, several works have already
demonstrated the  applicability of HLS for implementing hardware
components such as signal processing filters, cryptographic cores, and other computationally
intensive components~\cite{Cong:2011}. Our aims are different however. We want to describe
components in a high level of abstraction, but those should be implementable in hardware as well as
in software, and with performance close to software-only and hardware-only implementations. 

%maybe include figures of the other flows
On this track, the OSSS+R methodology~\cite{Schallenberg:2009} raises
the level of \textit{register transfer level}~(RTL) SystemC by adding new language constructs to
support synthesizable polymorphism and high-level communication. However, hardware/software
partitioning must still be done in the beginning of the design process~\cite{Gruttner:2008}, and the
inclusion of non-standard language constructs reduces the compatibility of the design with available
compilers and hardware synthesis tools. The \emph{Saturn}~\cite{Mischkalla:2010} design
flow also contributes in this scenario, but follows a different approach. It aims to close the gap
between UML-based modeling and the execution of the models for their verification. The authors have
elaborated over \emph{SysML}, an extension of UML for system-level design~\cite{OMG:SysML}, and
developed a tool which generates C++ for software and RTL SystemC for hardware. Although using a
single language, software and hardware are still modeled separately. Additionally, it is not clear
whether their tool generates code only for the interface and integration of components, or the
behavior is also inferred from the SysML models.

SystemCoDesigner~\cite{Keinert:2009} is a tool which integrates a HLS flow with design space
exploration. The design entry of SystemCoDesigner is an actor-based data flow model implemented
using
SystemMoC~\cite{Falk:2006}. After design space exploration, actors of this model can be 
converted to synthesizable SystemC or to C++ for software compilation. However, as the authors
themselves claim, SystemCoDesigner targets mostly data-flow-based applications, and they do not
provide directions towards a more general deployment. The System-on-chip
environment~(SCE)~\cite{Rainer:2008} takes SpecC models as input and provides a refinement-based
tool flow.  Guided by the designer, the SCE automatically generates a set of
\textit{Transaction-level models}~(TLM)~\cite{Cai:2003} that are further refined to pin- and
cycle-accurate system implementation.

Other works focus mainly on the interface between software and hardware. The \emph{HThread}
project~\cite{Anderson:2007}, the ReconOS~\cite{Lubbers:2008} and the BORPH operating
system~\cite{So:2008} provide a unified interface for both domains. In these works a task performed
in hardware is seen with the same semantics as a software thread, and a system call interface is
provided to hardware components. However, despite providing this unified interface, they do not
cover the gap that still exists between the way the hardware and software threads themselves are
implemented. The work of \textit{Rincón et al}~\cite{Rincon:2009} is based on concepts from
distributed object platforms such as CORBA and Java RMI and provides a tool which generates the
communication glue necessary so that hardware and software components can communicate seamlessly.
     
\section{Application-driven Embedded System Design}
\label{sec:adesd}

\textcolor{Red}{\textbf{Review 2:} Without reading the previous work of the authors it is very hard
to get a deeper understanding of the technical concept and soundness of the approach. Section 3
should better aim on giving an introduction to the general concepts of aspects and aspect weaving.
Currently section 3 points to previous work and gives only little high-level/abstract information.
\\
\\
\textbf{Review 3:} On the general approachability of the text. The authors seem to assume that
readers understand many concepts like ``aspect-oriented programming'', and do not really explain
these concepts in the paper. For someone who does not have prior knowledge of C++ template and UML
(Many embedded designers use languages like C instead of C++), these will only create confusion. 
More explanations on the concepts of OOP/UML and C++ template will be helpful. If space is a
problem, the author should at least say something like ``we assume that the readers are comfortable
with C++ templates and UML diagrams in the reset of this paper. For information on these, please see
[xx] and [yy] for more explanation.''
}


The ADESD~\cite{Polpeta:2005} methodology elaborates on commonality and variability
analysis---the well-known domain decomposition strategy behind OOP---to add the concept of
\emph{aspect} identification and separation at early stages of design. It defines a domain
engineering strategy focused on the production of families of scenario-independent components.
Scenario dependencies observed during domain engineering are captured as \emph{aspects}, thus
enabling components to be reused on a variety of execution scenarios through the application of
\emph{aspect programs}. The design artifacts proposed by ADESD facilitates the separation of
concerns within embedded system components making hybrid implementations possible. This was
initially explored by the idea of \emph{Hybrid Components}~\cite{Marcondes:2009}, in which a common
architecture for the implementation and communication between components living in hardware and/or
software was developed. This architecture defines interfaces that, when implemented, allow
components to communicate independently of whether they are deployed in software or in hardware. 

In this work we aim to show how ADESD's aspect separation mechanisms can be used to yield
components susceptible to both hardware and software synthesis. ADESD proposes the use  of
constructs called \emph{Scenario adapters}~\cite{Mueck:OSR:2012} to perform aspect
weaving. Scenario adapters were developed around the idea of components getting in and out of an
execution scenario, allowing actions to be executed at these points. Figure
\ref{fig_scenario_adapter} shows how this is achieved. The \emph{Scenario} class represents the
execution scenario and incorporates, via aggregation, all aspect programs that are needed to
characterize it. The adaptation of the component to the scenario is performed by the
\emph{Scenario\_Adapter} class via inheritance implemented using static metaprogramming. 

\figSC{.33}{fig_scenario_adapter}{Component adaptation using a scenario adapter.}

In the next sections we demonstrate how characteristics specific of a \emph{hardware scenario} or a
\emph{software scenario} can be isolated from the core behavior and the interface of a component. By
following this approach, the same component description can be tailored by the scenario adapter in
order to feed either a software compilation flow or a hardware high-level synthesis flow.

         
\section{Unified hardware/software design}
\label{sec:proposal}

\textcolor{Red}{\textbf{Review 1:} Instead of giving general guidelines, the authors only present
sample code snippets, which provide solutions for their running example. Often, the code snippets
are even not discussed at all, which makes it difficult to even comprehend this particular solution.
Especially, I do have problems understanding the Traits example on page six in the right column. The
applicability of the solution and its limitations remain unclear.
\\
\\
\textbf{Review 3:}While the proposed method could work well for the purpose of describing hardware
and software in a unified way, comparison with other methods for the same purpose is missing. For
example, it is possible to use C (with extensions/pragmas) to describe both hardware and software (I
know people in the industry doing so), and I believe what static metaprogramming offers can also be
achieved using C language constructs, like macros and \#ifdef blocks. Discussion on the advantage of
the proposed approach should be elaborated, with comparison to possible alternatives (not
necessarily experiemtal comparison). For example, one of the advantages I can see is that the
proposed approach is more systematic and thus can potentially offer better checking at the syntax
level; i.e., a domain-specific compiler may easily inform the designer about missing constructs.
Yet, a disadvantage could be that a coding style using static-metaprogramming can be difficult to
debug. Comparisons like this could help the reader better understand the proposed method and
appreciate its unique advantages.
}\\

%To save space, this paragraph can be removed or merged with the next one
HLS tools allow for hardware synthesis from algorithms described in languages such as C++. When
aiming at this goal, the implementation of the algorithm itself is usually very similar to what is
seen in software. However, at component level, several characteristics arise which distinguish
descriptions aiming at hardware and software. In the following sections we first discuss these
differences. Then, we present our strategy for the separation of hardware and software concerns and
how we achieved efficient and flexible unified C++ descriptions.

%This subsection can be merged with the top-level one if the above paragraph is removed
\subsection{Differences between hardware and software}
\label{sec:proposal:hw_sw_differences}

Table \ref{tab_comm_interface} summarizes the most common components communication patterns. 
In the software domain, components may be objects which communicate using method invocation
(considering an OOP-based approach), while in the hardware domain, components communicate using
input/output signals and specific handshaking protocols. For communication through different
domains, the software must provide appropriate \textit{hardware abstraction layers}~(HAL) and
\textit{interrupt service routines}~(ISR), while the hardware must be aware that it is requesting a
software operation.

\tabSC[ht]{tab_comm_interface}
{Usual component communication patterns. The \emph{Caller} requests operations from the
\emph{Callee}.}

In some system-level approaches, such as TLM, components communicate by reading and writing data
from/to \emph{channels}. Latter in the design 
process, these channels can be mapped to buses, point-to-point signals, or function calls, whether
the communicating components are in hardware or in software. This strategy provides a clear
separation between communication and behavior, but it is still too hardware-oriented since it
basically provides higher-level versions of RTL signals. Figure \ref{fig_tlm_vs_oop} highlights this
fact by comparing a TLM and a more software-oriented OO model of the same system. The OOP model is
more expressive and clear in the way components interactions are defined. A component can be either
implemented as a global object (\emph{C1} and \emph{C3}) or as a part of another object
(\emph{C2}).\\
\textcolor{Red}{\textbf{Review 2:} the comparison of TLM-based communication and communication in
object-oriented modes seems to be a little strange. Without giving further details on the
methodology behind the presented approach (incl. different models for the application, execution
platform and the mapping of application elements to component of the execution platform) this
comparison is dangerous. Communication in object-oriented application models describe application
specific communication, while TLM models describe how communication is realized in the execution
platform through physical channels.
I.e. object-oriented communication at application layer can be mapped to platform communication
resources that implement this communication.
}\\

\figSC{.6}{fig_tlm_vs_oop}{Communication between components in transaction level (left) and
object-oriented (right) models.}

However, the structure of TLM-like models leads to a more natural mapping to final physical
implementations. In OOP the original structure will be ``disassembled'' if different objects in the
same class hierarchy represent components that are to be implemented in different domains. For
example, \emph{C2} is ``inside'' \emph{C1} in the OO model in Figure \ref{fig_tlm_vs_oop}, but, in
the final implementation, \emph{C1} could be implemented as a hardware component while \emph{C2}
could run as software in a processor. Since we focus on an OOP-based methodology, in this paper we
show how these different mappings can be made transparent to the designer. This is explained in
section \ref{sec:proposal:unified_design:stubs}.

Another important characteristic that distinguishes hardware from software is resource allocation.
The hardware is frozen and common software features, such as dynamic resource allocation, are not
easily available. Therefore, in code suitable for hardware synthesis, all data structures must
reside in statically allocated memory. Some works focus on this problem by relying on dynamic
reconfiguration technologies of FPGAs to support hardware components instantiation at
run-time\cite{Abel:2010}. However, this is not the focus of our current work. We aim at providing
more general guidelines for describing components.

\subsection{Defining C++ unified descriptions}
\label{sec:proposal:unified_design}

\textcolor{Red}{\textbf{Review 2:} This section appears to focus only on some specific issues like
the use of pointers, static polymorphism, allocation, and dispatching. These issues are indeed
important but the overall description of the unified description is missing. The presented
techniques from template meta programming are interesting, but the description is not sufficient for
understanding how these techniques are applied in a systematic way in an overall unified
description.}\\

A unified description of components can be obtained from implementations that are largely
independent from hardware and software scenario details. This can be achieved through careful domain
engineering and system design. An initial work~\cite{Pizani:2011} has already shown how
the ADESD methodology was used to provide a C++ description of a resource scheduler suitable for
high-level synthesis. In the next sections we show how one can further leverage on ADESD's artifacts
to provide C++ unified descriptions and efficient hardware/software aspects separation.

\subsubsection{Component implementation}
\label{sec:proposal:unified_design:unified_descriptions}
C++ code unified and suitable for automatic implementation in both hardware and software must
follow a careful design process so it will not contain characteristics specific of hardware or
software. To illustrate how ADESD yields such components, we describe in more details one of our
case studies: the design and unified implementation of the EPOS's thread scheduler. The
\textit{Embedded Parallel Operating System}~(EPOS)~\cite{EPOS:2011} is a case study on which the
design artifacts proposed by ADESD were implemented and validated. The OS is implemented in C++ and
leverages on \emph{generative programming}\cite{Czarnecki:2000} techniques such as \emph{static
metaprogramming} in order to achieve high reusability with low overhead. EPOS's domain engineering
simplified our work by providing a good \emph{separation of concerns} around the scheduler. Figure
\ref{fig_epos_scheduler} shows a simplified class diagram of the scheduling-related classes in EPOS.

\figSC{.6}{fig_epos_scheduler}{Simplified class diagram of scheduling-related classes in EPOS.}

The \emph{Scheduler} class is responsible only for keeping ordered queues, with the ordering defined
by the scheduling criterion. An object of the \emph{Scheduler} class also allows its callers to
insert and remove resources from the queues, as well as to get the current and next owners of the
resource. In our case study, we implemented a scheduler for threads. However, the scheduler code is
largely independent of the type of resource being scheduled (in fact, \emph{Scheduler} is a
\emph{parametric class}). Furthermore, concerns such as timing interrupt generation and context
switching are handled separately by the OS. 

Among all classes in Figure \ref{fig_epos_scheduler}, we've adapted the original implementation of
the \emph{Scheduler} class (and also its base classes), so that it can now serve as input for both
hardware and software implementation flows. These adaptations were necessary not due to specific
hardware or software characteristics, but due to some limitations of HLS tools. The main limitation
is related to \emph{pointers}. Pointers have no intrinsic meaning in hardware. They are mapped by
HLS tools to indices of the storage structures to which they point. Thus, \emph{no null or otherwise
invalid pointers} are allowed in the source code. However, the original scheduler implementation
used null pointers to report failures. To avoid this, we've changed the code to utilize \emph{option
types}. An option type is a container for a generic value, and has an internal state which
represents the presence or absence of this value. We implemented an option type in the C++ class
template \emph{SafePointer\textless T\textgreater}, which has the following constructors:

\scriptsize\begin{verbatim}
template<typename T> class SafePointer {
...
  SafePointer(): _exists(false), _thing(T()){}
  SafePointer(T obj): _exists(true), _thing(obj){}
...
};
\end{verbatim}\normalsize

One constructor represents the absence of a value in the container while the other represents its
presence. By replacing all occurrences of simple pointers (T*) in the scheduler code with
\emph{SafePointer\textless T*\textgreater} values, we completely avoided passing invalid pointers
around.

HLS tools also limit the use of C++ features that rely on dynamic structures in software (e.g.
heaps, stacks, virtual method tables), such as \emph{new} and \emph{delete} operators, recursion,
and dynamic polymorphism. In section \ref{sec:proposal:unified_design:aspects} we show how resource
allocation can be implemented as a separated \emph{aspect}, however recursion and polymorphism can
be implemented using static metaprogramming techniques, yielding code supported by HLS tools. Static
polymorphism can be implemented as shown below:

\scriptsize\begin{verbatim}
template <typename derived_class> class Base {
  void operation() {
    static_cast<derived_class*>(this)->operation();
  }
};
class Derived : public Base<Derived> {
  void operation();
};
\end{verbatim}\normalsize

Classes can derive from template instantiations of the base class using themselves as template.
This is also known as \textit{Curiously Recurring Template Pattern}~(CRTP)~\cite{Coplien:1995}, and
allows the static resolution of calls to virtual methods of the base class.

Other aspects concerning hardware generation using HLS are related to the synthesis process. The
same high-level algorithm can span several different hardware implementations. For instance, loops
can have each iteration executed in a clock cycle, or can be fully unrolled in order to increase
throughput at the cost of additional silicon area. This kind of synthesis decision is usually taken
based on directives which are provided separately from the algorithm descriptions. The definition
and fine tuning of these directives is part of the design space exploration process and is not in
the scope of this work.


\subsubsection{HW/SW aspects encapsulation}
\label{sec:proposal:unified_design:aspects}

\textcolor{Red}{\textbf{Review 3: }There are more differences in hardware design and software design
that may need attention. For example, for high-level synthesis, bit-accurate data types are very
useful. By using only enough bit widths for operators, storage elements and interconnects,
significant saving in resource/power can be achieved. On the other hand, software compilers usually
only use 8/16/32/64 bit for integers. The tool used in your experiments, Catapult-C, supports the
ac\_int/ac\_fixed datatypes in C++. I wonder if bit-accurate datatypes are used in your experimental
evaluation? How do you unify the hardware/software description if bit-accurate datatypes are needed?
There can be subtle issues when overflow occurs.
\\
\\
The approach, as a coding style, can be applied to a more general class of
"module selection" problem. The scenarios considered do not have to be limited to either "software"
or "hardware". In high-level synthesis, the design space can be explored by using different pragmas
(like loop unrolling/pipeling), and each implementation could be a scenario. Some of the techniques
described in this paper can actually encode multiple sets of implementation options in a unified
description.
\\
\\
\textbf{Review 1: }No alternative solutions are discussed. This would have been
interesting especially for the static allocation and dispatching
aspects.\textcolor{Blue}{(specific comments added below)}}\\

Throughout the domain decompositions of our case studies we have identified two aspects that must be
handled differently whether the component is in hardware or in software: \emph{storage allocation}
and \emph{method call interface}. Figure \ref{fig_hw_sw_scenarios} shows how we have used scenario
adapters to isolate such aspects. 

\figSC{.6}{fig_hw_sw_scenarios}{Software and hardware scenarios' aspects}

The \emph{HW Scenario} is composed by the aspects \emph{Static Alloc} and \emph{Dispatch}, whom are
responsible, respectively, for storage allocation and method call dispatch. The former is a storage
allocator used to deal with the absence of dynamic memory allocation in hardware. Handling memory
allocation externally is only possible because our components implement solely their
\emph{core behavior}. For example, the \emph{List} class (Figure \ref{fig_epos_scheduler}) is a
linked list, but it is not responsible for the allocation of space for links and the objects it
stores. It implements only the list algorithms and deals with references to such elements.
Therefore, all components operations go through the allocator which reserves and releases storage
space on demand. The example below shows how the \emph{insert} and \emph{remove} methods of the
list are implemented using this approach:

\scriptsize\begin{verbatim}
Link insert(Object obj) {
    Link link = Scenario::allocate(obj);
    Base::insert(link);
    return link;
}
Object remove(Link link) {
    Object obj = Scenario::get(link);    
    Base::remove(link);
    Scenario::free(link);
    return obj;
}
\end{verbatim}\normalsize

In hardware implementations, \emph{Scenario::allocate(obj)}, \emph{Scenario::get(link)},
and \emph{Scenario::free(link)} map to operations implemented in the \emph{Static Alloc} aspect. In
this scenario, the number of storage slots for links and objects is defined at synthesis-time and
allocation requests are just mapped to a free slot. In a software implementation, dynamic memory
allocation is available, thus, storage allocation can be handled by either the \emph{Static
Alloc} or the \emph{Dynamic Alloc} aspect, as shown in figure \ref{fig_hw_sw_scenarios}.\\
\textcolor{Red}{\textbf{Review 1: }why do the authors define their own allocation class while the
standard template library is already providing a ready to use implementation? In summary, by only
providing some examples, it is not clear what exact solution is proposed.}\\

\hl{The \emph{Dispatch} aspect is used, in \emph{HW Scenario}, to define an
entry point for the
component so it will be compliant with HLS tools requirements. For the tool used in our case
studies} (Calypto's CatapultC~\cite{Calypto:Catapult}), \hl{the top-level interface of the resulting
hardware block (port directions and sizes) is inferred from a \emph{single function signature}.}
This function is defined by \emph{Dispatch} and receives a \emph{method id} as its first parameter,
interprets its value, performs the necessary type conversions and calls the appropriate method of
the component. The value returned by the called method is also inspected, converted if necessary and
assigned to one of the dispatcher output parameters. A dispatch mechanism is not necessary in
the software scenario since operations are requested using direct method calls.\\
\textcolor{Red}{\textbf{Review 1: }the proposed dispatching strategy is very specific for the
CatapultC high-level synthesis. Nearly all other HLS tools do not use a single function signature
for describing hardware components. They typically require to present hardware components as SystemC
modules having signal ports or transaction sockets. In this case, the proposed solution could not be
applied directly. }\\

Finally, it is worth mentioning that aspects, scenario, and adapters are implemented using
static metaprogramming and are highly generic. The scenario to which the component is adapted is,
in fact, defined using metaprogramming, as shown in figure \ref{fig_hw_sw_scenarios}.  Special
template classes called \emph{Traits} are used to define which characteristics of each component is
activated. The code sample below shows an example of a \emph{Trait} class:

\scriptsize\begin{verbatim}
template <> struct Traits<Component> {
    static const bool hardware = true;
};
\end{verbatim}\normalsize

It defines that the component \emph{Component} has a \emph{hardware} characteristic that is used to
define which domain the component will be on (hardware or software). In figure
\ref{fig_hw_sw_scenarios}, this characteristic is used to conditionally modify the scenario
adapter's base scenario. This decision is statically determined using a metaprogram. The
implementation of \emph{IF} metaprogram is shown below:

\scriptsize\begin{verbatim}
template<bool condition, typename Then, typename Else>
struct IF { typedef Then Result; };

template<typename Then, typename Else>
struct IF<false, Then, Else> { typedef Else Result; };
\end{verbatim}\normalsize

\subsubsection{Wrapping communication}
\label{sec:proposal:unified_design:stubs}
\textcolor{Red}{\textbf{Review 2:} tSection 4.2.3 presents the idea of a Remote Method invocation
with marshaling and unmarshaling services. It remains unclear how these techniques are supported by
the presented methodology. Nothing about interrupt handling for software calls is mentioned. A Trait
is a very generic template meta programming technique. It remains unclear how this technique solves
the problem of HW/SW communication.
}\\

Issues related to communication cannot be completely handled using only the mechanisms described so
far. For example, in the OO model in Figure \ref{fig_tlm_vs_oop}, the \emph{C2} is an attribute of
\emph{C1}, thus \emph{C2} will be compiled/synthesized together with \emph{C1}. However, if the
designer intends to have \emph{C1} and \emph{C2} as two independent components implemented in the
different domains, then an additional mechanism is necessary. 

A way to overcome this issue is to use to use concepts from distributed object
platforms~\cite{Rincon:2009}. Figure \ref{fig_remote_invocation} illustrates possible interactions
between components \emph{C1} and \emph{C2}. The callee is represented in the domain of the
caller by a \emph{proxy}. When an operation is invoked on the components' proxy, the arguments
supplied are marshaled in a request message and sent through a \emph{communication channel} to the
actual component. In the \emph{HW->SW} interaction, an \emph{agent} receives requests, unpacks
the arguments and performs local method invocations. The whole process is then repeated in the
opposite direction, producing reply messages that carry eventual return arguments back to the
caller. An \emph{agent} is not required by the \emph{SW->HW} interaction since the \emph{dispatcher
aspect} can already play its role.

\figSC{0.6}{fig_remote_invocation}
{Communication between components in different domains. The leftmost components request
operations from the rightmost ones (the scenario adapters are omitted for simplicity).}

Another issue is how to make these mechanisms transparent in the components' descriptions. An
efficient solution is to use template metaprograms to replace the definition of a component by its
proxy when necessary. For example, in the software domain, \emph{C2} can be defined as an empty
class that inherits from its actual implementation depending on the configuration defined by the
component's \emph{Traits}:

\scriptsize\begin{verbatim}
class C2 : 
  public IF<Traits<C2>::hardware, 
            SW_Proxy<C2>, Scenario_Adapter<C2> >::Result {};
\end{verbatim}\normalsize

There are still more implementation issues that are still to be considered. The mechanisms
proposed above are only general guidelines that can span several specific implementations. The
implementation of \emph{channels}, \emph{proxies} and \emph{agents} can be realized in several
different ways (e.g. specific using buses, DMA, \emph{Network-on-Chips}~(NoCs) ). In section
\ref{sec:case_study} we describe our case studies and the chosen architecture to implement the
mechanisms above.

\subsection{Implementation flow summary}
\label{sec:proposal:summary}

\figTC[ht]{.6}{fig_adesd_flow_v2}{Summary of the implementation flow}

Figure \ref{fig_adesd_flow_v2} summarizes our implementation flow. The first steps show the
artifacts of our proposed approach. Aspects, scenarios, and the unified implementation of
components made up the inputs for the design flows. Proxies and agents can be automatically
generated from the components' interface by a tool (EPOS's syntactical analyzer~\cite{Schulter:2007}
can be used to obtain the operation signatures of all components). The final steps comprises the
final system generation. Once the hardware/software partitioning is defined (by the components'
Traits), the adapted components are fed to either the hardware or the software generation flows. 

In the software flow, components are compiled along with the RTOS. In our case study we use EPOS.
Apart of basic RTOS features, EPOS is also responsible for the implementation of the run-time
support required by the mechanisms mentioned in section \ref{sec:proposal:unified_design:stubs}. For
example, a software component that is in the scope of a hardware component is instantiated by this
run-time support. When the hardware component requests operations through the proxy, the software is
interrupted and the run-time support handles the communication between the stub and the component in
software.

In the hardware flow, an HLS tool is used to generate RTL descriptions. These descriptions are
bound with the hardware platform library and fed to the RTL synthesis tool. The platform library
contains the components required to run the software (softcore processor, memories, and peripherals)
and the communication infrastructure that allows application's components to communicate with each
other. Details of the features available in both EPOS and the platform library are given in the
description of our case study in the next section.

%TODO move this to the conclusion or introduction
It is worth pointing out that this work focuses only on general implementation guidelines and not a
whole design methodology. Issues such as design space exploration and design verification are not
in the scope of this work.

\section{Case study}
\label{sec:case_study}
\textcolor{Red}{\textbf{Review 2: }The main focus of the case-study is on the comparison of
component implementations using C++ with the presented unified C++ approach. The evaluation is quite
extensive and could be reduced.}\\

In order to evaluate our approach, we have analyzed a PABX application and designed some of its
basic building blocks using the proposed implementation guidelines. A high-level diagram of the PABX
system is shown in Figure \ref{fig_pabx_system}. The main component is a commutation matrix that
switches connections amongst different input/output data channels. These channels are connected to
phone lines (through an AD/DA converter), tone generators, and tone detectors. The system also
supports the transmission of voice data through an Ethernet network.

\figSC{.6}{fig_pabx_system}{PABX system diagram}

The components we have selected to be reimplemented using unified C++ are described in more detail
below:

\textbf{EPOS's scheduler:} the use of the scheduler described in section
\ref{sec:proposal:unified_design:unified_descriptions} as a case study is motivated by its complex
behavior. A scheduler may perform operations both synchronously (upon request by another component)
or asynchronously (by preempting the execution of another component). Furthermore, a
hardware-implemented scheduler has less jitter and provides better support for real-time
applications~\cite{Marcondes:2009:2}. Figure \ref{fig_epos_scheduler_extended} extends figure
\ref{fig_epos_scheduler} with the main operations implemented by the scheduler. For our thread
scheduler, the component is instantiated using class \emph{Thread} as the template parameter.

\figSC{.6}{fig_epos_scheduler_extended}{Scheduler component definition}

\textbf{ADPCM codec:} an IMA ADPCM encoder/decoder~\cite{IMA:ADPCM} that is used to reduce
the traffic of data transmitted through the network. It performs data compression using an
\emph{adaptative differential pulse-code modulation}~(ADPCM) algorithm to convert 16-bit samples to
4-bit samples. Figure \ref{fig_adpcm_codec} shows the structure of the codec. The encoding and
decoding algorithms are independent and implemented in different classes. Both algorithms, however,
share the same lookup tables which are defined in a common class. The \emph{ADPCM\_Codec} class only
encloses both implementations as a single codec component.

\figSC{.6}{fig_adpcm_codec}{ADPCM codec component definition}

\textbf{DTMF detector:} the \textit{Dual-Tone Multi-Frequency}~(DTMF) detector is one of the
basic building blocks of any PABX system. The DTMF detector receives signals sampled from the phone
lines connected to the central and detects DTMF tones. Figure \ref{fig_dtmf_detector} shows its
definition. The entry point of the original C implementation was a single function that received
a pointer to a frame of samples and returned the detected tone. The redesigned unified
implementation defines two public operations: \emph{add\_sample} updates a sample of the current
frame; and \emph{do\_dtmf} implements the pseudocode in figure \ref{fig_dtmf_detector} to perform
the detection. For each tone, it uses the \emph{goertzel algorithm} to check if the sample frame
contains the frequency components of a tone, then uses lookup tables to analyze the results and
return the ASCII character representing the tone.

\figSC{.6}{fig_dtmf_detector}{DTMF detector component definition}


Figure \ref{fig_pabx_soc_v2} shows the final block diagram of the PABX SoC. It is a NoC-based SoC
and uses the \emph{RTSNoC}\cite{Berejuck:2011} as the core communication infrastructure. Each
hardware component is implemented as a single node connected to the NoC. Software components run in
a \emph{processing node} that consists of a MIPS32 core and memories. The SoC also contains an
\emph{IO peripheral node}. The components selected as case studies are highlighted and appear in as
hardware and software, since they can move between both domains depending on the final
hardware/software partitioning.

\figSC{.5}{fig_pabx_soc_v2}{PABX SoC block diagram}

The upper part of figure \ref{fig_pabx_soc_v2} shows the structure of the software domain. EPOS's
\emph{Component Manager} implements the runtime support mentioned in section
\ref{sec:proposal:summary}. Operations request from software to hardware are marshaled and sent
through the \emph{NoC proxy}. Requests in the opposite direction are captured by the \emph{Component
Manager} which forwards the operation to the target component in software (it implements the
software agents described in section \ref{sec:proposal:unified_design:stubs}).

\subsection{Results}
\label{sec:case_study:results}

In order to demonstrate that unified implementations can be compared to dedicated ones in terms of
efficiency, we compare software scenario-adapted components against the original C
implementations (C++ for the scheduler), and hardware scenario-adapted components against
components manually tailored for high-level synthesis.

Table \ref{tab_result_sw_exec_time} and Figures \ref{fig_chart_sw_mem}--\ref{fig_chart_sw_avg_time}
compare the original software-only C (ADPCM and DTMF) and C++ (Scheduler) with the software
scenario-adapted C++. The footprints were obtained from the object files generated after compiling
each component in isolation, while the execution times were measured from the running application
using a timestamp counter. Everything was compiled with \emph{gcc 4.0.2} targeting the MIPS32 ISA
and using \emph{level 2} optimizations. Figure \ref{fig_chart_sw_mem} shows an average increase of
about 4.9\% in the total memory footprint. In the case of the scheduler, the overhead can be
explained by the introduction of the \emph{option types} and the use of a more generic mechanism for
storage allocation (the \emph{Static/Dyn Alloc} aspect). For the remaining case studies, most of the
overhead comes from additional code required to encapsulate the behavior into more reusable OOP
classes with a clear method interface.

%Unified/HW-only
%Scheduler 1.056
%ADPCM 1.074
%DTMF 1.017
\figSC{.75}{fig_chart_sw_mem}{Memory footprint of software-only C++ \emph{vs.} Unified C++ adapted
to the software domain. The leftmost bars show results for software-only components.}

%Unified/HW-only
%Scheduler 1.02
%ADPCM 1.03
%DTMF 1.05
%\tabSCxXxXfig[ht]
%{tab_result_sw_exec_time}
%{fig_chart_sw_avg_time}{.75}
%{Execution time of software-only C++ \emph{vs} Unified C++ adapted to the software domain. The
%normalized average execution times are plotted with absolute values above their respective bars.}
\tabSC[ht]{tab_result_sw_exec_time}
{Execution time of software-only C++ \emph{vs.} Unified C++ adapted to the software domain.}
\figSC{.70}{fig_chart_sw_avg_time}{Normalized average execution times. Absolute values are shown
above their respective bars.}

Table \ref{tab_result_sw_exec_time} and Figure \ref{fig_chart_sw_avg_time} show the execution time
of each component operation and compare the average values. The execution time of the Scheduler and
the ADPCM codec is about 2.5\% higher in the unified implementation. For the DTMF detector, the
difference increases to 5\%. The original DTMF detector requires a single call to \emph{do\_dtmf} to
analyze a frame of samples, while the refactored DTMF detector requires several calls to
\emph{add\_sample} before performing the same task, which results in a more significant increase in
the execution time.

Table \ref{tab_result_hw_area} and Figures
\ref{fig_chart_hw_avg_area}--\ref{fig_chart_hw_results_speed} compare the hardware
generated from unified C++ against hardware-only C++. \emph{Calypto's CatapultC} HLS tool was used
to obtain RTL descriptions of the components. The descriptions were then synthesized using
\emph{Xilinx's ISE 13.4} targeting a \emph{Virtex6 XC6VLX240T} FPGA. CatapultC and ISE were
configured to minimize circuit area considering a target operating frequency of 100 MHz (the
operating frequency of the SoC).

%Unified/HW-only
%Scheduler 1.39
%ADPCM 1.27
%DTMF 0.97
\tabSC{tab_result_hw_area}
{FPGA resource utilization of hardware-only implementations \emph{vs.} Unified implementations
adapted to the hardware domain}
\figSC{.75}{fig_chart_hw_avg_area}{Average FPGA resource utilization}
%\tabSCxXxXfigV[ht]
%{tab_result_hw_area}
%{fig_chart_hw_avg_area}{.75}
%{FPGA resource utilization of hardware-only implementations \emph{vs} Unified implementations
%adapted to the hardware domain}

\figTC{.70}{fig_chart_hw_results_speed}{Performance of hardware-only C++ \emph{vs.} unified C++
adapted to the hardware domain. In figure (b) values are normalized to compare all components in the
same scale.}

Table \ref{tab_result_hw_area} shows the amount of FPGA resources required for each
component and Figure \ref{fig_chart_hw_avg_area} plots the \emph{average resource utilization}. The
\emph{average resource utilization} is the arithmetic mean of the amount of each
specific resource weighted by its total amount available. This resulting value estimates the total
amount of FPGA area (in \%) required and is used as an area comparison metric. The results vary
significantly in each case study. The apparent smaller area of the unified DTMF detector is due to
different mapping of resources between \emph{RAM blocks} and \emph{flip-flops}, which resulted in 
smaller \emph{average resource utilization}. On the other hand, the unified Scheduler and DTMF
require about 39\% and 27\% more area, respectively. Since the implementations of the HW-only and
unified ADPCMs are very similar, we conclude that, in this case, most of the extra area comes from
the \emph{Dispatch} aspect which implements the \emph{agent} (section
\ref{sec:proposal:unified_design:stubs}) required for transparent communication between hardware and
software. The agent must implement a generic mechanism for parsing and issuing operation requests,
while a hardware-only description can focus on a more specific and optimized interface. This
overhead can be considered significant and increases with the number of supported operations.
Nevertheless, this overhead is expected to be significantly reduced in future implementations of the
agent. 
%TODO compare the dummy results with the ones of other works, such as  Gantel et al (5 min pres.)

Figure \ref{fig_chart_hw_results_speed}a shows the maximum operating frequency of each component.
All implementations achieved similar clock frequencies and met the 100 MHz constraint. Figure
\ref{fig_chart_hw_results_speed}b shows the maximum number of clock cycles required to perform an
operation. For the unified implementations of the Scheduler and the ADPCM, the \emph{agents'}
overhead is proportional to the number of arguments in the operation (2 for \emph{Scheduler::insert}
and 1 for \emph{ADPCM\_Codec::encode}). The high absolute overhead of the unified DTMF detector
comes from the several invocations of \emph{DTMF\_Detector::add\_sample} required to fill its
internal buffer. This operation is implemented in a stream-like fashion in the HW-only
detector.

\tabTC[!ht]{tab_result_hw_others_area}
{Hardware footprint of the remaining components}

To conclude our analysis, we have evaluated the total overhead of communication infrastructure
required to handle transparent hardware/software communication. EPOS's internal components are
implemented using static metaprogramming to achieve high reusability with low overhead and its final
footprint depends on the application configuration. Therefore, it does not make sense to evaluate
certain components in isolation (e.g. the \emph{Component Manager}---Figure \ref{fig_pabx_soc_v2},
which implements the runtime support described in section \ref{sec:proposal:summary}). In order to
provide such evaluation, Table \ref{tab_soc_results} thus shows the total footprint considering the
following different partitionings of our PABX SoC: all the case studies are in software; all the
case studies are in hardware; and a hybrid partitioning in which only the scheduler is in software.
The values shown in parentheses are the total footprints subtracted by the footprints of all
case studies in the respective domain. For instance, the software footprint \emph{()'s} value of a
specific partitioning is the total software footprint subtracted by the ones of all case studies
implemented as software in that partitioning. This value allows us to evaluate the overhead added by
the component management mechanisms. As reference, the footprints of the remaining hardware
components are also provided in Table \ref{tab_result_hw_others_area}.

%All SW - All HW = 4278 (Comp, mgm. + stubs ovehead when all SW)
%Hybrid - All HW = 126 
%Comp, mgm. + stubs ovehead (DTMF + ADPCM) = 4170
%About 4k + 30b per stub op
%----------
%About 1.3% more hardware area
As can be seen in table \ref{tab_soc_results}, moving all cases to hardware reduced the total
footprint. By comparing the \emph{()'s} values, we can see that, in the \emph{All HW} partitioning,
the introduction of the component management mechanism added an overhead of 4278 bytes. By moving
the Scheduler back to software in the \emph{Hybrid} partitioning, the aforementioned overhead is
reduced to 4170 bytes. Considering the number of operations implemented in each stub, we estimate
an initial overhead of about 4 Kbytes plus 30 bytes for each operation implemented in a stub. We
expect to significantly reduce this overhead in future implementations, however, the current results
are acceptable if compared with similar infrastructures~\cite{Gracioli:2010}. On the hardware side,
the calculated area overhead when all cases are in hardware represents only 1.3\% of the total
circuit area and negligible when represented in terms of the total amount of resources available
in the target device (only 0.05\%).

%Entre parenteses o footprint total e do lado o total-footprint_componentes_individuais
\tabSC{tab_soc_results}
{SoC area footprint. In the hybrid partitioning, the Scheduler is in software while the ADPCM codec
and the DTMF detector are in hardware.}

\section{Conclusion}
\label{sec:conclusion}
In this paper we have explored a methodology based on AOP and OOP concepts in order to produce
unified descriptions of hardware and software components. We have shown that components designed
following the principles presented in this work are susceptible to both software and hardware
generation using standard compilers and HLS tools. This is possible through the isolation of
specific hardware and software characteristics (resource allocation and communication interface)
into aspect programs which are weaved with the unified descriptions only during the final stages of
the design process. Furthermore, our mechanisms are implemented using only standard C++ features,
thus facilitating compatibility with different C++/C-based HLS tools. 

Finally, we have demonstrated our methods by redesigning some functional blocks of a PABX system.
The resulting components confirmed that, at an acceptable cost in area and performance, we can use
C++ as a unified language to implement both hardware and software in an straightforward way, thus
reducing the costs of design cycles and time-to-market, and contributing to the progress of embedded
system design towards system-level methodologies.

\section*{Acknowledgments}
The authors would like to thank João Paulo Pizani Flor and Marcelo Daniel Berejuck for providing the
original implementations of the some of the case studies used in this work. This work is also
partially supported by the \emph{Coordination for Improvement of Higher Level Personnel}~(CAPES),
under grants RH-TVD 006/2008 and 240/2008.

%\bibliographystyle{IEEEtran}
%\scriptsize

\bibliographystyle{IEEEtran}
\bibliography{paper}


%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}

% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}

\end{document}
