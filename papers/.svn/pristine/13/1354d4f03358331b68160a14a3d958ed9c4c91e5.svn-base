\documentclass[10pt,twocolumn]{article} 

\usepackage[latin1]{inputenc}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{times}
\usepackage{verbatim}
\usepackage{latex10_Bilbao}




\newcommand{\fig}[4][htbp]{
  \begin{figure}[#1] {\centering\scalebox{#2}{\includegraphics{fig/#3}}\par}
    \caption{#4\label{#3}}
  \end{figure}
}
\newcommand{\figR}[5][htbp]{
  \begin{figure}[#1]{\centering\scalebox{#2}{\includegraphics[angle=#5]{fig/#3}}\par}
    \caption{#4\label{#3}}
  \end{figure}
}
\newcommand{\figTC}[4][htbp]{
  \begin{figure*}[#1] {\centering\scalebox{#2}{\includegraphics{fig/#3}}\par}
    \caption{#4\label{#3}}
  \end{figure*}
}

\sloppy

%------------------------------------------------------------------------- 
% take the % away on next line to produce the final camera-ready version 
%\pagestyle{empty}

%------------------------------------------------------------------------- 
\begin{document}

\title{Operating System Management of Scratchpad Memories}

\author{Tiago Rogério Mück\\ 
\and Hugo Marcondes\\ 
\and Antônio Augusto Fröhlich\\  
\and \\
Federal University of Santa Catarina (UFSC)\\
Laboratory for Software and Hardware Integration (LISHA)\\
\{tiago, hugom, guto\}@lisha.ufsc.br\\
}


\maketitle
\thispagestyle{empty}


\begin{abstract}

Contemporary embedded system applications are requiring even faster processors and larger memories. Previous studies have shown that the memory subsystem is an important optimization point. \textit{Software-controlled caches}, often called \textit{scratch-pad memories} (SPM), are being increasingly used due to their efficiency. However, to exploit all the advantages of the SPMs an efficient allocation must be done in software, . In this work we propose a runtime operating system management approach for SPMs that do not require compiler support, application profiling or hardware support. The OS will use annotations, inserted into the code by the programmer, as hint to choose the most appropriate level in the memory hierarchy to allocate the data. The results showed that we were able to implement a run-time SPM allocation technique without adding any significant overhead to the system when compared with the manual allocation.

\end{abstract}


\Section{Introduction}


Contemporary embedded system applications are requiring even faster processors and larger memories. Previous studies have shown that the memory subsystem is responsible for 50\%-75\% of the total system power consumption and occupies significant chip area~\cite{Kandemir::2002}, which shows that the memory subsystem is an important optimization point. Most system rely on cache-based memory hierarchies due to the capacity of caches to exploit the spatial and temporal locality of memory access. However, caches require an additional tag memory and address comparison logic which may significantly increase their power consumption and area cost, thus turning them inappropriate for most embedded applications~\cite{Verma::2006}. In addition, \emph{worst case execution time} (WCET) must be overestimated due to the lack of predictability of caches~\cite{Wehmeyer::2005}, which may forbid their use on real-time embedded systems.

An alternative to caches is the use of \textit{software-controlled caches}, often called \textit{scratch-pad memories} (SPM). The SPMs do not need the extra logic to map data and instructions to it because all of the memory allocation to the SPM is controlled by software, so SPMs are more power and area efficient than caches~\cite{Verma::2006}. Also, considering that the contents of the SPM are known, tighter bounds on WCET prediction can be achieved~\cite{Wehmeyer::2005}. Nevertheless, to exploit all the advantages of the SPMs an efficient allocation must be done in software. Several software allocation approaches have been proposed. All of the proposed approaches are compile-based techniques, and most of them rely on profiling information to define the instructions and data to be allocated to the SPM at compile-time. These compile-based approaches have two big drawbacks. First, the use of profiling limits the scope of the mapping techniques not only because of the difficulty in obtaining reasonable profiles but also due to high space and time requirements to generate a profile~\cite{Shrivastava::2009}, and this is especially true for dynamic applications were the memory access patterns depends on the input data to the application~\cite{Cho::2009}. Second, this kind of allocation scheme leads to a more complicated software development and reduced portability because it requires very specific toolchains with modified compilers.

In this work we propose a runtime operating system management approach for SPMs that do not require compile support, profiling or hardware support. We assume that an embedded system targets a specific hardware platform and a specific application, so an embedded OS can receive information about the underlaying memory hierarchy and about the kind of access to the application data in order to provide an efficient memory allocation. In the proposed approach, all the memory components are abstracted as a single dynamic heap. When an application requires an memory allocation, the OS will use annotations, inserted into the code by the programmer, as hint to choose the most appropriate level in the memory hierarchy to allocate the data. If an allocation request on the preferred memory component fails, the OS will attempt to allocate on a less optimal memory component, thus handling exhaustion of a particular memory component. This way the OS can take advantage of the developer's knowledge about the application to provide an efficient data allocation without the drawbacks of the previously proposed techniques. In our approach we handle only user declared heap variables. Global variables allocated at compile-time can be easily converted to heap variables by declaring them in this way and allocating them manually during the application initialization. The automatic allocation of code and stack variables to the SPM will be discussed later as future work.



\Section{State of Art}


In the last years a lot of SPM management approaches have been proposed. We separated this approaches in the different categories shown in figure \ref{fig_spm_state_of_art}. The \textit{static} approaches~\cite{Avissar::2002, Angiolini::2004, Hiser::2004} are those in which the contents of the SPM are fixed at compile-time and never change. In the \textit{dynamic} approaches the SPM contents change during the program execution. When the sets of code and/or data that will be moved to/from the SPM are defined at compile-time, we call it a \textit{compile-time} approach~\cite{Verma::2006, Udayakumaran::2006, Ozturk::2007}. If this sets can change or are defied during the program execution, we call it a \textit{run-time} approach~\cite{Cho::2009, Shrivastava::2009, Milidonis::2009, Dominguez::2005, McIlroy::2008, Nguyen::2007, Huneycutt::2002}. The run-time approaches generally fallows one or more of the following three basic methodologies that we have defined: an run-time approach is \textit{compiler-assisted} if actions are taken by the compiler to define the allocation. An \textit{hardware-assisted} approach are the ones that require special hardware support. Finally there are the approaches that require \textit{run-time software support} provided by a standalone library or by an OS to perform the allocation.

\figTC{.45}{fig_spm_state_of_art}{Classification of SPM allocation approaches}

Several static allocation approaches have been proposed~\cite{Avissar::2002, Angiolini::2004, Hiser::2004}. As shown in figure \ref{fig_spm_state_of_art}, they can be divided into two catogories: \textit{compile-time techniques} where the allocation is made by the compiler~\cite{Avissar::2002, Hiser::2004}, and \textit{post-compile techniques} where algorithms are applied at the final binary code to change the memory allocation~\cite{Angiolini::2004}. These static allocation approaches either use greedy strategies to find an efficient solution, or model the problem as a \textit{knapsack} problem or an \textit{integer-linear programming} problem (ILP) to find an optimal solution. \textit{Avissar et al}~\cite{Avissar::2002} proposed a memory allocation strategy that is optimal in relation to the profiling provided. In \textit{Angiolini et al}~\cite{Angiolini::2004} another optimal solution was proposed. This technique is applied in the application binary code and is optimal in relation to a certain set of execution traces. Despite being optimal, all the static methods have the disadvantage of being dependent of an efficient application profile and future publications have shown that the dynamic approaches usually leads to a more efficient usage of the SPM.

Dynamic methods based on compile time techniques are those which can change the SPM allocation based only on compile time decisions~\cite{Verma::2006, Udayakumaran::2006, Ozturk::2007}. All dynamic data movement decisions are made at compile-time based on profile information. \textit{Verma et al}~\cite{Verma::2006} is a good example of this kind of technique. The authors propose an overlay-based memory allocation approach for both code and data. The proposed solution uses ILP to find the optimal memory allocation and overlay points that minimizes energy consumption for a given profile. They also propose a first-fit algorithm to obtain an near-optimal solution for the allocation.

The compile-time dynamic methods are more efficient in exploiting the benefits of SPM, but they are still dependent on good application profiles. Another problems of this methods is that they do not provide an efficient allocation when the accessed memory regions are heavily related to the application's input data, thus methods that change the objects that are allocated in the SPM at run-time are required. The run-time techniques are generally composed of run-time software or OS that determine the contents of the SPM based on features inserted by the compiler and/or hardware support, although there are run-time techniques that do not require compiler support. In \textit{Milidonis et al}~\cite{Milidonis::2009} the global data structures are sliced into \textit{tiles} which are allocated to the SPM by the compiler. An hardware component called \textit{Data type Unit} (DTU) works like an special cache that keeps references to the most accessed tiles and sends commands to a DMA unit to move the data between the SPM and main memory when necessary. This approach solves the problem of dynamic access patterns, but it still require an initial profiling to determine the possible tiles, and a very specific hardware support that forbids it application fixed hardware platforms.

In \textit{Shrivastava et al}~\cite{Shrivastava::2009} is proposed an approach that do not require profiling or hardware support. They manage the function's stack frames, allocating them on the SPM when they are in use, thus this approach handles only stack data which represents 65\% of the memory access on multimedia applications~\cite{Shrivastava::2009}. They proposed a software library that provides functions to manage the stack. The calls to the library are inserted by the compiler before and after each function call. To avoid excessive calls to their library they use a program flow analysis based on \textit{Global Call Control Flow Graphs} (GCCFG) to group their function calls more efficiently. This approach have the advantage of not requiring profiling or hardware support, but it still require compiler modifications and focus on only one class of applications (multimedia applications).
 
In \textit{Cho et al}~\cite{Cho::2009} was proposed an allocation scheme that integrates compiler, OS, and hardware, that is very similar to \textit{Milidonis et al}~\cite{Milidonis::2009}. First, through profiling the most accessed data sets are defined and based on a cost analysis the compiler define the optimal points to insert the OS calls the reallocate the SPM data. When reallocating, the OS verifies an hardware structure called \textit{Data Access Record Table} (DART) that keeps information about the most accessed data sets. The OS uses this information to define the new memory allocation. Since the data addresses changes during run-time, they added a simplified MMU for address translation. The author shows that the technique is very efficient their target application (multimedia application), but it requires compiler, OS, and hardware support, thus it come up with all the drawbacks of the dynamic run-time techniques discussed earlier.

There are dynamic run-time techniques that require only run-time software support. A common technique is \textit{software caching}. This approach emulates a cache in SRAM using software. The tag, data and valid bits are all managed by code inserted at each memory access. Significant software overhead is incurred to manage these fields, and all the improvements of the SPM in relation to caches disappear. Another run-time-only technique that follows a different approach was proposed in \textit{Nguyen et al}~\cite{Nguyen::2007}. In this approach the authors uses the same ideas discussed in the hardware-based approaches to implement SPM management for Java applications. The main difference is that the tracking of the accessed data structures and allocation code are implemented at JVM level. This technique do not require special compiler or hardware support, but the overhead of a JVM may be unacceptable on an embedded system.

All the previous techniques handled only code and/or global/stack data. The only known technique that allocates heap data to the SPM was proposed in \textit{Dominguez et al}~\cite{Dominguez::2005}. The proposed technique divides the application code in regions where the begin and end of each region is defined by the begin and end of function and loops. An compile-time analysis is done in this regions to define the head variables that will be allocated to the SPM and the code to make this allocation is inserted. Since the size of heap variables may be unknown at run-time, the size of the variable is estimated and only a fixed part of the variable is allocated to the SPM. Despite of being the fist technique that allocates heap data to the SPM, this technique follows the \textit{dynamic compile-time approach} discussed earlier, and suffer with the same problems. Another work that deals with the management of heap data was presented in \textit{McIlroy et al}~\cite{McIlroy::2008}. In this work the authors do not propose a technique for SPM management, they just suppose a run-time system that provides the automatic management of SPM as a dynamic heap and propose a heap memory allocation algorithm. The proposed algorithm is optimized to very small memories and aims to reduce the space overhead while keeping performance at reasonable levels.


\Section{Implementation}

In our approach we assume that an embedded system targets a specific hardware platform and a specific application, so an embedded OS receive information about the underlaying memory hierarchy and about the kind of access to the application data in order to provide an efficient memory allocation. All the memory components are abstracted as a single dynamic heap. When an application requires an memory allocation, the OS uses annotations, inserted into the code by the programmer, as hint to choose the most appropriate level in the memory hierarchy to allocate the data.

We have implemented an framework for the C++ language that provides parameterized versions of the \textit{new} and \textit{delete} operators. Allowing the programmer to easily insert allocation hints into the program. The framework was implemented on the \textit{Embedded Parallel Operating System} (EPOS)~\cite{Frohlich::2001}. EPOS relies on the \textit{Application-Driven Embedded System Design Method} (ADESD)~\cite{Frohlich::2001} to design and implement both software and hardware components that can be automatically adapted to fulfill the requirements of particular applications. Low overhead and high performance are achieved by a careful implementation that makes use of \textit{generative programming}~\cite{Czarnecki::2000} techniques, including \textit{static metaprogramming}. A detailed description of the memory management framework and its implementation on EPOS are presented bellow.

\SubSection{The allocation framework}

Our framework uses two different class of annotations:

\begin{itemize}
 \item Type annotations \begin{itemize}
                         \item ALLOC\_T\_VOLATILE 
			 \item ALLOC\_T\_PERSISTENT
                        \end{itemize}

 \item Priority annotations \begin{itemize}
                             \item ALLOC\_P\_HIGH
			     \item ALLOC\_P\_LOW
			     \item ALLOC\_P\_NORMAL
                            \end{itemize}

\end{itemize}

Type annotations define if the object will be allocated in a volatile or in a non-volatile memories. We idealize the abstraction of the management of both memory and storage in persistent devices (e.g. FLASH, EPROM, etc) through a single abstraction, so we included this type annotations in the framework in order to allow it to provide this abstraction. However, currently the framework handles allocation only on volatile memories and do not support type annotations. The support to non-volatile store will be approached in future works.

Priority annotation are the ones used by the OS to define in which level of the memory hierarchy the date will be allocated. When the \textit{ALLOC\_P\_HIGH} annotation is used, it means that particular object have a high memory access priority (i.e. performance/power consumption of read/write operations on it have a major impact over the system efficiency) and should be allocated on the more efficient level of the memory hierarchy (e.g. a SPM). The \textit{ALLOC\_P\_LOW} have the inverse meaning. It means that the object have a low memory access priority and it can be allocated on the less efficient level of the memory hierarchy without a significant impact on the system efficiency. Finally, the \textit{ALLOC\_P\_NORMAL} annotation is used to indicate that the OS should decide the best place to allocate that object.

The example in figure \ref{fig_spm_code_alloc} shows how this annotations are passed to the \textit{new} operators. In this example, four arrays of type \textit{int} are allocated using the different annotations and without annotation. When annotations are not used, the OS assumes \textit{ALLOC\_P\_NORMAL}. The usage of the \textit{delete} operator doesn't change.  

\begin{figure}[htbp]
\small
\scriptsize
\begin{verbatim}
int *at_spm = new (ALLOC_P_HIGH) int[[10];
int *at_main_mem = new (ALLOC_P_LOW) int[[10];
int *somewhere = new (ALLOC_P_NORMAL) int[[10];
int *somewhere_else = new int[[10];/*equivalent to the
                                   statement above/*

delete[] at_spm;
delete[] at_main_mem;
delete[] somewhere;
delete[] somewhere_else;
\end{verbatim}
  \normalsize
  \caption{Examples of memory allocation requests using the priority annotation}
  \label{fig_spm_code_alloc}
\end{figure}
 
Given an annotation, it may not be possible to allocate the data on the desired location. The pseudo-code in figure \ref{fig_spm_code_alloc_algo} describes the algorithm used to decide where the data will be allocated based on the annotation and the amount of space available on the different memories.

\begin{figure}[htbp]
\scriptsize
\centering
\begin{verbatim}
memory allocation (size, annotation)

    if annotation = ALLOC_P_HIGH 
        if fits on spm (size)
            allocate_on_spm
        else
            allocate on main mem
    
    else if annotation = ALLOC_P_LOW
        if fits on main mem (size)
            allocate on main mem
        else
            allocate on spm
        
    else if annotation = ALLOC_P_NORMAL
        if spm free percentage > 
                  main mem free percentage
            if fits on spm (size)
                allocate_on_spm
            else
                allocate on main mem
        else
            if fits on main mem (size)
                allocate on main mem
            else
                allocate on spm
\end{verbatim}
  \normalsize
  \caption{Algorithm that defines where the allocation will be done}
  \label{fig_spm_code_alloc_algo}
\end{figure}

If an allocation request can't be accomplished on the preferred memory component, the OS will attempt to allocate on a less optimal memory component. If it is left to the OS to decide where to allocate, the OS will attempt to allocate on the memory with the highest percentage of free space, thus handling exhaustion of a particular memory component. 

The implementation of the memory deallocation is straightforward. The OS just checks the pointer address to decide if the memory will be deallocated on the main memory or on the SPM.

\SubSection{Memory management on EPOS}

The \textit{Heap} abstraction is the higher level abstraction responsible for memory management on EPOS. It keeps a list of free memory blocks and handles allocation and deallocation requests. Its interface is described in the UML diagram in figure \ref{fig_spm_epos_heap}.

\fig{.40}{fig_spm_epos_heap}{UML diagram of the \textit{Heap} abstraction}

Two Heap instances are created on EPOS during the system initialization. One is used to implement the \textit{malloc} and \textit{new operator}, that are both used to handle memory allocation request from the application. The other is used to implement the \textit{kmalloc}, which is used to handle OS memory allocation requests(e.g memory for the threads stacks).

\SubSection{Implementation on EPOS}

In order to managed the SPM on EPOS, we created a new application heap. During system initialization, we initialize this new heap with the base address and size of the SPM defined on the platform's memory mapping. Memory allocation requests to the SPM are handled using the new heap. The \textit{malloc} and \textit{free} functions of EPOS are used to implement the \textit{new} and \textit{delete} operators. These functions ware modified to implement the algorithms described in the previous section and to decide if the allocation request will be forwarded to the original heap or to the new SPM heap, based on the annotations received from the \textit{new} operator.

This implementation approach give a hint about how stack variables allocation to the SPM could be handled in future work. Currently, the threads stacks are allocated using an heap dedicated to the OS. By using the same approach and dividing the SPM between two heaps (one for OS and one for the application) may lead to an unacceptable fragmentation. One possible solution is to modify EPOS so it can use an unified heap for both application and data, and then use the current approach with the possibility of giving allocation hints during thread creation. Another way would be to insert an workaround to allocate an thread stack using the modified \textit{malloc} instead of \textit{kmalloc}.


\Section{Results}

To evaluate the proposed approach we measured the memory latencies and the overhead added to the \textit{new} and \textit{delete} operations. With this preliminary tests we can verify if the framework imposes a significant overhead in relation to the manual allocation.

\SubSection{Evaluation setup}

We used the \textit{Xilinx ML403 Evaluation Board} to build a platform for our evaluation. The ML403 board features a Xilinx Virtex 4 FPGA with an embedded PowerPC 405 processor that is implemented as a hard-core inside the FPGA (i.e. it is implemented directly in silicon instead of using FPGA logic resources). Figure \ref{fig_spm_ml403_blk} shows a simplified block diagram of the built platform.

\figTC{.35}{fig_spm_ml403_blk}{Simplified block digram of the Xilinx ML403 platform used on the evaluations}

The PowerPC two \textit{Processor Local Bus} (PLB) interfaces which are high speed interfaces to connect on-chip peripherals to the processor. It has also an 
\textit{On-Chip Memory} (OCM) bus interface which is an interface dedicated to connect on-chip memory to the processor. The ML403 board features an external 64 Mb DDR SDRAM external memory that we connected to one of the PLB interface to use it our platform main memory. We implemented the SPM using the Virtex 4 internal block RAM connected to the OCM bus. Another block RAM peripheral is connected the another PLB bus interface to store the bootloader software that will load the system into the main memory. This bootloader memory is idle after the system is loaded, so we used it as a SPM as well, although its performance may suffer since its PLB bus is shared with the other IO peripherals. The PowerPC processor offers an internal two 16Kb caches for instructions and data that can be used to cache any memory peripheral connected to the PLB buses. To keep a standar memory hierarchy, we connected only the external memory to the caches. The resulting memory hierarchy is shown in figure \ref{fig_spm_ml403_mem}.

\fig{.34}{fig_spm_ml403_mem}{ML403 memory hierarchy}

Table bellow summarizes other parameters used on the experiments.

\begin{table}
\caption{Configuration parameters used on the experiments}
\label{results_table_params}
\centering
\begin{tabular}{ll}
\hline\noalign{\smallskip}
Parameter & Value \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
Synthesis tool & ISE/EDK 10.1 \\
Compiler & GCC 4.0.2 \\
FPGA clock & 100 MHz \\
Microprocessor clock & 100 MHz \\
\hline
\end{tabular}
\end{table}


\SubSection{Obtained results}

We evaluated the performance of the \textit{new} and \textit{delete} operators for each different annotation and compared with the original single heap allocation approach. The algorithm in figure \ref{fig_spm_code_alloc_test} were used to evaluate this operations. With this algorithm we are able to evaluate the allocation requests times using different allocation patterns. We repeated this iterations for the original \textit{new} and \textit{delete} operations without using annotations and for each of the three possible annotations: \textit{ALLOC\_P\_HIGH}, \textit{ALLOC\_P\_LOW}, and \textit{ALLOC\_P\_NORMAL}.

\begin{figure}[htbp]
\scriptsize
\centering
\begin{verbatim}
for (int i=0; i < 2 * BLK_SIZE; i++) 
    char *p1 = new (ANNOTATION) 
                   char[[ (i % BLOCK_SIZE) + 1];
    int *p2 = new (ANNOTATION) int;
    char *p3 = new (ANNOTATION) char[[300];

    delete[[] p1;
    delete[[] p2;
    delete[[] p3;
\end{verbatim}
  \normalsize
  \caption{\textit{new} and \textit{delete} evaluation algorithm}
  \label{fig_spm_code_alloc_test}
\end{figure}

Figure \ref{fig_spm_results_alloc} shows the average time to complete a \textit{new} and a \textit{delete} operation. The results show that our new allocation approach added a negligible overhead to the original one. The higher allocation time when the \textit{ALLOC\_P\_NORMAL} annotation is used is expected since extra logic is required to define the heap to be used.

\fig{.61}{fig_spm_results_alloc}{Performance of the original memory allocation operations \textit{new} and \textit{delete} compared with the new parameterizable memory operations when different parameters}

We also measured the latency of read and write operations on the tree memory components available. Figure \ref{fig_spm_results_mem_lat} shows the measured latency, which is the average time to read/write several blocks of 4096 words of 4 bytes. Surprisingly, the read/write times ware very close for all memories. The only significant difference was on the faster write operation in the SPM connected to the OCM bus. Since the caches were disabled in this experiment, one explanation for the PLB based SPM is that it is connected on a bus that is shared with IO peripherals, which may have affected its performance. However, the other OCM based SPM is connected to a bus which is dedicated to on-chip memories and should have shown better performance. The read/write latency is the same regardless the allocation approach used.

\fig{.61}{fig_spm_results_mem_lat}{Read/write latency of the different memories structures available on the platform. The measured latency is the time to read/write a block of 4096 words of 4 bytes}

\SubSection{Discussion}

The results showed that we were able to implement a run-time SPM allocation technique without adding any significant overhead to the system compared with the manual allocation. However, real benchmarks must be used to determine the efficacy of this proposed approach in relation to a cache-based system and the other proposed approach. Also an FPGA-based test platform do not provide realistic energy consumption results, so a different platform or simulations based on power consumption models are necessary to obtain information about energy consumption.

\Section{Conclusion}

We have proposed a runtime operating system management approach for SPMs that do not require compile support, profiling or hardware support. On the proposed approach, the OS will use annotations, inserted into the code by the programmer, as hint to choose the most appropriate level in the memory hierarchy to allocate the data. The results showed that we were able to implement a run-time SPM allocation technique without adding any significant overhead to the system compared with the manual allocation. However, more experiments are necessary to really determine the efficacy of the proposed approach. Also, in our approach we handle only user declared global and heap variables. We discussed the possible allocation of the entire stack to the SPM, but its necessary to find ways to break the stack between the different memories. The automatic allocation of code and stack variables to the SPM at run-time without the help of a compiler or special hardware will be covered in future works. 


\bibliographystyle{latex10_Bilbao}
\bibliography{references_spm.bib}

\end{document}
