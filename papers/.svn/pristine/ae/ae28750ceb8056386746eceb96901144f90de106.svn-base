%%
%% Copyright 2007, 2008, 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%

%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%%
%%
%%
%% $Id: elsarticle-template-num.tex 4 2009-10-24 08:22:58Z rishi $
%%
%%
\documentclass[final,5p,times,twocolumn]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% if you use PostScript figures in your article
%% use the graphics package for simple commands
%% \usepackage{graphics}
%% or use the graphicx package for more complicated commands
%% \usepackage{graphicx}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
%% \biboptions{comma,round}

% \biboptions{}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{url}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{color}
\usepackage[pdftex]{hyperref}
\usepackage{paralist}
\usepackage{listings}
%\usepackage{subfigure}
\usepackage{caption}
\usepackage{subcaption}
\lstset{keywordstyle=\bfseries, flexiblecolumns=true}
\lstloadlanguages{C,[ANSI]C++,HTML}
\lstdefinestyle{prg}{
  basicstyle=\small\sffamily,
%  lineskip=-0.2ex,
  showspaces=false
}

\newcommand{\comment}[1]{}
\definecolor{Orange}{rgb}{1,0.5,0}
\newcommand{\todo}[1]{\textsf{\textbf{\textcolor{Orange}{[[#1]]}}}}

\lstset{
  keywordstyle=\bfseries,
  aboveskip=15pt,
  belowskip=15pt,
  captionpos=b,
  identifierstyle=\ttfamily,
  escapeinside={(*@}{@*)},
  stringstyle=\ttfamiliy,
  %frame=single,
  numbers=left, basicstyle=\scriptsize, numberstyle=\tiny, stepnumber=0, numbersep=2pt}

\newcommand{\prg}[3][h]{
\begin{figure}[#1]
  \lstinputlisting[language=C,keywordstyle=\bfseries,
  aboveskip=15pt,
  belowskip=15pt,
  captionpos=b,
  identifierstyle=\ttfamily,
  escapeinside={(*@}{@*)},
  stringstyle=\ttfamiliy,
  frame=single,
  numbers=left, basicstyle=\tiny, numberstyle=\tiny, stepnumber=0, numbersep=2pt]{fig/#2.cc}
  \caption{#3}
  \label{prg:#2}
\end{figure}
}

\newcommand{\prgFull}[3][h]{
  \lstinputlisting[language=C,keywordstyle=\bfseries,
  aboveskip=15pt, 
  belowskip=15pt,
  captionpos=b,
  identifierstyle=\ttfamily,
  escapeinside={(*@}{@*)},
  stringstyle=\ttfamiliy,
  %frame=tbrl,
  numbers=left, basicstyle=\tiny, numberstyle=\tiny, stepnumber=0, numbersep=2pt]{fig/#2.cc}
}


\newcommand{\tab}[3][h]{
  \begin{table}[#1]
    {\centering\small\textsf{\input{fig/#2.tab}}\par}
    \caption{#3}
  \label{tab:#2}
  \end{table}
}

\newcommand{\Tab}[3][tb]{
  \begin{table*}[#1]
    {\centering\small\textsf{\input{fig/#2.tab}}\par}
    \caption{#3}
  \label{tab:#2}
  \end{table*}
}

\newcommand{\fig}[4][h]{
  \begin{figure}[#1]
    {\centering{\includegraphics[#4]{fig/#2}}\par}
    \caption{#3}
    \label{fig:#2}
  \end{figure}
}

\newcommand{\figtwo}[8]{
\begin{figure}[h]
	\centering
	\begin{subfigure}[h]{#8}
		\centering
		\includegraphics[#3]{fig/#1}
		\caption{#2}
	\end{subfigure}
	\begin{subfigure}[h]{#8}
		\centering
		\includegraphics[#6]{fig/#4}
		\caption{#5}
	\end{subfigure}
	
    \caption{#7\label{figtwo:#1#4}}
\end{figure}
}

\newcommand{\Figtwo}[8]{
\begin{figure*}[tb]
	\centering
	\begin{subfigure}[h]{#8}
		\centering
		\includegraphics[#3]{fig/#1}
		\caption{#2\label{figtwosub:#1}}
	\end{subfigure}%
	\begin{subfigure}[h]{#8}
		\centering
		\includegraphics[#6]{fig/#4}
		\caption{#5\label{figtwosub:#4}}
	\end{subfigure}
    \caption{#7\label{figtwo:#1#4}}
\end{figure*}
}

% \newcommand{\figfour}[9]{%
%     \def{\tempa}{#1}%
%     \def{\tempb}{#2}%
%     \def{\tempc}{#3}%
%     \def{\tempd}{#4}%
%     \def{\tempe}{#5}%
%     \def{\tempf}{#6}%
%     \def{\tempg}{#7}%
%     \def{\temph}{#8}%
%     \def{\tempi}{#9}%
%     \figfourcontinued
% }
% \newcommand{\figfourcontinued}[5]{
% \begin{figure*}[h]
% 	\centering
% 	\begin{subfigure}[h]{#5}
% 		\centering
% 		\includegraphics[#\paramc]{fig/#\parama}
% 		\caption{#\paramb}
% 	\end{subfigure}%
% 	\begin{subfigure}[h]{#5}
% 		\centering
% 		\includegraphics[#\paramf]{fig/#\paramd}
% 		\caption{#\parame}
% 	\end{subfigure}
% 	\begin{subfigure}[h]{#5}
% 		\centering
% 		\includegraphics[#\parami]{fig/#\paramg}
% 		\caption{#\paramh}
% 	\end{subfigure}%
% 	\begin{subfigure}[h]{#5}
% 		\centering
% 		\includegraphics[#3]{fig/#1}
% 		\caption{#2}
% 	\end{subfigure}
% 	
%     \caption{#4\label{figtwo:#\parama#\paramd#\paramg#1}}
% \end{figure*}
% }

\newcommand{\Fig}[4][h]{
  \begin{figure*}[#1]
    {\centering{\includegraphics[#4]{fig/#2}}\par}
    \caption{#3}
    \label{fig:#2}
  \end{figure*}
}



\journal{Computers \& Electrical Engineering}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\title{Efficient energy prediction for low power wireless sensor networks with photovoltaic energy harvesters}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{<author name>}
%% \address[label1]{<address>}
%% \address[label2]{<address>}

\author[das]{Arliones Hoeller Jr.}
\author[lisha]{Antônio Augusto Fröhlich}

\address[das]{Federal University of Santa Catarina - UFSC\\
Automation and Systems Engineering Department - DAS\\
arliones@das.ufsc.br}
\address[lisha]{Federal University of Santa Catarina - UFSC\\
Software/Hardware Integration Lab - LISHA\\
guto@lisha.ufsc.br}

\begin{abstract}
%% Text of abstract
\paragraph{Theme:} Low-power wireless sensor networks harvesting energy from the environment.
\paragraph{Scope:} Control of energy consumption of real-time wireless sensor network applications that harvest energy from the environment for sustaining uninterrupted operation.

\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
keywords\ldots
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%%
%% Start line numbering here if you want
%%
% \linenumbers

%% main text

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

%% References
%%
%% Following citation commands can be used in the body text:
%% Usage of \cite is as follows:
%%   \cite{key}         ==>>  [#]
%%   \cite[chap. 2]{key} ==>> [#, chap. 2]
%%

\section{Introduction}
\label{sec:intro}

% Make the case for the use of predictors
Computing systems harvesting energy from the environment use predictors of energy production to adapt the amount of work they can do in a short-term future window.
Bottom line, the system must ready either to use or to store the harvested energy at the exact moment of its production to avoid waste.
When using efficient predictors, i.e. predictors with low error rates, systems can reconfigure themselves in advance, increasing their utility by consuming more energy to execute more tasks, and making room in the battery for the energy that would turn into waste otherwise.
Inefficient predictors, however, can introduce significant errors in the systems' energy management mechanism.
That usually incur in increased failure rates or reduced system utility generated by the lack of energy.

% Solar energy is the most relevant/used in outdoor systems and is the one where prediction models are more explored
Photovoltaic panels are the most used energy harvesters for outdoors wireless sensor networks.
\tab{harvesters-power_density}{Power densities of harvesting technologies~\cite{Roundy:2005}.}
Table~\ref{tab:harvesters-power_density} shows that solar cells in photovoltaic panels extract approximately 45~times more energy than the best of the other technologies (piezoelectric).
The high efficiency of the harvesting material allows small and cheap panels to power a wireless sensor network node, satisfying two other frequent requirements of such systems: size and cost.
Another important feature of solar technology is the repetition pattern of the energy source (sunlight irradiation).
As can be seen in Figure~\ref{figtwo:plot_1dayplot_1year}, irradiance varies considerably during daytime (top), as does irradiation~\footnote{Solar irradiation is the cumulative energy brought from solar irradiance over a period of time, i.e. $E_I = \int_{t_0}^{t_1} I dt$.} during the year (bottom).
However, an important repetition pattern exists for sunlight irradiance: it is not present at night, increases during the morning until it reaches a peak around noon, and decreases again at the afternoon.
This tendency repeats every day due to the Earth rotation and orbit around the Sun.
Perturbations to this tendency, however, occur when sunlight gets blocked or filtered by other objects, such as trees, dust, or, more often, clouds.

?REPLACE DATA IN FIGURE 1 BY NREL-2004
\Figtwo
{plot_1day}{Solar irradiance of January 1st, 1998.}{width=\columnwidth}
{plot_1year}{1998 monthly irradiation.}{width=\columnwidth}
{Sample solar irradiance and irradiation at Florianópolis, Brazil ($27^o$ latitude).}{\columnwidth}
%\fig{nrel-2004}{One year of solar irradiation in 2004~\cite{NREL:2013}.}{width=\columnwidth}

% Several predictors exist: from dummy continuous repeaters to complex neural networks
% They are evaluated by its proximity to the reality: error rates.
% Computational complexity is also an issue for low-end systems.
There are, in the literature, several approaches to predict the energy intake from solar systems.
All approaches take advantage of the pseudo-periodic and cyclic behavior of sunlight irradiance.
The approaches present a wide range of complexity.
Low complexity solutions, such as EWMA (Exponentially Weighted Moving Average)~\cite{Kansal:2007} and the one presented by Moser et al.~\cite{Moser:2008}, demand for low memory footprint and processing power.
Slightly more complex solutions using filters like the WCMA (Weather-Conditioned Moving Average)~\cite{Piorno:2009}, WCMA-PDR (WCMA with Phase Displacement Regulator)~\cite{Bergonzini:2010}, and the Linear Filter applied by Hocaoğlu et al.~\cite{Hocaoglu:2008}, still show acceptable memory and processing requirements.
The requirements for sophisticated artificial intelligence techniques like neural networks~\cite{Karunanithi:1992}, however, may be prohibitive in some low-end systems.
In general, the higher the complexity of the technique, the lower their error rates and the higher the demands of memory footprint and computational power.
The scarceness of memory and processing power in most wireless sensor nodes makes an adequate analysis of the predictors a must.

% Looking at the behavior of each predictor, it is possible to note that each one of them peforms better in different weather/solar conditions or history (low/high capacity to adapt to changes?)
Moreover, although some predictors show considerable lower error rates when compared to others, none of them is the best predictor in all circumstances.
For instance, EWMA shows large errors and to take a long time to adapt the predictions when sudden weather changes happen.
WCMA overcomes this limitation, but that comes at the cost of a 5 times larger memory footprint and 9 times slower prediction processing~\cite{Bergonzini:2010}.
In the analysis performed here in this work, several of the studied algorithms, although showing low average error rates, still present high standard deviation.
This suggests that some predictors jeopardize the requirements of some applications, specially critical applications where some errors are catastrophic.

% This paper explores ways of taking the advantage of the low error rates of each predictor
In this paper, we analyze the low-complexity algorithms for predicting solar intake in wireless sensor network nodes with photovoltaic panels and propose two heuristics to take advantage of the best case of some of the heuristics.
Year-long simulations with weather-changing situations explore the behavior of the predictors.
Also, we show the computational time of the predictors in a typical, low-end processor, often used in WSN designs.
We show the impact of the prediction algorithms in WSN applications analyzing the time elapsed before the first failure for each predictor, including the proposed heuristics.

% Paper structure
The organization of the paper is as follows.
%Section~\ref{sec:related} describes the prediction algorithms used in this work.
Section~\ref{sec:error} presents related predictors and analyzes their behavior.
%Section~\ref{sec:computing} describes the complexity of the algorithms and shows their computational costs.
Section~\ref{sec:heuristics} presents two heuristic approaches to take advantage of the best case of all predictors.
Section~\ref{sec:experiments} shows an analysis of elapsed time before the first failure of the predictors.
Section~\ref{sec:conclusion} closes the paper.


% \section{Related work}
% \label{sec:related}
% 
% Benini et al.~\cite{Bergonzini:2010} compared six notable prediction algorithms in terms of error rates and computational demands (i.e. memory footprint and processing time).
% 
% Cullers' on long term prediction.

\section{Error rate of predictors}
\label{sec:error}

In this section we analyze the prediction error of the selected predictors over one year.
%Prediction error is taken as a metric to evaluate the fitness of a predictor for a given application.
As adopted in most of the related work, night values\footnote{All values bellow 10\% of the maximum value of the day are considered night values.} are discarded, once the objective of the algorithms is to predict sunlight evolution.
In related work, the accuracy of the predictors is usually estimated using an ordinary average.
The average error of $N$ predictions is would usually be given by:
\begin{equation}
E_{avg} = \frac{1}{N} \sum_{i=1}^N {abs \left ( 1 - \frac{E_i}{\hat{E}_i} \right )}
\end{equation}
where $E_i$ is the amount of energy produced by the photovoltaic module within a time-slot and $\hat{E}_i$ is the predicted amount of energy for the same time-slot.

This error metric, however, only takes into account the relation between predicted and actual energies ($E_i$ and $\hat{E}_i$), and not the magnitude of these values.
This can lead to an improper analysis once high errors in periods of low irradiance (e.g. early mornings) can be less prejudicial to a system then smaller errors are in high irradiance periods (e.g. noon).
To overcome this issue, we propose another metric to evaluate the predictors that takes into account the magnitude of the error in a weighted average.
The metric is given by:
\begin{equation}
E_{wgt} = \frac{ \sum_{i=1}^N { \left [ abs \left ( 1 - \frac{E_i}{\hat{E}_i} \right ) \cdot abs (E_i - \hat{E}_i) \right ] }}{\sum_{i=1}^N { abs (E_i - \hat{E}_i)}}
\end{equation}

% Another metric used to evaluate the predictors is the absolute error over the year.
% The absolute error ratio is computed using the sum of energy intake and predictions, as shown in~\ref{eq:abs_error}:
% \begin{equation}
% \label{eq:abs_error} Error_{abs} = 1 - \frac{\sum_{i=1}^N E_i}{\sum_{i=1}^N \hat{E}_i}
% \end{equation}
% It is important to note that this metric hides the variation of the prediction errors inside the evaluated period.

%The analysis of the predictors uses a year-long simulation to evaluate average prediction error over the year.
The simulations presented herein used publicly available solar data from the National Renewable Energy Laboratory (NREL) of the U.S. Department of Energy~\cite{NREL:2013}.
All experiments used the dataset in Figure~\ref{fig:nrel-2004}, that shows one sample of solar irradiation per minute during the year of 2004.

Energy production from solar irradiation is computed using the characteristics of a photovoltaic module for wireless sensor networks~\cite{Slongo:2013}.
That panel shows a quasi-linear behavior, approximated by Equation~\ref{eq:panel_current}.
To compute the energy intake in a period we integrate power assuming a constant voltage (3 volts) (Equation~\ref{eq:panel_energy}).
In the simulations, solar irradiation is assumed to be constant during one minute, and the integral is computed numerically using the Euler method with 1-minute discrete time steps.
Figure~\ref{figtwo:predictors_avgpredictors_wgt} presents the simulation results.
Once some filters use recent history to compute the predictions, the first 30 days of simulation were discarded to allow these algorithms to warm-up, ensuring a fairer comparison.
Details about each algorithm's results are discussed in the following subsections.

\begin{eqnarray}
\label{eq:panel_current} I [A] = 0.020628 \times Irrad [W/m^2] \\
\label{eq:panel_energy}  E_i [J] = \int_{t_0}^{t_1} ( I [A] \times U [V] ) dt [s]
\end{eqnarray}

\Figtwo
{predictors_avg}{$E_{avg}$ of studied predictors.}{width=\columnwidth}
{predictors_wgt}{$E_{wgt}$ of studied predictors.}{width=\columnwidth}
{Error rate characterization of studied sunlight irradiation predictors.}{\columnwidth}

\subsection{Exponentially Weighted Moving Average}

The EWMA (Exponentially Weighted Moving Average) filter~\cite{Cox:1961}, shown in Equation~\ref{eq:ewma}, has been used to predict sunlight evolution in low-end computing devices (e.g. sensor nodes)~\cite{Kansal:2007}.
This predictor was extensively evaluated in the past, and is reported to show little error when deployed for short-term prediction (up to 30-minute prediction windows)~\cite{Kansal:2007,Bergonzini:2010}.
The filter uses the recorded information about sunlight irradiation of the same period in the last days to predict the sunlight irradiation for the next prediction window.
An weighting factor ($\alpha$) balances exponentially the influence of past predictions and recent energy intake in the predictions.
The simulation results presented here are similar to the previously reported.

The difference between the $E_{avg}$ and $E_{wgt}$ shown in Figures~\ref{figtwosub:predictors_avg} and~\ref{figtwosub:predictors_wgt} shows that most of EWMA's prediction errors occur in low irradiation periods.
Another interesting characteristic of EWMA is that it shows an almost constant error rate for different window sizes, making it suitable for long-term predictions.

\begin{equation}
\label{eq:ewma} \hat{E}_{i+1} = \alpha \cdot (\hat{E}_i) + (1 - \alpha) \cdot E_i
\end{equation}



\subsection{Weather-Conditioned Moving Average}


The WCMA (Weather-Conditioned Moving Average) filter~\cite{Piorno:2009} extends the EWMA filter to take into account information about the weather conditions within the current day.
This modification addresses the serious drawback of the EWMA's inability to adapt fast enough to sudden weather changes.
Such enhancements, however, come at the expense of higher demands in terms of processing ($4.43\times$) and memory ($4\times$) requirements~\cite{Bergonzini:2010} when compared to EWMA.

Figure~\ref{fig:wcma_spaces} shows the average daily error of the WCMA predictor with the prediction window varying from one minute to one hour.
Comparing it to EWMA (Figure~\ref{fig:ewma_spaces}), it is possible to observe that WCMA shows reasonably lower error rates when using smaller window sizes.
In contrast with what happens with EWMA, the error rate escalates as the prediction window increases, specially when above 30 minutes, behaving mostly erratically with prediction windows close to 1 hour.
In the figure, the first 30 days were discarded to allow the algorithm to warm-up.

?EXPLICAR MELHOR O FILTRO
\begin{eqnarray}
\label{eq:wcma} \hat{E}_{i+1}(d) = \alpha \cdot E_i(d) + GAP_k \cdot M_D(d,i+1)\\
M_D(d,i) = \frac {\sum_{i=d-1}^{d-D}{E_{j,i}}} {D}\\
V = \{ v_1, v_2, \ldots, v_K \},~v_k = \frac {E_{n- K + k - 1}(d)} {M_D(d, n - K + k - 1)}\\
P = \{ p_1, p_2, \ldots, p_K \},~p_k = \frac{k}{K}\\
GAP_k = \frac{V \cdot P}{\sum P}
\end{eqnarray}


\subsection{Simple Moving Average}


The Simple Moving Average, or Running Average (RA), is a filter whose output is the linear average of the sunlight irradiation of a given time slot in the recent days.
It contrasts with the weighted averages of EWMA and WCMA.
Altought being simpler than WCMA and comparable to EWMA in terms of processing demands (see Equation~\ref{eq:ra}), it consumes more memory because it must store the values used in the average to drop the older of them in each iteration.
As can be seen in Figure~\ref{fig:ra_spaces}, the precision of the predictor is highly dependent on the size of the time slots.
Figures~\ref{fig:ra_space-err_avg} and~\ref{fig:ra_space-err_wgt} show that RA's performance is better during the summer, where fewer abrupt weather changes take place.
The lower errors in Figure~\ref{fig:ra_space_year_error-err_avg}, when compared to Figure~\ref{fig:ra_space_year_error-err_wgt}, indicates that most RA errors occur in low irradiance periods.
Also, the high standard deviation for larger prediction slots in both figures shows that the predictor is unreliable in such cases.
Like in EWMA and WCMA, RA presents a warm-up phase.
The plotted results use a look-back window of thirty days to compute the average for a given time slot.

\begin{equation}
\label{eq:ra} \hat{E}_{i+1} = \hat{E}_i - \frac{E_{i-D}}{D} + \frac{E_i}{D}
\end{equation}


\subsection{Constant Predictor}


The CP (Constant Predictor) is a simple heuristic for predicting sunlight irradiation.
Dividing the time into slots, CP assumes that the amount of energy intake for the next slot will be the same of the previous one, i.e., $\hat{E}_{i+1} = E_i$.
The precision of the predictor is highly dependent on the size of the time slots.
Unlike the average-based approaches, the warm-up phase of CP is very short (one slot), and the algorithm exhibits an absolute simplicity: it stores only the last recorded energy intake and performs only one attribution.
Figure~\ref{fig:cp_spaces} shows that, besides the fact that CP precisions for slots larger than 15 minutes are disastrous, it works surprisingly well for shorter-term predictions (average errors bellow 10\% for 1 and 5 minutes).


\subsection{CP Corrections}

An approach to improve the results of CP is to correct the predictions using its derivative to estimate the future behavior of the irradiation curve.
We evaluated the use of the first (FD) and second (SD) derivatives.
The results of FD and SD are shown, respectively, in Figures~\ref{fig:fdd_spaces} and~\ref{fig:sdd_spaces}.  
In the algorithm, the derivatives are approached numerically using Newton's method of the difference quotient\footnote{In this case, once the derivative uses the last predictions, the quotient (time difference) is unitary, i.e., one slot. That is why there is no quotient in Equation~\ref{eq:fdd}}.
In terms of required resources, this algorithm only stores one extra value for the recent energy intake ($E_{i-1}$) to compute the first derivative and another extra value ($E_{i-2}$) to compute the second derivative.
Although showing slightly smaller prediction errors on the average, the introduction of the derivatives increased the standard deviation of the predictions, making the algorithms even less reliable.

\begin{equation}
\label{eq:fdd} \hat{E}_{i+1} = E_i + (E_i - E_{i-1})
\end{equation}
\begin{equation}
\label{eq:sdd} \hat{E}_{i+1} = E_i + (E_i - E_{i-1}) + [ (E_i - E_{i-1}) - (E_{i-1} - E_{i-2}) ]
\end{equation}

%\subsection{Discussion on the analyzed predictors}

%Nevertheless, the first 30 days were also discarded in Figure~\ref{fig:cp_spaces} for better visual comparison.


%\tab{avg_error}{Average error of the predictors after one year.}
%Table~\ref{tab:avg_error} shows the average error of each predictor together with its standard deviation.
%As can be seen, EWMA and WCMA show high average daily errors, while WCMA shows a very large standard deviation.
%In fact, 



%\section{Computational complexity of current predictors}
%\label{sec:computing}

\section{Heuristically choosing a prediction}
\label{sec:heuristics}

Section~\ref{sec:error} showed the analysis of the behavior of several sunlight irradiation predictors.
The analysis showed that better prediction, as the ones from the average-based predictors, comes at the cost of higher complexity, that would demand more processing power and memory capacity.
Sensing nodes have limited resources, with typical memory capacities of one to four kilobytes, and reduced processing time due to energy management through duty-cycling (i.e., long sleeping periods).
In these cases, it is impossible to use EWMA or WCMA, and RA would consume an important portion of the system resources.

In order to have a reliable short-term predictor executing in such constrained platforms, we analyze now a set of heuristics that try to increase the reliability of the less resource-consuming predictors: CP, FD, and SD.
It has been observed that, although being unreliable, these predictors give precise results in some situations.
For instance:
\begin{compactitem}
\item CP has a very low error rate with little variation when using small time slots;
\item FD shows lower error rates when variations are steady/monotonic, i.e., when sudden weather changes do not happen along the day;
\item SD, although not behaving very well when considering the average, show a large standard deviation, and can adapt better to sudden weather changes.
\end{compactitem} 

In this work we present BEST: a predictor of energy intake that heuristically chooses the ``best'' prediction.
Figure~\ref{fig:optimum_bests_wgt} shows what would be the optimum performance of BEST given that it can choose among the predictions of any of the six heuristics presented in Section~\ref{sec:error}.
This figure shows what the prediction error would be if BEST could always know, before hand, which predictor will have the lower error.

\fig{optimum_bests_wgt}{$E_{wgt}$ of BEST and BEST2 optimum heuristics.}{width=\columnwidth}

Figure~\ref{fig:optimum_bests_wgt} also shows the optimum performance of BEST when disregarding the average-based predictors, that consume much more computing resources.
Altought the performance of BEST2 is not as good as BEST's, BEST2 performance is comparable to the performance of EWMA and WCMA for shorter-term predictions for several of the prediction windows.
The advantage of the approach is that it comes at a much lower computational price.

In order to approach the optimum BEST during runtime, we propose three distinct heuristics:
\begin{compactitem}
\item {\bf Conservative:} a heuristic that always chose the method that predicts the {\emph lower} amount of energy intake for the next slot;
\item {\bf Greedy:} a heuristic that always chose the method that predicts the {\emph higher} amount of energy intake for the next slot;
\item {\bf Hit-Count:} a heuristic that computes each method's errors and changes the method of choice when one of the candidates shows the lowest error for two consecutive slots.
\end{compactitem}

\fig{heuristic_best_wgt}{$E_{wgt}$ for the heuristics approaching BEST2.}{width=\columnwidth}

Figure~\ref{fig:heuristic_best_wgt} show the performance of the three proposed heuristics.
It is shown that the choosing of an adequate heuristic to approach BEST2 depends on the prediction window required by the system.
Table~\ref{tab:best_heuristics} summarizes the best heuristic option for each prediction window.
The next section evaluates the impact of these heuristics in systems' failure rates.

\tab{best_heuristics}{More adequate heuristics to approach BEST2.}


\section{Experimental results}
\label{sec:experiments}

% In this section the proposed heuristics for predicting sunlight irradiation are evaluated through simulation using a setup typical for wireless sensor networks.
% 
% \subsection{Experimental scenario}

Recalling Section~\ref{sec:intro}, the ability to predict energy intake enables systems to adapt themselves to take the best advantage of the harvested energy.
If a system predicts a high availability of energy in the near future, it can increase the amount of work it executes, growing system performance at the expense of more energy.
Similarly, if the predictor foresees a period of low energy availability, an adaptation can take place to reduce the use of energy before its availability becomes critical, thus preventing system failures due to battery depletion.

The simulations presented here evaluate the heuristic predictors described in Section~\ref{sec:heuristics} when deployed to wireless sensor nodes in a dense, mobile network.
This application builds a critical scenario for communication and energy consumption due to the large amount of data exchanged in the network.
The simulation is parameterized with data collected from real measurements performed on \textsc{EposMoteII} nodes powered by rechargeable batteries and solar panels~\cite{Slongo:2013}.

The application consists of a wireless sensor network running the Ant-based Dynamic Hop Optimization Protocol (\textsc{ADHOP})~\cite{Okazaki:Sensors:2012} over an IP network using IEEE 802.15.4.
\textsc{ADHOP} is a self-configuring, reactive routing protocol.
The reactive component of \textsc{ADHOP} uses an \emph{Ant Colony Optimization} algorithm to discover and maintain routes.
Ants, piggybacked on data packets, go out to track routes and leave a trail of pheromone on their way back.
The routes through which packets get forwarded are those with larger amounts of pheromone.

% Describe ADHOP modification - task table
\textsc{ADHOP} is modified to become energy-aware.
The tasks implementing \textsc{ADHOP} are now either hard real-time or best-effort.
Hard real-time tasks must be executed regardless of the system's energy state, and thus, there must be an energy reserve for them.
Best-effort tasks run whenever the execution of hard real-time tasks is guaranteed, and their execution rate is proportional to the amount of excess energy.

\Tab{adhop-taskset}{Parameters for the tasks of the \textsc{ADHOP} case-study.}

The main idea behind this setup is to homogenize the battery discharge for every node in the network to enhance the lifetime of the network as a whole.
Considering the radio as the most energy-hungry component in a wireless sensing node, we modeled the routing activities of \textsc{ADHOP} as best-effort tasks, as shown by the task set at Table~\ref{tab:adhop-taskset}.

The basic functionalities of sensing a value (task \textit{Sense}) and sending it through the radio to a sink node (task \textit{Send}) where modeled as hard real-time tasks.
Two best-effort tasks implement the routing functionality:
\textit{LPL} (Low Power Listen) monitors the channel for arriving messages, and \textit{Route} actually receives incoming messages, handles them, and forwards them to the next node in the selected route.
This approach will break routes when nodes selfishly stop their best-effort tasks.
However, ADHOP is a suitable candidate for these modifications because the ACO-based mechanism to discover routes will, in time, find alternate routes.

% Describe application characteristics (lifetime, battery size, etc)
We fixed the guaranteed lifetime for this system at 30 days.
This means that, if the energy harvesting mechanism fails, the system will still be able to run its hard real-time tasks for, at least, 30 days.
Analyzing the task-set one can estimate the WCEC of the hard real-time tasks to around $722~mAh$ during the desired guaranteed lifetime.
The battery size has to be greater than that to allow the system to reserve energy to its critical part.
For these simulations, we assumed a battery with nominal capacity of $2,100~mAh$, which is a typical value for an NiMH AA rechargeable battery.

% Describe the 2 steps simulation
The evaluation procedure involves two simulation steps.
In the first step, a simulation using the \textsc{OmNET++} Simulator characterized response of the application to variations in the execution rate of its best-effort tasks.
As can be seen in Figure~\ref{figtwo:adhop-char-ddradhop-char-energy}, lower energy consumption at lower execution rates of best-effort tasks comes at the expense of lower data delivery rate.
% Also, it is possible to observe in the graphic that BET rates above $50\%$ have no significant impact on packet delivery.
% Thus, it is assumed that BET rate will only be adjusted within the range $[0,50]$ as a means to further save energy.

\Figtwo
{adhop-char-ddr}{Data delivery per BET rate.}{width=\columnwidth}
{adhop-char-energy}{Avg. power and energy cons. per BET rate}{width=\columnwidth}
{Network response to BET rate.}{0.5\textwidth}


% * After that, energy consumption was simulated for desired lifetime
The second step applies the proposed heuristics to this system and recomputes the execution rate of best-effort tasks taking the predictions into account.
The impact of the heuristics over the system is evaluated according to the failures observed.
In this context, we consider that a failure happens every-time an error on the prediction would jeopardize the energy reservation for the hard real-time tasks.
Heuristics are compared according to two metrics: the time until the first failure and the frequency in which failures take place.

% \subsection{Simulation results}




\section{Conclusion}
\label{sec:conclusion}




%% References with bibTeX database:

\bibliographystyle{elsarticle-num}
\bibliography{paper}

%% Authors are advised to submit their bibtex database files. They are
%% requested to list a bibtex style file in the manuscript if they do
%% not want to use elsarticle-num.bst.

%% References without bibTeX database:

% \begin{thebibliography}{00}

%% \bibitem must have the following form:
%%   \bibitem{key}...
%%

% \bibitem{}

% \end{thebibliography}


\end{document}

%%
%% End of file `elsarticle-template-num.tex'.
