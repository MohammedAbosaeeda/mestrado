% ------------------------------------------------------------------------------
\subsection{Distributed Motion Estimation}
ME is a technique employed to explore the similarity between 
neighboring pictures in a video sequence.
Figure \ref{fig:motion_estimation} illustrates the ME process for the
neighboring pictures \emph{A} and \emph{B}.
By searching for similarities between these two pictures, it is possible
to determine which blocks from picture \emph{A} are also found in
picture \emph{B}.
Such displacement of picture blocks is encoded by \emph{motion vectors}
(represented by the small arrows in the bottom side of
Figure \ref{fig:motion_estimation}).
Exploring the similarity between neighboring pictures allows for
difference-based encoding, thus increasing the compression rate of the generated
bitstream \cite{citeulike:1269699}.
As ME is a significant stage for H.264 encoding, the component
we have adapted to work with embedded \java~and~\lua~uses an optimized version
of ME.
In order to improve the performance of ME, the component uses a data
partitioning strategy where the motion estimation for each partition of the
picture is performed in parallel in a specific functional unit, such as a core
of a multicore processor.
However, such complexity is hidden from the point of view of the user of the
component (e.g. H.264 encoder), which only sees a component to perform ME
by using the \emph{match} method.

\figtwocolumn{.4}{motion_estimation}{Motion Estimation.}


% (4) About the DMEC App: Java and Lua, mimics the H.264 encoder
In order to use the ME component from \java~and \lua, first we wrote an
application that mimics the behavior of an H.264 encoder then, we have generated
binding code classes for \java~and \lua.

Figure \ref{progjava:dmec_java_app} shows the Java version of the
encoder-like application.
Figure \ref{proglua:dmec_lua_app} shows the same application written in \lua.
The application provides the component with pictures,
get from the component the ME results (motion vectors and motion cost), and
checks if the results are correct.

\progjava{dmec_java_app}{Motion Estimation Java application.}

\proglua{dmec_lua_app}{Motion Estimation Lua application.}

% \multprogjavatwoh{dmec_java_app}{dmec_lua_app}{ME Java and Lua applications.}


% (5) KESO wrapper and a Lua wrapper for DMEC (text in msc thesis: p6)
% IMPORTANT TO SAY TODO: This shows the reuse between distinct FFIs
Using \emph{EBG}, we have generated binding code classes for the ME component
in order to integrate it with \java~and \lua.
Figure \ref{progc:dmec_wrappers4lua} shows the binding code wrapping the
\emph{match} method to provide it for \lua.
Figure \ref{progc:dmec_wrappers4nano_vm} shows the equivalent code for NanoVM,
and Figure \ref{progjava:dmec_wrappers4java} shows it for KESO (both \java).
It is not our goal to describe these figures in detail.
Instead, such figures are an illustration that the same functional component
of the binding can be \emph{reused} for distinct FFIs.
% Na real o reuso é meio que a nível de DERCS..., mas tudo bem.
% Aqui mostra depois do weaving e depois da geração de código.
In all figures it is shown that the ME
parameters: the \emph{current} and the \emph{reference} picture
(which correspond, respectively, to picture \emph{A} and \emph{B} from
Figure \ref{fig:motion_estimation}) are selected and then used on the invocation
of the \emph{match} method.
Then, the \emph{match} method returns the motion vectors and
the motion cost (grouped together by the class \emph{PictureMotionCounterpart}).
% The output generated by EBG for KESO FFI,
% shown at Figure \ref{progjava:dmec_wrappers4java},
% is different from the output for \lua~and NanoVM FFI due to the
% generational approach of KESO.
% Instead of generating the binding code, EBG generates a \emph{weavelet} class
% (following the KESO FFI) which is then used by the KESO compiler to generate
% the final binding code.
% 
% It recovers the motion estimator object from the \lua's stack, as well the ME
% parameters: the \emph{current} and the \emph{reference} picture
% (which correspond, respectively, to picture \emph{A} and \emph{B} from
% Figure \ref{fig:motion_estimation}).
% Then, it invokes the \emph{match} method which returns the motion vectors and
% the motion cost (grouped together by the class \emph{PictureMotionCounterpart}).
% Finally, it puts back in the \lua's stack the ME's result and
% returns the control to the \lua~runtime.
% Figure \ref{progc:dmec_wrappers4nano_vm} shows the same binding code for the
% NanoVM FFI.
% Its structure is very similar to the \lua~binding code: it invokes the motion
% estimator and it uses the NanoVM stack to get the parameters and publish the
% ME return.
% The output generated by EBG for KESO FFI,
% shown at Figure \ref{progjava:dmec_wrappers4java},
% is different from the output for \lua~and NanoVM FFI due to the
% generational approach of KESO.
% Instead of generating the binding code, EBG generates a \emph{weavelet} class
% (following the KESO FFI) which is then used by the KESO compiler to generate
% the final binding code.


\progc{dmec_wrappers4lua}{Binding code for \emph{match} method (Lua FFI)}

\progc{dmec_wrappers4nano_vm}{Binding code for \emph{match} method (NanoVM FFI)}

\progjava{dmec_wrappers4java}{Binding code for \emph{match} method (KESO FFI)}


% (6) Performance evaluation: time overhead for match method
In order to evaluate the feasibility of the generated binding code classes, we
have evaluated them according to performance and memory consumption.
For performance evaluation, first we have measured the time overhead caused by
the binding code of the \emph{match} method.
%according to the equation \ref{eq:time_overhead}.
Then, we have calculated how such overhead affects the ME throughput in order to
see the impact in ME overall performance.
All time measurements were performed using the IA32 \emph{Time-Stamp Clock} (TSC),
which is a 64-bit register that counts the number if cycles since reset.
For memory usage evaluation, first we have measured how many bytes the
binding code for the \emph{match} method has.
Then, we have calculated how much of the total system size is caused by such
overhead.
All memory measurements were performed using the utility \emph{size} of GNU for
the IA32.

% (7) Performance evaluation: throughput for C++, for KESO, and for Lua.
% IMPORTANT TO SAY TODO: This evaluation show that our wrappers does not impact
% on the overall performance of the application.
% The time requirements for ME processing are still fulfilled
Table \ref{tab:dmec_time_overhead} shows the time overhead of the \emph{match}
method for each FFI used.
The column \emph{Device} contains the device time, which is the time of the
\emph{match} method while accessed directly through a C++ program, without the
use of any binding.
Such time is independent of the FFI used.
The column \emph{Binding} shows the overhead just for the binding code
of the match method, column \emph{VM} shows the runtime environment support
(e.g. virtual machine) overhead for decoding an instruction of native method
invoking, and column \emph{Total} show the overall overhead (binding plus VM).
% Comparate KESO, NanoVM and Lua.
% some partial conclusion
% As one can see, for all the FFIs the time overhead was less than X\%.


%Time overhead			
%FFI	Device (µs)	Binding Overhead (µs)	VM Overhead (µs) Total Overhead (µs)
%Lua	9.68362E+005	2.73753E-003	6.29973E+001         6.30000E+001
%NanoVM	9.68362E+005	3.97423E-003	1.96960E+001         1.97000E+001
%KESO	9.68362E+005	8.26280E-003	1.18113E+003         1.18113E+003


\begin{table*}[t]
\begin{center}
\caption{Time overhead}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{FFI} & \textbf{Device ($\mu s$)} & \textbf{Binding ($\mu s$)} & \textbf{VM ($\mu s$)} & \textbf{Total ($\mu s$)}\\
\hline
Lua    & 9.68362E+005 & 2.73753E-003 & 6.29973E+001 & 6.30000E+001 \\
\hline
NanoVM & 9.68362E+005 & 3.97423E-003 & 1.96960E+001 & 1.97000E+001 \\
\hline
KESO   & 9.68362E+005 & 8.26280E-003 & 1.18113E+003 & 1.18113E+003 \\
\hline
\end{tabular}
\label{tab:dmec_time_overhead}
\end{center}
\end{table*}

% TODO: Checkar se vou usar estes valores de 30 fps mesmo.
% Até se vou usar fps
% Se usar, é necessário definir o que é fps: frames per second.
% Essa argumentação é interessante. Mas para isso o DMEC teria de entregar
% realmente a 33 fps (ou perto disso).
% Se nao for o DMEC outras opção seria alguma applicação que use a UART
% (e.g. TSG / uart do modem)
% Ou ainda o NIC::send do radio do EPOS mote II para uma aplicação de
% transmissão de audio (ver trabalho do Rufino).
In order to evaluate the time overhead impact on the overall ME performance, we
have calculated how such overhead affects the ME throughput.
Table \ref{tab:me_throughput} shows the results.
The column \emph{Original Throughput} shows the original ME throughput
(without using any binding code) while
the column \emph{New Throughput} shows the ME throughput while using each
FFI/MPL evaluated.
Considering that the required throughput for the ME is one Frame-per-Second
(FPS), the new throughput is acceptable for all FFIs considered.
The overhead caused by the binding code and the VM is independent of the
\emph{Device} time.
It only depends on the number and the type of methods arguments, and method
return plus the VM decoding time of a native method invoke instruction.
Theoretically, considering a very fast ME 
(e.g. with a device time in the order of dozens of $\mu s$),
the total overhead (also around dozens of $\mu s$) would be prohibitive 
because it would be in the same order of the device time (representing an overhead around 100\%).
However, this is not the case in the practice since an real-time ME is on the
order of 30 FPS which represents a device time of 33 ms that is still one order
of magnitude bigger than the obtained overhead.
Thus, in practice all FFIs used will continue to meet the time requirements.

%ME throughput		
%FFI	Original throughput (FPS)	New throughput (FPS)
%Lua	1.032672	1.032604
%NanoVM	1.032672	1.032651
%KESO	1.032672	1.031416

\begin{table*}[t]
\begin{center}
\caption{ME throughput}
\begin{tabular}{|c|c|c|}
\hline
% \textbf{FFI} & \textbf{Original Throughput ($fps$)} & \textbf{New Throughput ($fps$)}\\
\textbf{FFI} & \textbf{Original Throughput (FPS)} & \textbf{New Throughput (FPS)}\\
\hline
Lua    & 1.032672 & 1.032604 \\
\hline
NanoVM & 1.032672 & 1.032651 \\
\hline
KESO   & 1.032672 & 1.031416 \\
\hline
\end{tabular}
\label{tab:me_throughput}
\end{center}
\end{table*}

% (8) Memory evaluation: memory overhead for KESO and for Lua.
In order to evaluate the memory overhead caused by the generated binding code
classes, we have measured
how many bytes the binding code for the \emph{match} method has.
Table \ref{tab:dmec_memory_overhead} shows the obtained values
(column \emph{Overhead})
for each FFI used.
The same table shows the total system footprint, including application, and the
MPL runtime (composed by the VM and EPOS), and how much of this size is caused
by such the binding code classes.
The memory available for the platform where DMEC runs
%(256MB)
% (4GB)
is far away bigger
than the new footprint obtained while using the binding code classes.
Thus, for all FFIs, the generated binding code classes fulfill the memory
usage requirements.

%Memory overhead and its impact on the total footprint			
%FFI	Overhead (byte)	Footprint (byte)	Impact (%)
%Lua	800	1576512	0.05
%NanoVM	1453	1459501	0.1
%KESO	201	1463201	0.01

\begin{table*}[t]
\begin{center}
\caption{Memory overhead and its impact on the total footprint}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{FFI} & \textbf{Overhead (byte)} & \textbf{Footprint (byte)} & \textbf{Impact (\%)}\\
\hline
Lua    & 800  & 1576512 & 0.05 \\
\hline
NanoVM & 1453 & 1459501 & 0.1 \\
\hline
KESO   & 201  & 1463201 & 0.01 \\
\hline
\end{tabular}
\label{tab:dmec_memory_overhead}
\end{center}
\end{table*}



% (9) Talks about Hardware / Software platform. DMEC@HW - HLS.
% Não me parece muito relavante falar sobre isso se o foco do paper é reuso de
% binding code entre FFIs distintas.

\clearpage

% ------------------------------------------------------------------------------
