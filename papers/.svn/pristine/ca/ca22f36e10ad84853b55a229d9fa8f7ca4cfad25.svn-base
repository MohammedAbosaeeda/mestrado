\documentclass[english]{ieee}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{babel}
\usepackage{times}
\usepackage{graphicx}
\usepackage{listings}
\lstset{keywordstyle=\bfseries, flexiblecolumns=true}
\lstloadlanguages{[ANSI]C++,HTML}
\lstdefinelanguage{XML} {
  keywords={xml,version,DOCTYPE,SYSTEM,EPOSConfig,family,member,name,type,
  default,pos,pre}}
\lstdefinestyle{prg} {basicstyle=\small\sffamily, lineskip=-0.2ex}
\lstdefinestyle{prgbox} {basicstyle=\small\sffamily lineskip=-0.2ex}
\lstdefinestyle{inlineprg} {basicstyle=\small\sffamily}

\newcommand{\fig}[3][htbp]{
  \begin{figure}[#1] {\centering{\scalebox{.6}{\includegraphics{fig/#2}}}\par}
    \caption{#3\label{fig:#2}}
  \end{figure}
}

\newcommand{\prg}[4][htbp]{
  \begin{figure}[#1]
%    \vspace{\parskip}
%    \makebox[\textwidth][c]{
      \lstinputlisting[language=#2,style=prg]{prg/#3.prg} %}
%    \vspace{0.4\parskip}
    \caption{#4\label{prg:#3}}
  \end{figure}
}

\newcommand{\inlineprg}[2][C++]{
  \vspace{\parskip}
  \noindent\makebox[\textwidth][c]{
    \begin{lstlisting}[language=#1,style=inlineprg]{}
      ^^J #2
    \end{lstlisting}}
  \vspace{0.5\parskip}
}

\def\textprg{\lstinline[language=C++,style=inlineprg]}

\title{SoCs under the Perspective of AOSD}

\author{
  Fauze Valério Polpeta, Antônio Augusto Fröhlich and Arliones Hoeller Jr\\
  UFSC/CTC/LISHA\\
  PO Box 476\\
  88049-900 Florianópolis - SC, Brazil\\
  \texttt{\{fauze,guto,arliones\}@lisha.ufsc.br}\\
  \texttt{http://www.lisha.ufsc.br/$\sim$\{fauze,guto,arliones\}}
}

\date{}

\begin{document}
\maketitle
\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

  This paper outlines a strategy for automating the genesis of
  embedded systems in the context of hardware and software components
  by generating automatically customized \emph{System-On-Chip}'s and
  the associated run-time support system for dedicated applications.

  We concentrate in the \emph{Hardware Mediator} construct, a
  portability artifact that relies on the \emph{Application-Oriented
  System Design} to enable the port of component-based operating
  systems to very distinct architectures. Besides giving rise to a
  low-overhead system-hardware interface, hardware mediators can be
  used to dictate which \emph{Intellectual Property} components could
  be instantiated into an \emph{System-on-Chip} to satisfy, in terms of
  hardware devices, the requirements of a given application.

  The deployment of hardware mediators in the \textsc{Epos} system
  corroborates the portability claims associated to this software
  artifact and in which way it could enable the composing of
  \emph{Application-Oriented System-on-Chip}'s in different
  application backgrounds.

  \paragraph{Keywords:} \textsc{AOSD}~-~Application-Oriented System
  Design, Portability, IP~-~Intellectual Property,
  \textsc{SoC}~-~System-on-Chip, \textsc{EPOS}~-~Embedded Parallel
  Operating System

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Embedded systems are becoming more and more complex, yet, there is no
room for development strategies that incur in extended time-to-market in
this extremely competitive sector.  In this context, \emph{Programmable
  Logic Devices}~(PLD) define a compromise between system complexity and
development costs. Furthermore, recent advances in programmable logic
devices are enabling developers to integrate complex designs into a
single silicon pastille. These \emph{Systems-On-Chip}~(\textsc{SoC})
have several advantages over traditional circuit board implementations,
including the level of integration, power consumption, maintainability
and most other development metrics.

Nevertheless, getting a \textsc{SoC} out off a
\emph{Field-Pro\-gram\-ma\-ble Ga\-te Ar\-ray}~(FPGA) is not a
tri\-vi\-al task and requires an intricate engineering
process. Several strategies have been proposed for this purpose,
having in common a methodology to devise components, usually referred
to as \emph{Intellectual Property}~(\textsc{IP}), and to assembly
these components together in a functioning system. The reusability of
such soft \textsc{IP}s can be considerably increased by isolating
their core functionalities from interfacing aspects, thus enabling the
creation of libraries of pre-verified {IP}s that can be integrated as
a \textsc{SoC} with the use of additional ``glue logic''.

In order to automate the development of \textsc{SoC}s, much effort has
been payed to supporting tools that assist designers in selecting and
configuring the most adequate \textsc{IP}s and also in generating the
necessary glue logic. These tools usually presuppose an standardized
interconnect, such as \textsc{Wishbone}~\cite{Wishbone},
\textsc{Amba}~\cite{Amba}  or \textsc{Coreconnect}~\cite{Coreconnect}, 
and thus can be very effective. For instance, the
\textsc{Coral}~\cite{Bergamaschi:2000} tool from IBM uses the concept
of \emph{Virtual Design}~\cite{Bergamaschi:2000a} to provide the
designer with simplified \textsc{IP} descriptions that hide many
implementation details.

Some \emph{embedded systems} can be com\-ple\-te\-ly im\-ple\-men\-ted
in hardware using this approach, but the more complex the application,
the greater is the probability it will need some kind of
\emph{run-time support system} and an \emph{application program}. This
is, after all, the reason why so many groups are concentrating efforts
to develop processor soft
cores~\cite{OpenRISC1200:2001,LEON2:2004}. Nevertheless, run-time
support systems are often neglected by currently available
\textsc{SoC} development methodologies and tools, being mostly
restricted to simple processor scheduling routines and the definition
of a \texttt{software/hardware interface}~\cite{SOPCBuilder, ISE}. The
gap between software and hardware gets even bigger when we recall that
one of the primary goals of an operating system is to grant the
portability of applications, since ordinary operating systems cannot
go with the dynamics of \textsc{SoC}s.

In this paper, we con\-si\-der the deployment of
\textsc{Appli\-ca\-tion-Orien\-ted Sys\-tem
De\-sign}~(AOSD)~\cite{Froehlich:2001}, a design methodology
originally proposed for run-time support systems, to guide the
complete development of embedded systems, including software and
hardware components as well as their integration as a
\textsc{SoC}. The results obtained so far are encouraging and will be
discussed in details in the subsequent sections.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Application-Oriented System Design}

The idea of building run-time support systems through the aggregation
of independent softwa\-re components is being used with claimed
success in a series of pro\-jects~\cite{Beuche:1999, Ford:1997,
Reid:2000, Baum:1999}.  However, software component engineering brings
about several new issues, for instance: how to partition the problem
domain so as to model really reusable software components? how to
select the components from the repository that should be included on
an application-specific system instance?  how to configure each
selected component and the system as a whole so as to approach an
optimal system?

\emph{Application-Oriented System Design}~(AOSD)~\cite{Froehlich:2001}
proposes some alternatives to proceed the engineering of a domain
towards software components. In principle, an application-oriented
decomposition of the problem domain can be obtained following the
guidelines of \emph{Object-Oriented Decomposition}~\cite{Booch:1994}.
However, some subtle yet important differences must be considered.
First, object-oriented decomposition gathers objects with similar
behavior in class hierarchies by applying variability analysis to
identify how one entity specializes the other.  Besides leading to the
famous ``fragile base class'' problem~\cite{Mikhajlov:1998}, this policy
assumes that specializations of an abstraction (i.e. \emph{subclasses})
are only deployed in presence of their more generic versions (i.e.
\emph{superclasses}).

Applying variability analysis in the sense of \emph{Family-Based
  Design}~\cite{Parnas:1976} to produce independently deployable
abstractions, modeled as members of a family, can avoid this restriction
and improve on application-orientation.  Certainly, some family members
will still be modeled as specializations of others, as in
\emph{Incremental System Design}~\cite{Habermann:1976}, but this is no
longer an imperative rule. For example, instead of modeling
connection-oriented as a specialization of connectionless communication
(or vice-versa), what would misuse a network that natively operates in
the opposite mode, one could model both as autonomous members of a
family.

A second important difference between application-oriented and
object-oriented decomposition concerns environmental dependencies.
Variability analysis, as carried out in object-oriented decomposition,
does not emphasizes the differentiation of variations that belong to the
essence of an abstraction from those that emanate from the execution
scenarios being considered for it. Abstractions that incorporate
environmental dependencies have a smaller chance of being reused in new
scenarios, and, given that an application-oriented operating system will
be confronted with a new scenario virtually every time a new application
is defined, allowing such dependencies could severely hamper the system.

Nevertheless, one can reduce such dependencies by applying the key
concept of \emph{Aspect-Oriented Programming}~\cite{Kiczales:1997}, i.e.
aspect separation, to the decomposition process.  By doing so, one can
tell variations that will shape new family members from those that will
yield scenario aspects. For example, instead of modeling a new member
for a family of communication mechanisms that is able to operate in the
presence of multiple threads, one could model multithreading as a
scenario aspect that, when activated, would lock the communication
mechanism (or some of its operations) in a critical section.

Based on these premises, Application-Oriented Systems Design guides a
domain engineering procedure (see figure~\ref{fig:aosd} that models
software components with the aid of three major constructs: families of
scenario-independent abstractions, scenario adapters and inflated
interfaces.

\fig{aosd}{Overview of application-oriented domain decomposition.}


\subsection*{Families of scenario independent abstractions}

During domain decomposition, abstractions are identified from domain
entities and grouped in families according to their commonalities. Yet
during this phase, aspect separation is used to shape
scenario-independent abstractions, thus enabling them to be reused in a
variety of scenarios.  These abstractions are subsequently implemented
to give rise to the actual software components.

%The implementation of the members of a family of abstractions is not
%restricted to the use of specialization as we would do in
%object-orientation, although it can occur, when convenient. For example,
%members could be implemented as classes conjunctly distributed as a
%package through aggregation or composition. Afterwards, some families
%may contain mutually exclusive members, that is, only one of the members
%can be present in the system configuration at a time.


\subsection*{Scenario adapters}

As explained earlier, AOSD dictates that scenario dependencies must be
factored out as \emph{aspects}, thus keeping abstractions
scenario-independent. However, for this strategy to work, means must be
provided to apply factored aspects to abstractions in a transparent way.
The traditional approach to do this would be deploying an \emph{aspect
  weaver}, though the \emph{scenario adapter}
construct~\cite{Froehlich:sci:2000} has the same potentialities without
requiring an external tool.  A scenario adapter wraps an abstraction,
intermediating its communication with scenario-dependent clients to
perform the necessary scenario adaptations.


\subsection*{Inflated interfaces}

Inflated interfaces summarize the features of all members of a family,
creating a unique view of the family as a ``super component''. It allows
application programmers to write their applications based on well-know,
comprehensive interfaces, postponing the decision about which member of
the family shall be use until enough configuration knowledge is
acquired. The binding of an inflated interface to one of the members of
a family can thus be made by automatic configuration tools that identify
which features of the family were used in order to choose the simplest
realization that implements the requested interface subset at
compile-time.


\subsection*{Hardware mediators}

\emph{Hardware mediators} are software constructs that mediate the
interaction between abstractions and hardware components.  The main idea
behind hardware mediators is not to build universal hardware abstraction
layers and virtual machines, but sustaining an \emph{interface contract}
between system and machine. Differently from ordinary \textsc{HAL}s,
hardware mediators do not build a monolithic layer encapsulating the
resources available in the hardware platform. Each hardware component is
mediated via its own mediator, thus granting the portability of
abstractions that use it without creating unnecessary dependencies.
Indeed, hardware mediators are intended to be mostly metaprogrammed and
therefore dissolve themselves in the abstractions as soon as the
interface contract is met. In other words, a hardware mediator delivers
the functionality of the corresponding hardware component through a
system-oriented interface.


\subsection*{Configurable features}

Another important element of AOSD are \emph{configurable features},
which designate features of components that can be switched on and off
according to the requirements dictated by abstractions.  A configurable
feature is not restricted to a flag indicating whether a preexisting
feature must be activated or not. Usually, it also incorporates a
\emph{Generic Programmed}~\cite{Musser:1989} implementation of the
algorithms and data structures that are necessary to implement that
feature when the component itself does not provide it.  An example of
configurable feature is the generation of CRC codes in an Ethernet
mediator.

\subsection*{Component framework}

A \emph{component framework} captures a reusable software architecture
by defining how abstractions can be arranged together in a functioning
system. Reusable system architectures are usually defined considering
the domain knowledge acquired during the design of previous systems.
After having developed some systems, or some versions of a system, for a
certain problem domain, developers begin to agree on how to implement
the abstractions that build up the domain; how they interact with each
other, with the environment, and with applications; and how the implied
non-functional requirements can be accomplished.  Such an expertise can
be captured in an architectural specification to be reused in upcoming
systems.

% - Why to reuse an architecure?
Capturing reusable system architectures in a component-based system is
fundamental, since a real component-based system is only achieved when
components can be arranged together in an assemblage of predictable
behavior. In AOSD, reusable architectures begin to be modeled yet during
domain decomposition with the identification of relationships between
families of abstractions. These relationships are latter enriched by
scenario constraints during the specification of scenario aspects to
yield a component framework in the form of a collection of interrelated
scenario adapters. Each scenario adapter acts as a ``socket'' for
components of the corresponding family. Plugging components into the
framework is accomplished by binding the inflated interface of every
used family to the desired family member.  The way scenario adapters are
arranged in the framework would define the basic architecture of
resultant systems, while architectural elements that do not concern
components could be hard-coded in the framework.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{AOSD and SoCs} 

Although originally devised to guide the development of software
components of the operating system domain, the main concepts behind
the \emph{Application-Oriented System Design} methodology can also be
deployed on the context of hardware components. More specifically, on
the context of programmable logic, where hardware components are
described using high-level languages such as \textsc{VHDL},
\textsc{Verilog} and \textsc{SystemC} in order to abstract the physical 
elements of the underling hardware platform technology. When
instantiated, these components give rise to a program
\emph{bitstream}, which in its turn represents a substantial advance 
when compared to the lithography masks used to build hard ASIC
components.

The creation of a software component considering the \textsc{AOSD}
methodology is drived by four main stages: domain analysis, domain
decomposition, component design and its implementation. Indeed, all
the stages can be used without any modification to develop hardware
components. For comparison, it is perfectly feasible to think about
modeling a set of hardware devices as a family of hardware components,
and, these components are nothing more than a set of \textsc{HDL}
(Hardware Description Language) files, i. e., a \emph{software}.

In a future not so far, as an outcome of the consolidation of
higher-level languages for hardware description such as
\textsc{SystemC}, there will also be possible to employ, in the 
implementation of the hardware components, techniques that allow these
components to be much more organized and offer easier
maintainability. There can also be provided, through the use of
advanced techniques such as Aspect-Oriented Programming, Static
Meta-Programming, Subject-Oriented Programming and
Generic-Programming, an enhanced configurability, what will make
application-orientation much more feasible than now. Another important
outcome of this consolidation is a possible easier integration between
software and hardware source-code.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{SoCs in EPOS} 

Until this moment, we conjectured about portability in component-based
operating systems, focusing in the \emph{hardware mediator} construct,
which, differently from hardware abstraction layers and virtual
machines, have the ability to establish an interface contract between
the hardware and the operating system components and yet generate
virtually no overhead.

The use of hardware mediators in the \texttt{Epos} system corroborated
the portability claims associated to the techniques explained and
enabled \textsc{Epos} to be easily ported across very distinct
architectures without any modification in its software components. For
each architecture, only the respective set of hardware mediators has
to be implemented. However, the deployment of \emph{Application
Oriented System Design} on the context in which hardware mediators are
inserted---software-hardware interfacing---fosters this portability
artifact to a new perspective on the genesis of embedded systems. 

Under the scope of \textsc{AOSD}, hardware mediators, when
instantiated, can be viewed as a summary of which hardware components
are necessary to support an application. In this way, by extending the
concept of hardware operating system interface to a level that would
enable hardware generation, mediators are also figurated as pointers
for generating a ``machine description'' that matches, as does the
operating system, the application's requirements. Besides implementing
hardware interfacing components, mediators can be associated with
pre-designed and pre-verified hardware description components. Such
mediators, when instantiated, will give rise not only to a
system-hardware interface, but to an application-oriented hardware
instance in the form of a \emph{System-on-a-Chip}.~\footnote{A
\emph{System-on-a-Chip}, also referred as SoC, is an
apparatus able to deliver the same functionality that a traditional
hardware platform does when connecting several electronic components
together on a circuit board, but, differently from the traditional
ones, it is encapsulated in a single-chip pastille.}.

\prg{XML}{cpu.xml}{A fragment of the \texttt{CPU} hardware mediator 
          family description.}

In order to evaluate this new approach, the \texttt{Epos} system was
taken again. The strategy used in \textsc{Epos} to describe software
components in a repository and their dependencies plays a key role in
making the process of generating application-oriented SoCs
possible. The description of the components holds the information
necessary to identify which abstractions and hardware mediators
satisfy the application's requirements and more: which of these
mediators are associated with hardware components. A typical
description of a family of mediators is depicted in the
figure~\ref{prg:cpu.xml}.

%descrever como é uma família!

Perhaps, considering now that the mediator related to the
\texttt{OR1200} \texttt{CPU} core can be associated with a hardware
component or, in other words, an \emph{IP}~\footnote{IP is the
abbreviation for \emph{Intellectual Property}. It refers to a
description of a eletronic circuit that can later be reduced to an
on-chip hardware device through a synthesis process.}, which can be
instantiated in a programmable logic device to realize the same
functionality that a \texttt{OR1200} core chip does. To ratify this
peculiarity in the mediator description, a non-functional property
named \emph{synthesizable} is specified. As illustrated in the
figure~\ref{prg:or1200.xml} this property, classified as a
\emph{feature}, can designate other non-functional properties. 
In this case two \emph{dependences}, which in turn indicate the
hardware components that compose the \texttt{OR1200} \textsc{CPU}
core.
%~\footnote{Non-functional properties specify features provided
%by components and dependence among them that cannot be directly
%deduced from their interfaces. They are used only for configuration
%purposes, aggregating no extra-code to the system.}

\prg{XML}{or1200.xml}{A fragment of the hardware mediator for the
synthesizable \textsc{OR1200} \texttt{CPU} core.}

As regards to the description of this class of components, it follows
the same principles of describing system abstractions and hardware
mediators. However, due to the very own nature of the traditional
\emph{hardware description languages} in not implementing the object
oriented paradigm~\footnote{The traditional hardware description
languages are focused in the \textsc{VHDL} and \textsc{Verilog}
approachs. Otherwise, there is a substantial effort to bring to the
context of these languages the design paradigms used in software
programming.}, the description of hardware component is essencially
focused in non-functional properties and configurable features. The
figure~\ref{prg:or1200_ip.xml} presents a component family that
features, among other \textsc{CPU} components, those that compose the
\texttt{OR1200} core. As illustrated, both the \textsc{OR1200\_I} and
\textsc{OR1200\_D} have a feature named \emph{interconnection}. This 
feature specifies the on-chip bus(es) on which the component can be
compatibly connected. The subsequently configurable features, in the
form of \emph{traits}, aggregate the necessary information that will
be passed to a \texttt{SoC} building tool in order to perfectly enable
the integration of each IP when it is tailored into a
SoC.

\prg{XML}{or1200_ip.xml}{A fragment of a family of \texttt{CPU} hardware 
                         description components}

Nevertheless, new features or dependencies could be specified inside
the \texttt{IP} descriptions. The purpose of non-functional properties
have been specifying features that cannot be directly deduced from the
component's interface. Consider, for instance, that all the
IPs that will be instantiated for a given application have to
realize the same on-chip bus standard to be glued together into a
SoC. The already mentioned feature \emph{interconnection} 
enables us to ensure this peculiarity yet at system configuration
time.

However, classifying a hardware mediator as \emph{synthesizable} does
not implies that it will always instantiate the associated IP
components. It depends on a \emph{machine description} to determine,
as soon as the application's requirements are matched, which soft
IPs can be synthesized and which are already instantiated as
hard cores in hardware. Indeed, this machine description figurates an
complete overview of the hardware platform, including the devices that
it compromises and how these devices are disposed on it. The
figure~\ref{prg:orsoc_target.xml} depicts a description of a hardware
platform that is all based on a programmable logic device, which means
that each one of the system's mediators is associated with an
IP that will be instantiated as soon as the application
requires it.

\prg{XML}{orsoc_target.xml}{}

Yet in respect to the machine description illustrated in the
figure~\ref{prg:orsoc_target.xml}. The element named \emph{synthesis}
in the machine description has a crucial importance in the
configuration process. It summarizes all the global synthesis
properties that must be matched as features in the hardware
descriptions components that can be isntantiated as hardware devices
of this machine. Whithout this summary, the features of each component
would need to be matched among all the IPs. The mentioned
compatibility of on-chip bus between the IPs figurates a good
example of it. Another feature could be language used to describe the
hardware components (VHDL, Verilog...), specially if one wants to keep
the homogeneity in the implementation of the hardware components that
compose the machine. However considering that the synthesis process
will reduce the hardware components to a gate-level description, this
feature becomes optional and therefore, an own user decision.

Additionally, besides featuring a wide-ranging specification strategy
to describe software components from the operating system and hardware
domain, \textsc{Epos} counts with a development environment from which
many different application-oriented instances can virtually arises. An
overview of this infrastructure is depicted in the
figure~\ref{fig:epos_overview}.

\fig{epos_overview}{An overview of the \texttt{Epos} development 
                    environment.}

As depicted in the figure~\ref{fig:epos_overview}, the primary
specification produced is resulted from the application's
analysis. The \texttt{analyzer} scans the application searching for
references to the inflated interfaces~\footnote{Inflated interfaces
summarize the features of all members of a family, creating a unique
view of the family as a ``super component''} and outputs an
specification of requirements in the form of partial component
interface declarations, including methods, types and constants that
were used by the application. This specification feeds a second tool,
the \texttt{configurator}, which consults a component description
database to build a dependency three. The output of this configuration
process consists of a set of keys that define the binding of inflated
interfaces to abstractions and the definition of which IPs
(if the application and the platform enabled it) will be instantiated.
%Additionally, the \texttt{configurator} activates the scenario aspects
%and configurable features eventually identified as necessary to
%satisfy the constraints dictated by the target application or by the
%configured execution scenario.

The last step in the generation process is accomplished by the
\texttt{generator}. This tool translates the keys produced by the
\texttt{configurator} into parameters for a statically metaprogrammed
component framework and causes the compilation of a tailored operating
system instance. On the side of the hardware, if a SoC needs
also to be tailored, the \texttt{generator} counts with a \emph{SoC
Builder} module that, using the configurable features of the selected
IPs, will logically glue these components into a single 
synthesizable description that later can be instantiated in a
programmable logic device such as a FPGA.

\section{Case Study: OpenRISC 1200 Memory System}

Aiming the validation of these concepts, an analysis was made to
identify the effects of using this methodology on adapting the
processor's cache size and the number of \textsc{TLB} (Translation
Lookaside Buffer) entries to the application needs. The chosen
architecture was the \textsc{OpenRISC 1200}, a 32-bit scalar RISC
processor based on the Harvard microarchitecture, very similar to a
\textsc{PowerPC}~\cite{OpenRISC1200:2001}. This soft core is organized
in a way that allows the programmer to change the sizes of the
processor's caches and \textsc{TLBs}.

Experimental results showed that this core, configured with 8 KBytes
of cache memory (4 KBytes for instructions and 4 KBytes for data),
needs 772 more \textsc{LUTs} (Look-Up Tables) than the another one
with the same configuration just without any cache. This space can be
very useful when dealing with small \textsc{FPGA} (Field-Programmable
Gate-Array) devices, once the saved gates can be used to build, for
example, another microcontroller, or can even allow the use of a
smaller device, making the system cheaper. However, the definition of
the optimum size for the \texttt{CPU} cache must be done through a
workflow analysis, so it cannot be achieved automatically.

Nevertheless, the EPOS configuration tools will always know the size
of the software which will run over this SoC, so it can configure the
system's \textsc{MMU} (Memory Management Unit) to have only the amount
of \textsc{TLB} entries needed by the application. It is known that
the number of \textsc{LUTs} that will be saved through this
configuration is not so expressive as the ones saved by changing the
cache sizes, but what must be taken into account here is which gates
we are saving. The \textsc{TLB} implementation uses special purpose
gates that are built to make comparisons faster. Most \textsc{FPGA}
devices have a limited amount of this kind of gates, and some don't
even implement it, so avoid using them is a good design improvement.

Another complex issue to deal within this context is the software
support for a dynamically configurable \textsc{MMU}. Most operating
systems implements monolithic drivers to handle this devices. The
memory manager of the \textsc{EPOS} system is not implemented this
way. The use of several resources such as Aspect-Oriented Programming
and Static Meta-Programming, and the development following the AOSD
methodology generated a very efficient and easily portable software
support for a wide variety of memory management strategies. This
memory system is better described in the respective
work~\cite{Hoeller:2004}.

The table \ref{tab:memory_system} shows the obtained numbers of the
built SoCs. All of them were designed supposing a system with a 32-bit
processor (\textsc{OpenRISC 1200}) and a serial port
(\textsc{UART16550}). The first prototype had exactly this
configuration, i. e., it didn't have any cache memory or
\textsc{MMU}. The other two configurations imposed the use of a cache
memory and implemented a \textsc{MMU} with different \textsc{TLB}
sizes (64 and 128 entries). The gain on changing this configuration
isn't too good (54 \textsc{LUTs}), but it is enough to build, for instance,
another serial port. Another important issue to consider is that, as
explained above, saving these gates is important to allow other
devices to use the comparison gates.

\begin{table}[h]   
  \begin{center}
    \begin{tabular}{|l|r|}
      \hline
      \multicolumn{1}{|c|}{\textbf{Prototype} } & 
      \multicolumn{1}{|c|}{\textbf{LUTs}} \\
      \hline
      \textsc{Basic} & 5,866 \\
      \hline
      \textsc{Basic + 8KB cache + 64 entries TLB} & 6,638 \\
      \hline
      \textsc{Basic + 8KB cache + 128 entries TLB} & 6,692 \\
      \hline
    \end{tabular}
  \end{center}
  \caption{The size (in LUTs) of the synthesized prototypes.
	\label{tab:memory_system}}
\end{table}

\section{Conclusions and Future Work} 

This paper presented the results obtained until this moment from the
deployment of \textsc{Application-Oriented System Design}~(AOSD) as a
design methodology to develop complete embedded systems, including
software and hardware components, for it generating a hardware
instance in the form of a \textsc{SoC} and the correspondent run-time
software support, the both fulfilling the application's requirements.

The experiments were concentrated on instantiating a customized
OpenRISC-based \textsc{SoC} under different application contexts. The
\textsc{EPOS} system provided the appropriated support for these
experiments by enabling the description of the system components and
their respective integration. 

The results are so good that we decided to extend the project to a
level where we can, not only statically, but also dynamically adapt the
hardware and software instances in according with the applications
demand.

\bibliographystyle{ieee}
\bibliography{intro,arliones}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Portability in Ordinary Operating Systems}

Operating systems, as discussed in the introduction of this paper, are
one of the main artifacts to promote applicative software portability, as
they hide architectural dependencies behind standardized interfaces such
as \textsc{Posix}. A properly designed operating system
enables applications to endure the quick evolution of computer hardware
without major impact.  Consequently, being able to quickly port an
operating system to a new hardware platform became an strategic issue
for the software industry.

Yet in the 70's, the \textsc{VM/370}\footnote{The technical literature
often refers to \textsc{IBM}'s \textsc{VM/370} as \textsc{CP/CMS}.}
operating system from \textsc{IBM}~\cite{Case:1978} was strongly
concerned with portability. In order to enable batch applications
developed for older systems to execute in the new environment,
\textsc{IBM} opted for introducing multitasking in the \textsc{VM/370}
by means of a virtual machine scheme that delivered each application a
duplicate of the real hardware. In this way, each virtual machine
could run on its own operating system to match application's
requirements.  Since most of the virtual machine instructions were
indeed real machine instructions executed directly by the processor,
the whole scheme presented rather good performance. Nonetheless, this
approach prevented the system from being ported to other
architectures, restricting it to the
\textsc{TSS/370} platform.

The concept of virtual (or abstract) machine, however, goes far beyond
the scheme introduced by \textsc{VM/370}. As a matter of fact, any
software layer aimed at extending the functionality, or raising the
abstraction level, of a computer system can be taken as a \emph{virtual
  machine}. A high-level programming language compiler, which translates
abstract language constructs into machine-level instructions, could be
viewed as a virtual machine~\cite{Wirth:1992}. However, this could lead
us to conclude that the simple choice of an universal programming
language---such as \textsc{C}, for which numerous cross-compilers are
available---to implement the operating system could respond for all
portability matters. This is definitely not true: first, because
high-level programming languages do not feature all the operations
needed by the operating system to interact with the hardware, forcing
system programmers to write native code (e.g. \emph{assembly}) that
cannot be automatically translated to new architectures; second, because
device drivers are usually very platform-specific and cannot be
automatically converted too (e.g. a \textsc{IDE} disk driver cannot be
automatically converted into an \textsc{SCSI} driver).

Even if programming languages alone cannot be accounted for operating
system portability, they are a crucial means. By taking on a portable
programming language and gathering all architecture-dependent code in a
self-contained \emph{hardware abstraction layer}, operating system
engineers have an option for developing portable systems. The original
\textsc{Unix}~\cite{Thompson:1974} from \textsc{AT\&T Bell Labs} was one
of the first operating systems to use this approach. As described by
Miller~\cite{Miller:1978}, porting \textsc{Unix} from the \textsc{PDP}
to the \textsc{Interdata} was a straightforward activity mostly
concentrated on the \textsc{HAL} implementation. This strategy for
portability is nowadays adopted by many operating system, including
\textsc{Unix} descendants and also \textsc{Windows}.

Recent advances in both approaches are well represented by \textsc{Java
  VM} on the side of virtual machines and by \textsc{Exokernel} on the
side of hardware abstraction layers. On the one hand, systems like the
\textsc{JavaOS}~\cite{Madany:1996}, developed by Sun Microsystems, have
promoted the \textsc{Java VM} as an attractive system portability tool
but, not differently from other \textsc{VM}-based systems, the
\textsc{VM} must abstract all hardware resources and thus be
reimplemented for every new platform.  On the other hand,
\textsc{Exokernel}~\cite{Engler:1995} eliminates the notion of
abstractions from the operating system kernel. Instead, it provides
means for controlling system resources in a secure, multi-user
environment. However, the diversity of devices in each hardware platform
imposes severe restriction on the definition of interfaces for the
\textsc{Exokernel}, and therefore compromising its
portability~\cite{Kaashoek:1997}.

Nevertheless, both approaches, HALs and VMs, are becoming too
restricted to match contemporary software engineering techniques. As a
matter of fact, the design of traditional portability artifacts like
HALs and VMs is usually driven by the necessity of making the
resources available in a given hardware platform to a given operating
system. However, binding the design process to a preexisting hardware
platform or operating system makes room for unnecessary dependencies
that most likely will restrain both, reuse and portability. In order
to understand how such dependencies grow up in the system, let us
consider the well-know memory management scheme~\cite{Bach:1987} used
by \textsc{Unix}\footnote{A similar scheme is also used by
\textsc{Windows}, so the criticism could, in principle, be extend to
the entire desktop operating system scenario.}. The \texttt{brk}
system-call in \textsc{Unix} can be used by ordinary processes to
modify the size of its data segment. More notoriously, it is used by
\texttt{libc}'s \texttt{malloc} an
\texttt{free} functions to manage a process' heap. The implementation of
this system-call presupposes a paging memory management strategy
supported by an \textsc{MMU}. Indeed, implementing \texttt{brk}
without an \textsc{MMU} is unpractical, for it would imply in dynamic
process relocation. Consequently, \textsc{Unix}'s \textsc{HAL}
includes a paging engine abstraction. This design seems reasonable for
a multitasking operating system, but it severely compromises its
portability to a platform that does not feature a
\textsc{MMU}\footnote{A more careful design, that eliminates this
dependency, will be presented in section~\ref{sec:epos}.}.

Eliminating architectural dependencies of this kind, that extend thought
the system from \textsc{HAL} to \textsc{API}, is fundamental for systems
compromised with portability and reusability. In particular, the
embedded system realm, which today accounts for 98\% of the processors
in the market~\cite{Tennenhouse:2000}, cannot go with restrictions like
this. Moreover, embedded systems often operate on restricted resources
and monolithic \textsc{VM}s and \textsc{HAL}s are likely to overwhelm
the system. In this scenario, a component-based \textsc{HAL} whose
components can be selected and adapted according to application's
demands is certainly a better choice, specially if one considers
software/hardware co-design. The next section introduces a novel
strategy to achieve portability in component-based run-time support
systems.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Hardware Mediators in EPOS: a Case Study}
\label{sec:epos}

% What is EPOS

The Embedded Parallel Operating System~(\textsc{Epos}) aims at
delivering adequate run-time support for dedicated computing
applications.  In order to match its goal, \textsc{Epos} relies on the
\emph{AOSD} method to guide the
development of families of software components, each of which
implements a scenario-independent abstraction that can latter be
adapted to a given execution scenario with the aid of scenario
adapters.  Software components are collected in a repository and are
exported to the application programmers via inflated interfaces, which
hide the peculiarities of each member in a family as though the whole
family were a single component. This strategy, besides drastically
reducing the number of exported abstractions, enables programmers to
easily express their application's requirements regarding the
operating system.

An application designed and implemented according to the strategy
proposed by \textsc{Epos} can be submitted to a tool that performs
syntactical and data flow analysis to extract a blueprint for the
operating system to be generated. The blueprint is then refined by
dependency analysis against information about the execution scenario
acquired from the user via visual tools. The outcome of this process
supports the generation of an application-oriented operating system
instance.

% How HM are used in EPOS

% CPU Example
In order to preserve the portability of its software components,
\textsc{Epos} relies on hardware mediators. In principle, none of
\textsc{Epos} abstractions interact directly with the hardware,
utilizing the corresponding hardware mediators instead. In this way, a
context switch done in the realm of the \texttt{Thread} abstraction
concerns mainly the decision of which thread should occupy the
\textsc{CPU} next, leaving the operation of saving and restoring the
\textsc{CPU}'s context to the corresponding mediator. This might seem an
obvious example, but defining the interface for \texttt{CPU} mediator
becomes a hard task if one considers the variability of \textsc{CPU}
cores and the different environments in which they are used:
multithread, multitask, multiprocessor, etc.

% The MMU example
Perhaps a more substantial example can be found in \textsc{Epos}'s
memory management components. All portable operating systems are
challenged by the fact that some computing platforms feature
sophisticated memory management units (\textsc{MMU}) while others do not
provide any means to map and protect address spaces. For most operating
system, this is an unbreakable barrier that forces them to either be
portable across platforms that feature an specific kind of \textsc{MMU}
(.e.g paging) or portable across platforms without memory management
hardware. A careful design of abstractions and mediators enabled
\textsc{Epos}'s memory management components to be ported across
virtually any platform, including rudimentary microcontrollers such as
the \textsc{H8} and the \textsc{AVR8} along with powerful microprocessors
such as the \textsc{IA-32} and the \textsc{PowerPC}.

\fig{memory}{Memory manager components in \textsc{Epos}.}

The main design decision to enable \textsc{Epos}'s memory management
system to be highly portable was the encapsulation of details pertaining
address space protection and translation, as well as memory allocation,
inside the \texttt{MMU} family of hardware mediators. \textsc{Epos}
features an \texttt{Address\_Space} abstraction, which is a kind of
container for chunks of physical memory called \emph{segments}. It does
not implement any protection, translation or allocation duties, handling
them over the \texttt{MMU} mediator. A particular member of the
\texttt{Address\_Space} family, called \texttt{Flat\_AS}, defines a
memory model in which logical and physical addresses do match, thus
eliminating the need for a real \textsc{MMU}.  This model ensures the
preservation of the interface contract between other components and the
memory subsystem in platforms that do not feature an \textsc{MMU}. This
design is depicted in figure~\ref{fig:memory}, which additionally
illustrates the message flow for a segment creation (1 and 2) and
attachment (3 and 4).

The \texttt{MMU} mediator for a platform that does not feature the
corresponding hardware components is a rather simple artifact, since
its deployment implies in the \texttt{Flat\_AS}
abstraction\footnote{Deployment rules are used in \textsc{Epos} to
specify dependencies among components and particular requirements of
individual components. These rules are part of a build-up database
that is processed by the configuration tools and do not appear in the
source code of components.}.  Methods concerning the attachment of
memory segments into the single, flat address space become empty, with
segments being ``attached'' at their physical addresses. Methods
concerning memory allocation operate on words in a way that is similar
to \texttt{libc}'s traditional \texttt{malloc} function. To illustrate
the example, figures~\ref{prg:ia32mmu} and \ref{prg:h8mmu} present
fragments of the implementation of method \texttt{map} for two
significant architectures: \textsc{H8} and \textsc{IA-32}.

\prg{C++}{ia32mmu}{Implementation of method \texttt{map} of the
  \texttt{MMU} hardware mediator for the \texttt{Intel IA-32}.}

The example in figure~\ref{prg:ia32mmu} shows a typical implementation
of method \texttt{map} for an architecture with a two-level paging
engine, while the example in figure~\ref{prg:h8mmu} shows a typical
implementation for architectures that do not feature an \textsc{MMU}.
The variability across the member of a family of mediators do not affect
the interface contract of the family. Conceptually the memory model
defined by the \texttt{Flat\_AS} can be viewed as a degeneration of the
paged memory model in which the page size equals the size of a memory
word and the page tables implicitly map physical addresses as logical
ones.

\prg{C++}{h8mmu}{Implementation of method \texttt{map} of the
  \texttt{MMU} hardware mediator for the \texttt{Hitachi H8}.}

% The UART example
An additional phenomenon typical of low-level programming regards the
mediation of a same hardware device in different architectures.  For
example, suppose that a given device is part of two hardware platforms,
one that uses programmed I/O and another that uses memory mapped I/O.
Being the same \textsc{UART} it is very likely that the procedures used
to interact with the device in both platforms would be the same, thus
turning the corresponding device driver into a portable component.
Nevertheless, the different I/O access modes will probably drive
traditional operating system into setting up two distinct, non-portable
device drivers.  A metaprogrammed hardware mediator can solve this kind
of problem by introducing an \texttt{IO\_Register} abstraction that is
resolved to one of the possible access modes at compile-time. An outline
of such abstraction, as well as a simple deployment example, is
presented in figure~\ref{prg:io_reg}.(Not ~\ref{fig:epos_machine}).

\fig{epos_machine}{The \texttt{Machine} hardware mediator in
  \textsc{Epos}.}

\prg{C++}{io_reg}{The metaprogrammed \texttt{IO\_Register} construct.}

% The IC example

%O uso de mediadores de hardware como mecanismo de portabilidade é
%ampliado quando técnicas de \emph{Aspect Oriented Programming} são
%empregadas. A possibilidade de ``diluir'' no código de um mediador
%propriedades específicas do elemento de hardware permite transpor a
%visão unilateral do mediador como uma abstração de hardware ao ponto
%de ser caracterizado como uma extensão dos componentes que constituem
%as abstrações do próprio sistema operacional.

An general overview of \textsc{Epos} hardware mediators is presented in
figure~\ref{fig:epos_machine}. The \texttt{Machine} mediator yields a
topmost abstraction for a hardware platform.  It comprises a set of
other mediators, including processor (\texttt{CPU}), interrupt
controller (\texttt{IC}), timers (\texttt{TMR}), real-time clock
(\texttt{RTC}) and several other core devices.

\section{Sample system instances}

In order to illustrate portability achieved trought hardware
mediators, a same configuration of the \textsc{Epos} system was
instantiated for three very distinct architectures:
\textsc{IA-32}, \textsc{H8} and \textsc{PPC32}. This configuration
included support for a single task with multiple threads in a
cooperative environment. Dynamic memory allocation was also made
available to application threads. Table~\ref{tab:images} shows the size
(in bytes) of the segments relative to each generated image.

The figures shown in table~\ref{tab:images} illustrates system
adequacy as a run-time support system for embedded applications. All
three instances were generate from absolutely the same software
components (abstractions), but using particular hardware mediators.
The different sizes for \texttt{.text}, \texttt{.data} and
\texttt{.bss} segment originate basically from the different
instruction formats and word sizes of each one of the architectures.
%, while the differences in \texttt{.bss} result from distinct initial
% \texttt{heap} sizes (4 Kbytes for 32-bit architectures and 512 bytes
% for 8-bit architectures).

\begin{table}[h]   
  \begin{center}
    \begin{tabular}{|l|r|r|r|r|}
      \hline
      \multicolumn{1}{|c|}{\textbf{Arch} } & 
      \multicolumn{1}{|c|}{\textbf{.text}} & 
      \multicolumn{1}{|c|}{\textbf{.data}} &
      \multicolumn{1}{|c|}{\textbf{.bss} } & 
      \multicolumn{1}{|c|}{\textbf{total}} \\
      \hline
      \textsc{IA-32} & 926 & 4 & 64 & 994 \\
      \hline
      \textsc{H8} & 644 & 2 & 22 & 668 \\
      \hline
      \textsc{PPC32} & 1,692 & 4 & 56 & 1,752 \\
      \hline
    \end{tabular}
  \end{center}
  \caption{The size (in bytes) of \textsc{Epos} images for three 
           architectures.\label{tab:images}}
\end{table}

Perhaps a more significant analysis would have been a ration between
portable (abstractions, aspects and framework glue) and non-portable
(hardware mediators) system pieces, thus yielding the degree of
portability imputed to the system by the techniques introduced.
However, the deployment of \emph{Static Metaprogramming} in hardware
mediators causes them to dissolve in the system code, so that object
code analysis becomes meaningless. Counting the number of source code
lines would also lead us towards incorrect figures, since a good
fraction of a hardware mediator source code is dedicated to the
interaction with other metaprograms and abstractions, and generates no
object code. At least at this moment, the degree of portability must
be inferred from easiness to port component-based systems across such
different architectures as the \texttt{IA-32}, \texttt{H8} and
\texttt{PPC32}.

Additionally, in order to evaluate the gain of performance obtained
with hardware mediators, we elaborated a benchmark analysis involving
the \textsc{Epos} and the \textsc{eCos}~\cite{Massa:2002} system from
RedHat. Such as \textsc{Epos}, the Embedded Cygnus Operating System
(\textsc{eCos}) aims at delivering a customized run-time support
system that follow the application's requirements. However, as opposed
to \textsc{Epos}, \textsc{eCos} does not perform an application
analysis in order to identify which software components have to be
selected to provide the application with the necessary system and
hardware abstractions; application programmers need to specify them
manually, including a entirely \textsc{HAL}. As a consequence, we
could diagnose a performance decreasing that is illustrated in
table~\ref{tab:time}.~\footnote{The both benchmarks, context-switching
and memory allocation, were experimentally realized with a number of
10,000 consecutive operations.}

\begin{table}[h]   
  \begin{center}
    \begin{tabular}{|l|c|r|}
      \hline
      \multicolumn{1}{|c|}{\textbf{System}} & 
      \multicolumn{1}{|c|}{\textbf{operation}} & 
      \multicolumn{1}{|c|}{\textbf{time taken (\begin{math}{\mu}s\end{math})} }  \\ 
      \hline
      \hline
      \textsc{Epos} & context switching & 1,502 \\
      \hline
      \textsc{eCos} & context switching & 2,915 \\
      \hline
      \hline
      \textsc{Epos} & memory allocation & 762 \\
      \hline
      \textsc{eCos} & memory allocation & 3,180 \\
      \hline
    \end{tabular}
  \end{center}
  \caption{Context switching and memory allocation benchmarks of \textsc{Epos}
           and \textsc{eCos}.\label{tab:time}}
\end{table}

As \textsc{Epos}, the instance of \textsc{eCos} only featured support
for a single task with multiple threads and dynamic memory
allocation. The measurements shown in table~\ref{tab:time} consisted
of two basic tests. The first test was based on measuring the amount
of time taken to execute a specified number of consecutive
\texttt{CPU} context switches in a cooperative thread environment. The
second one aimed at measuring the amount of time taken to perform a
given number of memory allocations and their subsequently
releases. The results lead us to conclude that \textsc{Epos} was
around 95\% better than
\textsc{eCos} in the ``switch-context'' benchmark and 415\% better for
the ``memory-alloc'' benchmark.

The overhead diagnosed in \textsc{eCos} can be attributed to its
\textsc{HAL}, which is imputed into the system as soon as the target
platform is defined. The table ~\ref{tab:size} give us the notion of
how different are the system image sizes used in these benchmarks. It
is important to say here that we used the same
\textsc{IA-32}-based platform to benchmark the both systems.

\begin{table}[h]   
  \begin{center}
    \begin{tabular}{|l|c|r|}
      \hline
      \multicolumn{1}{|c|}{\textbf{System}} & 
      \multicolumn{1}{|c|}{\textbf{portability strategy}} &
      \multicolumn{1}{|c|}{\textbf{size}} \\
      \hline
      \textsc{Epos} & Hardware Mediators & 994 \\
      \hline
      \textsc{eCos} & HAL & 35,848 \\
      \hline
    \end{tabular}
  \end{center}
  \caption{The size (in bytes) of the \textsc{Epos} and \textsc{eCos} 
           system images for an \textsc{IA-32}-based platform.\label{tab:size}}
\end{table}

%In other experiment, TinyOS 

%%%%%%%%%%%%%%%%%%%%%%%%%%

\emph{Hardware Mediators}~\cite{?} has been proposed by Fröhlich in 
his \emph{Application Oriented System Design}
method~\cite{Froehlich:2001} as software constructs that mediate the
interaction between operating system components and hardware
components. Differently from the traditional software-hardware
interfaces, which are mainly concentrated in \emph{Hardware
Abstraction Layers} and \emph{Virtual Machines}, hardware mediators
have the ability to establish an interface contract between the
hardware and the operating system components. Each hardware component
is mediated via its own mediator and so; enabling the customization of
the software-hardware interface. In addition, the deployment of
\emph{Application Oriented System Design} on the context in which
hardware mediators are inserted---software-hardware
interfacing---enables hardware mediators to a new perspective in the
genesis of embedded systems whose the hardware platforms are based on
SoCs.

Besides giving rise to a low-overhead and customizable
software-hardware interface, hardware mediators can be themselves
associated with \emph{Intellectual Property} components. 
